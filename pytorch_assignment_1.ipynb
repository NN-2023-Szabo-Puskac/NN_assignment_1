{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonard\\anaconda3\\envs\\pytorch_nn_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import wandb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleonard-puskac\u001b[0m (\u001b[33mfiit-nn-2023-lp-vs\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Leonard\\Desktop\\2.semester\\NN\\NN_assignment_1\\wandb\\run-20230330_162243-wsoui2ck</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1/runs/wsoui2ck' target=\"_blank\">solar-grass-12</a></strong> to <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1' target=\"_blank\">https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1/runs/wsoui2ck' target=\"_blank\">https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1/runs/wsoui2ck</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1/runs/wsoui2ck?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x136c5c07940>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"nn-assignment-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/sonar.all-data\") as all_data_file:\n",
    "    lines = all_data_file.readlines()\n",
    "    all_data = []\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        line = line.strip().split(',')\n",
    "        label = line.pop()\n",
    "        #line = np.asarray(line, dtype=float)\n",
    "        if label == \"R\":\n",
    "            labels.append(0)\n",
    "            all_data.append(line)\n",
    "        elif label == \"M\":\n",
    "            labels.append(1)\n",
    "            all_data.append(line)\n",
    "        else:\n",
    "            pass\n",
    "    all_data = np.asarray(all_data, dtype=float)\n",
    "    labels = np.asarray(labels, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_2darray(d2array):\n",
    "    output_array = []\n",
    "    for array in d2array:\n",
    "        x = (array - np.mean(array)) / np.std(array)\n",
    "        #x[x<0] *= -1\n",
    "        #x = (x-np.min(x))/(np.max(x) - np.min(x))\n",
    "        output_array.append(x)\n",
    "    return np.asarray(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_2(input_data, input_labels):\n",
    "    indices = np.random.permutation(input_data.shape[0])\n",
    "    split_idx = math.floor(input_data.shape[0] * 0.7)\n",
    "    train_idx, test_idx = indices[:split_idx], indices[split_idx:]\n",
    "    train_data, test_data = input_data[train_idx,:], input_data[test_idx,:]\n",
    "    train_labels, test_labels = input_labels[train_idx], input_labels[test_idx]\n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 37)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm = normalise_2darray(all_data)\n",
    "\n",
    "corr_arr = []\n",
    "for idx, row in enumerate(x_norm):\n",
    "    arr = np.asarray(list(row) + [labels[idx]])\n",
    "    corr_arr.append(arr)\n",
    "corr_arr = np.asarray(corr_arr)\n",
    "corr_map = np.corrcoef(corr_arr, rowvar=False).round(2)\n",
    "corr_map = corr_map[:, 60]  # keep only final column of the heatmap | correlation to target class\n",
    "corr_map = corr_map.reshape((61, 1))\n",
    "\n",
    "to_drop = []\n",
    "for idx, value in enumerate(corr_map):\n",
    "    if value > -0.1 and value < 0.1:\n",
    "        to_drop.append(idx)\n",
    "\n",
    "x_norm = np.delete(x_norm, to_drop, axis=1)\n",
    "x_norm.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 37) (63, 37) (145,) (63,)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#x_train, x_val = train_test_split(x_norm, test_size=0.3)\n",
    "#y_train, y_val = train_test_split(labels, test_size=0.3)\n",
    "x_train, x_val, y_train, y_val = train_test_split_2(x_norm, labels)\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([145, 37]) torch.Size([63, 37]) torch.Size([145, 1]) torch.Size([63, 1])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "x_val = torch.tensor(x_val, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device).reshape(-1,1).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).to(device).reshape(-1,1).to(device)\n",
    "\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size) -> None:\n",
    "        super(Network, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.network = self.__setup_network()\n",
    "\n",
    "    def __setup_network(self):\n",
    "        net = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        return net\n",
    "    def forward(self, input):\n",
    "        return self.network(input)\n",
    "    \n",
    "    def fit(self, X, y, X_val, y_val, n_epochs, loss_fn, optimizer, batch_size=30):\n",
    "        batches = torch.arange(0, len(X), batch_size)\n",
    "        for epoch in range(n_epochs):\n",
    "            best_loss = 20000\n",
    "            best_acc = 0\n",
    "            self.train()\n",
    "            for batch_start in batches:\n",
    "                X_batch = X[batch_start:(batch_start+batch_size)]\n",
    "                y_batch = y[batch_start:(batch_start+batch_size)]\n",
    "\n",
    "                prediction = self.forward(X_batch)\n",
    "                loss = loss_fn(prediction, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                acc = (prediction.round() == y_batch).float().mean()\n",
    "                wandb.log({\"loss\": loss})\n",
    "                wandb.log({\"acc\": acc})\n",
    "                best_acc = acc if acc > best_acc else best_acc\n",
    "                best_loss = loss if loss < best_loss else best_loss\n",
    "            \n",
    "            self.eval()\n",
    "            y_pred = self.network(X_val)\n",
    "            val_acc = (y_pred.round() == y_val).float().mean()\n",
    "            val_loss = loss_fn(y_pred, y_val)\n",
    "            wandb.log({\"val_acc\": val_acc})\n",
    "            print(f\"Epoch {epoch}:\\ttrain_loss: {best_loss:.4f}\\ttrain_acc: {best_acc:.4f}\\tval_loss: {val_loss:.4f}\\tval_acc: {val_acc:.4f}\")\n",
    "                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\ttrain_loss: 0.6777\ttrain_acc: 0.6333\tval_loss: 0.7300\tval_acc: 0.3492\n",
      "Epoch 1:\ttrain_loss: 0.6705\ttrain_acc: 0.6333\tval_loss: 0.7267\tval_acc: 0.3492\n",
      "Epoch 2:\ttrain_loss: 0.6708\ttrain_acc: 0.6333\tval_loss: 0.7156\tval_acc: 0.3492\n",
      "Epoch 3:\ttrain_loss: 0.6540\ttrain_acc: 0.7000\tval_loss: 0.6536\tval_acc: 0.6508\n",
      "Epoch 4:\ttrain_loss: 0.5917\ttrain_acc: 0.7667\tval_loss: 0.6095\tval_acc: 0.6825\n",
      "Epoch 5:\ttrain_loss: 0.5505\ttrain_acc: 0.7667\tval_loss: 0.5842\tval_acc: 0.7460\n",
      "Epoch 6:\ttrain_loss: 0.5362\ttrain_acc: 0.7667\tval_loss: 0.5660\tval_acc: 0.7143\n",
      "Epoch 7:\ttrain_loss: 0.5112\ttrain_acc: 0.8000\tval_loss: 0.5954\tval_acc: 0.6984\n",
      "Epoch 8:\ttrain_loss: 0.4726\ttrain_acc: 0.8333\tval_loss: 0.5393\tval_acc: 0.7460\n",
      "Epoch 9:\ttrain_loss: 0.4827\ttrain_acc: 0.8333\tval_loss: 0.5034\tval_acc: 0.8095\n",
      "Epoch 10:\ttrain_loss: 0.4537\ttrain_acc: 0.8400\tval_loss: 0.5642\tval_acc: 0.7619\n",
      "Epoch 11:\ttrain_loss: 0.4027\ttrain_acc: 0.8667\tval_loss: 0.5134\tval_acc: 0.7778\n",
      "Epoch 12:\ttrain_loss: 0.4561\ttrain_acc: 0.8333\tval_loss: 0.5451\tval_acc: 0.7460\n",
      "Epoch 13:\ttrain_loss: 0.4376\ttrain_acc: 0.8333\tval_loss: 0.5620\tval_acc: 0.7460\n",
      "Epoch 14:\ttrain_loss: 0.4593\ttrain_acc: 0.8333\tval_loss: 0.5233\tval_acc: 0.7619\n",
      "Epoch 15:\ttrain_loss: 0.4584\ttrain_acc: 0.8333\tval_loss: 0.5061\tval_acc: 0.7937\n",
      "Epoch 16:\ttrain_loss: 0.4238\ttrain_acc: 0.8333\tval_loss: 0.4988\tval_acc: 0.8095\n",
      "Epoch 17:\ttrain_loss: 0.3820\ttrain_acc: 0.8667\tval_loss: 0.5044\tval_acc: 0.7937\n",
      "Epoch 18:\ttrain_loss: 0.3863\ttrain_acc: 0.8667\tval_loss: 0.4964\tval_acc: 0.7778\n",
      "Epoch 19:\ttrain_loss: 0.3425\ttrain_acc: 0.9000\tval_loss: 0.4854\tval_acc: 0.7778\n",
      "Epoch 20:\ttrain_loss: 0.3513\ttrain_acc: 0.9333\tval_loss: 0.4824\tval_acc: 0.7937\n",
      "Epoch 21:\ttrain_loss: 0.3400\ttrain_acc: 0.9333\tval_loss: 0.5048\tval_acc: 0.8095\n",
      "Epoch 22:\ttrain_loss: 0.3577\ttrain_acc: 0.8667\tval_loss: 0.5133\tval_acc: 0.8095\n",
      "Epoch 23:\ttrain_loss: 0.3479\ttrain_acc: 0.9000\tval_loss: 0.4400\tval_acc: 0.8254\n",
      "Epoch 24:\ttrain_loss: 0.3071\ttrain_acc: 0.9333\tval_loss: 0.4686\tval_acc: 0.8413\n",
      "Epoch 25:\ttrain_loss: 0.3245\ttrain_acc: 0.9000\tval_loss: 0.4724\tval_acc: 0.7937\n",
      "Epoch 26:\ttrain_loss: 0.4170\ttrain_acc: 0.8667\tval_loss: 0.5026\tval_acc: 0.8254\n",
      "Epoch 27:\ttrain_loss: 0.3224\ttrain_acc: 0.9333\tval_loss: 0.6006\tval_acc: 0.7619\n",
      "Epoch 28:\ttrain_loss: 0.3589\ttrain_acc: 0.9000\tval_loss: 0.4225\tval_acc: 0.8254\n",
      "Epoch 29:\ttrain_loss: 0.2739\ttrain_acc: 0.9667\tval_loss: 0.6016\tval_acc: 0.7460\n",
      "Epoch 30:\ttrain_loss: 0.3248\ttrain_acc: 0.9000\tval_loss: 0.3919\tval_acc: 0.8730\n",
      "Epoch 31:\ttrain_loss: 0.3580\ttrain_acc: 0.9000\tval_loss: 0.4827\tval_acc: 0.8254\n",
      "Epoch 32:\ttrain_loss: 0.2988\ttrain_acc: 0.9667\tval_loss: 0.5068\tval_acc: 0.8095\n",
      "Epoch 33:\ttrain_loss: 0.3026\ttrain_acc: 0.9333\tval_loss: 0.5319\tval_acc: 0.7937\n",
      "Epoch 34:\ttrain_loss: 0.2830\ttrain_acc: 0.9667\tval_loss: 0.4786\tval_acc: 0.8254\n",
      "Epoch 35:\ttrain_loss: 0.2590\ttrain_acc: 0.9667\tval_loss: 0.4590\tval_acc: 0.8413\n",
      "Epoch 36:\ttrain_loss: 0.2494\ttrain_acc: 0.9333\tval_loss: 0.4553\tval_acc: 0.8413\n",
      "Epoch 37:\ttrain_loss: 0.3883\ttrain_acc: 0.8667\tval_loss: 0.6179\tval_acc: 0.7778\n",
      "Epoch 38:\ttrain_loss: 0.3182\ttrain_acc: 0.9000\tval_loss: 0.4496\tval_acc: 0.8413\n",
      "Epoch 39:\ttrain_loss: 0.3396\ttrain_acc: 0.9000\tval_loss: 0.4479\tval_acc: 0.8254\n",
      "Epoch 40:\ttrain_loss: 0.3518\ttrain_acc: 0.9000\tval_loss: 0.4502\tval_acc: 0.8254\n",
      "Epoch 41:\ttrain_loss: 0.3392\ttrain_acc: 0.9333\tval_loss: 0.5699\tval_acc: 0.7937\n",
      "Epoch 42:\ttrain_loss: 0.2533\ttrain_acc: 0.9667\tval_loss: 0.4665\tval_acc: 0.8413\n",
      "Epoch 43:\ttrain_loss: 0.3025\ttrain_acc: 0.9000\tval_loss: 0.4686\tval_acc: 0.8095\n",
      "Epoch 44:\ttrain_loss: 0.3377\ttrain_acc: 0.9000\tval_loss: 0.4844\tval_acc: 0.8413\n",
      "Epoch 45:\ttrain_loss: 0.3189\ttrain_acc: 0.9000\tval_loss: 0.4847\tval_acc: 0.8095\n",
      "Epoch 46:\ttrain_loss: 0.3352\ttrain_acc: 0.9000\tval_loss: 0.4782\tval_acc: 0.8413\n",
      "Epoch 47:\ttrain_loss: 0.2990\ttrain_acc: 0.9000\tval_loss: 0.4762\tval_acc: 0.8413\n",
      "Epoch 48:\ttrain_loss: 0.2892\ttrain_acc: 0.9000\tval_loss: 0.5407\tval_acc: 0.7937\n",
      "Epoch 49:\ttrain_loss: 0.2497\ttrain_acc: 0.9667\tval_loss: 0.4608\tval_acc: 0.8095\n",
      "Epoch 50:\ttrain_loss: 0.3053\ttrain_acc: 0.9000\tval_loss: 0.5205\tval_acc: 0.7937\n",
      "Epoch 51:\ttrain_loss: 0.3331\ttrain_acc: 0.8667\tval_loss: 0.5335\tval_acc: 0.7778\n",
      "Epoch 52:\ttrain_loss: 0.3157\ttrain_acc: 0.9000\tval_loss: 0.5371\tval_acc: 0.7778\n",
      "Epoch 53:\ttrain_loss: 0.2918\ttrain_acc: 0.9333\tval_loss: 0.5209\tval_acc: 0.8095\n",
      "Epoch 54:\ttrain_loss: 0.2842\ttrain_acc: 0.9000\tval_loss: 0.5011\tval_acc: 0.8254\n",
      "Epoch 55:\ttrain_loss: 0.2796\ttrain_acc: 0.9000\tval_loss: 0.4352\tval_acc: 0.8413\n",
      "Epoch 56:\ttrain_loss: 0.3346\ttrain_acc: 0.9000\tval_loss: 0.4633\tval_acc: 0.8254\n",
      "Epoch 57:\ttrain_loss: 0.3061\ttrain_acc: 0.9667\tval_loss: 0.4617\tval_acc: 0.8095\n",
      "Epoch 58:\ttrain_loss: 0.3374\ttrain_acc: 0.9000\tval_loss: 0.5180\tval_acc: 0.8254\n",
      "Epoch 59:\ttrain_loss: 0.3025\ttrain_acc: 0.9000\tval_loss: 0.5930\tval_acc: 0.7937\n",
      "Epoch 60:\ttrain_loss: 0.2799\ttrain_acc: 0.9333\tval_loss: 0.5198\tval_acc: 0.7778\n",
      "Epoch 61:\ttrain_loss: 0.2757\ttrain_acc: 0.9333\tval_loss: 0.5704\tval_acc: 0.7937\n",
      "Epoch 62:\ttrain_loss: 0.2901\ttrain_acc: 0.9333\tval_loss: 0.5282\tval_acc: 0.7778\n",
      "Epoch 63:\ttrain_loss: 0.3262\ttrain_acc: 0.9000\tval_loss: 0.5033\tval_acc: 0.7778\n",
      "Epoch 64:\ttrain_loss: 0.3168\ttrain_acc: 0.9000\tval_loss: 0.5536\tval_acc: 0.7778\n",
      "Epoch 65:\ttrain_loss: 0.2608\ttrain_acc: 0.9333\tval_loss: 0.4897\tval_acc: 0.7937\n",
      "Epoch 66:\ttrain_loss: 0.3263\ttrain_acc: 0.9667\tval_loss: 0.5251\tval_acc: 0.7778\n",
      "Epoch 67:\ttrain_loss: 0.3130\ttrain_acc: 0.9333\tval_loss: 0.5349\tval_acc: 0.7778\n",
      "Epoch 68:\ttrain_loss: 0.3052\ttrain_acc: 0.9000\tval_loss: 0.4831\tval_acc: 0.8095\n",
      "Epoch 69:\ttrain_loss: 0.2606\ttrain_acc: 0.9667\tval_loss: 0.4897\tval_acc: 0.7937\n",
      "Epoch 70:\ttrain_loss: 0.3012\ttrain_acc: 0.9000\tval_loss: 0.5036\tval_acc: 0.8095\n",
      "Epoch 71:\ttrain_loss: 0.2574\ttrain_acc: 0.9333\tval_loss: 0.4532\tval_acc: 0.8254\n",
      "Epoch 72:\ttrain_loss: 0.2702\ttrain_acc: 0.9333\tval_loss: 0.5059\tval_acc: 0.8254\n",
      "Epoch 73:\ttrain_loss: 0.2953\ttrain_acc: 0.9000\tval_loss: 0.5243\tval_acc: 0.7778\n",
      "Epoch 74:\ttrain_loss: 0.2994\ttrain_acc: 0.9333\tval_loss: 0.5248\tval_acc: 0.8095\n",
      "Epoch 75:\ttrain_loss: 0.3180\ttrain_acc: 0.9000\tval_loss: 0.5087\tval_acc: 0.7937\n",
      "Epoch 76:\ttrain_loss: 0.2703\ttrain_acc: 0.9000\tval_loss: 0.5074\tval_acc: 0.8254\n",
      "Epoch 77:\ttrain_loss: 0.2653\ttrain_acc: 0.9333\tval_loss: 0.4443\tval_acc: 0.8095\n",
      "Epoch 78:\ttrain_loss: 0.2748\ttrain_acc: 0.9000\tval_loss: 0.4927\tval_acc: 0.8095\n",
      "Epoch 79:\ttrain_loss: 0.2532\ttrain_acc: 0.9333\tval_loss: 0.4518\tval_acc: 0.8254\n",
      "Epoch 80:\ttrain_loss: 0.2460\ttrain_acc: 0.9333\tval_loss: 0.4517\tval_acc: 0.8254\n",
      "Epoch 81:\ttrain_loss: 0.2394\ttrain_acc: 0.9333\tval_loss: 0.4456\tval_acc: 0.8413\n",
      "Epoch 82:\ttrain_loss: 0.2731\ttrain_acc: 0.9333\tval_loss: 0.4468\tval_acc: 0.8254\n",
      "Epoch 83:\ttrain_loss: 0.2317\ttrain_acc: 0.9667\tval_loss: 0.4524\tval_acc: 0.8254\n",
      "Epoch 84:\ttrain_loss: 0.2069\ttrain_acc: 0.9667\tval_loss: 0.4799\tval_acc: 0.8095\n",
      "Epoch 85:\ttrain_loss: 0.2507\ttrain_acc: 0.9333\tval_loss: 0.4781\tval_acc: 0.7937\n",
      "Epoch 86:\ttrain_loss: 0.2840\ttrain_acc: 0.9333\tval_loss: 0.4947\tval_acc: 0.7778\n",
      "Epoch 87:\ttrain_loss: 0.2754\ttrain_acc: 0.9333\tval_loss: 0.4772\tval_acc: 0.8095\n",
      "Epoch 88:\ttrain_loss: 0.2550\ttrain_acc: 0.9333\tval_loss: 0.4873\tval_acc: 0.8095\n",
      "Epoch 89:\ttrain_loss: 0.2798\ttrain_acc: 0.9333\tval_loss: 0.4790\tval_acc: 0.8254\n",
      "Epoch 90:\ttrain_loss: 0.2170\ttrain_acc: 0.9667\tval_loss: 0.4603\tval_acc: 0.8254\n",
      "Epoch 91:\ttrain_loss: 0.2714\ttrain_acc: 0.9333\tval_loss: 0.4571\tval_acc: 0.8413\n",
      "Epoch 92:\ttrain_loss: 0.2421\ttrain_acc: 0.9333\tval_loss: 0.4616\tval_acc: 0.7937\n",
      "Epoch 93:\ttrain_loss: 0.2364\ttrain_acc: 0.9333\tval_loss: 0.4745\tval_acc: 0.8254\n",
      "Epoch 94:\ttrain_loss: 0.2410\ttrain_acc: 0.9333\tval_loss: 0.4556\tval_acc: 0.8095\n",
      "Epoch 95:\ttrain_loss: 0.3008\ttrain_acc: 0.9000\tval_loss: 0.5069\tval_acc: 0.7937\n",
      "Epoch 96:\ttrain_loss: 0.2958\ttrain_acc: 0.9000\tval_loss: 0.5242\tval_acc: 0.7937\n",
      "Epoch 97:\ttrain_loss: 0.2850\ttrain_acc: 0.9000\tval_loss: 0.5378\tval_acc: 0.7778\n",
      "Epoch 98:\ttrain_loss: 0.2532\ttrain_acc: 0.9333\tval_loss: 0.4879\tval_acc: 0.7937\n",
      "Epoch 99:\ttrain_loss: 0.2532\ttrain_acc: 0.9333\tval_loss: 0.5102\tval_acc: 0.8095\n",
      "Epoch 100:\ttrain_loss: 0.2787\ttrain_acc: 0.9000\tval_loss: 0.5008\tval_acc: 0.8095\n",
      "Epoch 101:\ttrain_loss: 0.2597\ttrain_acc: 0.9333\tval_loss: 0.4766\tval_acc: 0.8095\n",
      "Epoch 102:\ttrain_loss: 0.2508\ttrain_acc: 0.9333\tval_loss: 0.4648\tval_acc: 0.7937\n",
      "Epoch 103:\ttrain_loss: 0.2486\ttrain_acc: 0.9333\tval_loss: 0.4331\tval_acc: 0.8413\n",
      "Epoch 104:\ttrain_loss: 0.2251\ttrain_acc: 0.9667\tval_loss: 0.4396\tval_acc: 0.8413\n",
      "Epoch 105:\ttrain_loss: 0.2221\ttrain_acc: 0.9333\tval_loss: 0.5268\tval_acc: 0.7937\n",
      "Epoch 106:\ttrain_loss: 0.2648\ttrain_acc: 0.9333\tval_loss: 0.4781\tval_acc: 0.7937\n",
      "Epoch 107:\ttrain_loss: 0.2683\ttrain_acc: 0.9333\tval_loss: 0.4992\tval_acc: 0.8095\n",
      "Epoch 108:\ttrain_loss: 0.2572\ttrain_acc: 0.9333\tval_loss: 0.4414\tval_acc: 0.8413\n",
      "Epoch 109:\ttrain_loss: 0.2445\ttrain_acc: 0.9333\tval_loss: 0.5074\tval_acc: 0.7937\n",
      "Epoch 110:\ttrain_loss: 0.2637\ttrain_acc: 0.9333\tval_loss: 0.4987\tval_acc: 0.7937\n",
      "Epoch 111:\ttrain_loss: 0.2320\ttrain_acc: 0.9333\tval_loss: 0.4154\tval_acc: 0.8413\n",
      "Epoch 112:\ttrain_loss: 0.2248\ttrain_acc: 0.9667\tval_loss: 0.4709\tval_acc: 0.8254\n",
      "Epoch 113:\ttrain_loss: 0.2296\ttrain_acc: 0.9333\tval_loss: 0.4989\tval_acc: 0.8254\n",
      "Epoch 114:\ttrain_loss: 0.2205\ttrain_acc: 0.9667\tval_loss: 0.4238\tval_acc: 0.8413\n",
      "Epoch 115:\ttrain_loss: 0.2004\ttrain_acc: 0.9667\tval_loss: 0.4236\tval_acc: 0.8413\n",
      "Epoch 116:\ttrain_loss: 0.2543\ttrain_acc: 0.9333\tval_loss: 0.3975\tval_acc: 0.8571\n",
      "Epoch 117:\ttrain_loss: 0.2384\ttrain_acc: 0.9333\tval_loss: 0.4088\tval_acc: 0.8413\n",
      "Epoch 118:\ttrain_loss: 0.2108\ttrain_acc: 0.9667\tval_loss: 0.3893\tval_acc: 0.8730\n",
      "Epoch 119:\ttrain_loss: 0.2185\ttrain_acc: 0.9333\tval_loss: 0.4368\tval_acc: 0.8413\n",
      "Epoch 120:\ttrain_loss: 0.2037\ttrain_acc: 0.9667\tval_loss: 0.4643\tval_acc: 0.8095\n",
      "Epoch 121:\ttrain_loss: 0.2297\ttrain_acc: 0.9333\tval_loss: 0.4601\tval_acc: 0.8413\n",
      "Epoch 122:\ttrain_loss: 0.2496\ttrain_acc: 0.9333\tval_loss: 0.4567\tval_acc: 0.8413\n",
      "Epoch 123:\ttrain_loss: 0.2427\ttrain_acc: 0.9333\tval_loss: 0.5849\tval_acc: 0.7778\n",
      "Epoch 124:\ttrain_loss: 0.2747\ttrain_acc: 0.9333\tval_loss: 0.4595\tval_acc: 0.8413\n",
      "Epoch 125:\ttrain_loss: 0.2284\ttrain_acc: 0.9667\tval_loss: 0.4359\tval_acc: 0.8413\n",
      "Epoch 126:\ttrain_loss: 0.2073\ttrain_acc: 0.9667\tval_loss: 0.4586\tval_acc: 0.8254\n",
      "Epoch 127:\ttrain_loss: 0.2697\ttrain_acc: 0.9000\tval_loss: 0.4067\tval_acc: 0.8413\n",
      "Epoch 128:\ttrain_loss: 0.2442\ttrain_acc: 0.9333\tval_loss: 0.4239\tval_acc: 0.8254\n",
      "Epoch 129:\ttrain_loss: 0.2407\ttrain_acc: 0.9333\tval_loss: 0.4808\tval_acc: 0.8095\n",
      "Epoch 130:\ttrain_loss: 0.2661\ttrain_acc: 0.9333\tval_loss: 0.4524\tval_acc: 0.8413\n",
      "Epoch 131:\ttrain_loss: 0.2839\ttrain_acc: 0.9000\tval_loss: 0.4339\tval_acc: 0.8413\n",
      "Epoch 132:\ttrain_loss: 0.2319\ttrain_acc: 0.9333\tval_loss: 0.5602\tval_acc: 0.7937\n",
      "Epoch 133:\ttrain_loss: 0.2678\ttrain_acc: 0.9333\tval_loss: 0.4639\tval_acc: 0.8413\n",
      "Epoch 134:\ttrain_loss: 0.2281\ttrain_acc: 0.9333\tval_loss: 0.4452\tval_acc: 0.8413\n",
      "Epoch 135:\ttrain_loss: 0.1993\ttrain_acc: 0.9667\tval_loss: 0.4785\tval_acc: 0.8095\n",
      "Epoch 136:\ttrain_loss: 0.2529\ttrain_acc: 0.9333\tval_loss: 0.4524\tval_acc: 0.8413\n",
      "Epoch 137:\ttrain_loss: 0.2005\ttrain_acc: 0.9667\tval_loss: 0.4213\tval_acc: 0.8571\n",
      "Epoch 138:\ttrain_loss: 0.2303\ttrain_acc: 0.9333\tval_loss: 0.4380\tval_acc: 0.8413\n",
      "Epoch 139:\ttrain_loss: 0.1924\ttrain_acc: 0.9667\tval_loss: 0.4442\tval_acc: 0.8413\n",
      "Epoch 140:\ttrain_loss: 0.2298\ttrain_acc: 0.9333\tval_loss: 0.4802\tval_acc: 0.8095\n",
      "Epoch 141:\ttrain_loss: 0.2274\ttrain_acc: 0.9667\tval_loss: 0.4385\tval_acc: 0.8413\n",
      "Epoch 142:\ttrain_loss: 0.2579\ttrain_acc: 0.9333\tval_loss: 0.4286\tval_acc: 0.8413\n",
      "Epoch 143:\ttrain_loss: 0.2729\ttrain_acc: 0.9000\tval_loss: 0.5224\tval_acc: 0.8095\n",
      "Epoch 144:\ttrain_loss: 0.2371\ttrain_acc: 0.9333\tval_loss: 0.4164\tval_acc: 0.8571\n",
      "Epoch 145:\ttrain_loss: 0.1974\ttrain_acc: 0.9667\tval_loss: 0.4808\tval_acc: 0.8095\n",
      "Epoch 146:\ttrain_loss: 0.2379\ttrain_acc: 0.9667\tval_loss: 0.4520\tval_acc: 0.8254\n",
      "Epoch 147:\ttrain_loss: 0.2052\ttrain_acc: 0.9667\tval_loss: 0.4524\tval_acc: 0.8254\n",
      "Epoch 148:\ttrain_loss: 0.1936\ttrain_acc: 0.9667\tval_loss: 0.4534\tval_acc: 0.8254\n",
      "Epoch 149:\ttrain_loss: 0.1884\ttrain_acc: 0.9667\tval_loss: 0.4530\tval_acc: 0.8413\n",
      "Epoch 150:\ttrain_loss: 0.1861\ttrain_acc: 0.9667\tval_loss: 0.4602\tval_acc: 0.8254\n",
      "Epoch 151:\ttrain_loss: 0.2204\ttrain_acc: 0.9333\tval_loss: 0.4119\tval_acc: 0.8571\n",
      "Epoch 152:\ttrain_loss: 0.2678\ttrain_acc: 0.9333\tval_loss: 0.4551\tval_acc: 0.8413\n",
      "Epoch 153:\ttrain_loss: 0.2769\ttrain_acc: 0.9000\tval_loss: 0.4285\tval_acc: 0.8413\n",
      "Epoch 154:\ttrain_loss: 0.2055\ttrain_acc: 0.9667\tval_loss: 0.4325\tval_acc: 0.8254\n",
      "Epoch 155:\ttrain_loss: 0.2394\ttrain_acc: 0.9333\tval_loss: 0.4446\tval_acc: 0.8413\n",
      "Epoch 156:\ttrain_loss: 0.2002\ttrain_acc: 0.9667\tval_loss: 0.4292\tval_acc: 0.8413\n",
      "Epoch 157:\ttrain_loss: 0.2191\ttrain_acc: 0.9333\tval_loss: 0.4231\tval_acc: 0.8413\n",
      "Epoch 158:\ttrain_loss: 0.2230\ttrain_acc: 0.9333\tval_loss: 0.4471\tval_acc: 0.8254\n",
      "Epoch 159:\ttrain_loss: 0.1958\ttrain_acc: 0.9667\tval_loss: 0.4492\tval_acc: 0.8413\n",
      "Epoch 160:\ttrain_loss: 0.1882\ttrain_acc: 0.9667\tval_loss: 0.4511\tval_acc: 0.8413\n",
      "Epoch 161:\ttrain_loss: 0.1855\ttrain_acc: 0.9667\tval_loss: 0.4520\tval_acc: 0.8413\n",
      "Epoch 162:\ttrain_loss: 0.1843\ttrain_acc: 0.9667\tval_loss: 0.4532\tval_acc: 0.8413\n",
      "Epoch 163:\ttrain_loss: 0.1838\ttrain_acc: 0.9667\tval_loss: 0.4537\tval_acc: 0.8413\n",
      "Epoch 164:\ttrain_loss: 0.1835\ttrain_acc: 0.9667\tval_loss: 0.4542\tval_acc: 0.8413\n",
      "Epoch 165:\ttrain_loss: 0.1834\ttrain_acc: 0.9667\tval_loss: 0.4545\tval_acc: 0.8413\n",
      "Epoch 166:\ttrain_loss: 0.1833\ttrain_acc: 0.9667\tval_loss: 0.4548\tval_acc: 0.8413\n",
      "Epoch 167:\ttrain_loss: 0.1833\ttrain_acc: 0.9667\tval_loss: 0.4551\tval_acc: 0.8413\n",
      "Epoch 168:\ttrain_loss: 0.1833\ttrain_acc: 0.9667\tval_loss: 0.4558\tval_acc: 0.8413\n",
      "Epoch 169:\ttrain_loss: 0.1837\ttrain_acc: 0.9667\tval_loss: 0.5035\tval_acc: 0.8095\n",
      "Epoch 170:\ttrain_loss: 0.2330\ttrain_acc: 0.9333\tval_loss: 0.6036\tval_acc: 0.7778\n",
      "Epoch 171:\ttrain_loss: 0.3473\ttrain_acc: 0.9000\tval_loss: 0.5621\tval_acc: 0.7937\n",
      "Epoch 172:\ttrain_loss: 0.3417\ttrain_acc: 0.9000\tval_loss: 0.5366\tval_acc: 0.7937\n",
      "Epoch 173:\ttrain_loss: 0.3385\ttrain_acc: 0.9000\tval_loss: 0.5090\tval_acc: 0.7937\n",
      "Epoch 174:\ttrain_loss: 0.3349\ttrain_acc: 0.9000\tval_loss: 0.4996\tval_acc: 0.8095\n",
      "Epoch 175:\ttrain_loss: 0.3129\ttrain_acc: 0.9000\tval_loss: 0.4518\tval_acc: 0.8413\n",
      "Epoch 176:\ttrain_loss: 0.2843\ttrain_acc: 0.9333\tval_loss: 0.4399\tval_acc: 0.8413\n",
      "Epoch 177:\ttrain_loss: 0.2740\ttrain_acc: 0.9333\tval_loss: 0.4664\tval_acc: 0.8254\n",
      "Epoch 178:\ttrain_loss: 0.2652\ttrain_acc: 0.9333\tval_loss: 0.4744\tval_acc: 0.8095\n",
      "Epoch 179:\ttrain_loss: 0.2695\ttrain_acc: 0.9333\tval_loss: 0.4955\tval_acc: 0.8095\n",
      "Epoch 180:\ttrain_loss: 0.2505\ttrain_acc: 0.9333\tval_loss: 0.4492\tval_acc: 0.8254\n",
      "Epoch 181:\ttrain_loss: 0.2493\ttrain_acc: 0.9333\tval_loss: 0.4311\tval_acc: 0.8571\n",
      "Epoch 182:\ttrain_loss: 0.2945\ttrain_acc: 0.9333\tval_loss: 0.4510\tval_acc: 0.8254\n",
      "Epoch 183:\ttrain_loss: 0.2157\ttrain_acc: 0.9667\tval_loss: 0.4464\tval_acc: 0.8413\n",
      "Epoch 184:\ttrain_loss: 0.1957\ttrain_acc: 0.9667\tval_loss: 0.4441\tval_acc: 0.8413\n",
      "Epoch 185:\ttrain_loss: 0.1893\ttrain_acc: 0.9667\tval_loss: 0.4477\tval_acc: 0.8413\n",
      "Epoch 186:\ttrain_loss: 0.1864\ttrain_acc: 0.9667\tval_loss: 0.4500\tval_acc: 0.8413\n",
      "Epoch 187:\ttrain_loss: 0.1849\ttrain_acc: 0.9667\tval_loss: 0.4515\tval_acc: 0.8413\n",
      "Epoch 188:\ttrain_loss: 0.1841\ttrain_acc: 0.9667\tval_loss: 0.4524\tval_acc: 0.8413\n",
      "Epoch 189:\ttrain_loss: 0.1837\ttrain_acc: 0.9667\tval_loss: 0.4529\tval_acc: 0.8413\n",
      "Epoch 190:\ttrain_loss: 0.1834\ttrain_acc: 0.9667\tval_loss: 0.4533\tval_acc: 0.8413\n",
      "Epoch 191:\ttrain_loss: 0.1833\ttrain_acc: 0.9667\tval_loss: 0.4538\tval_acc: 0.8413\n",
      "Epoch 192:\ttrain_loss: 0.1833\ttrain_acc: 0.9667\tval_loss: 0.4539\tval_acc: 0.8413\n",
      "Epoch 193:\ttrain_loss: 0.1833\ttrain_acc: 0.9667\tval_loss: 0.4543\tval_acc: 0.8413\n",
      "Epoch 194:\ttrain_loss: 0.1832\ttrain_acc: 0.9667\tval_loss: 0.4547\tval_acc: 0.8413\n",
      "Epoch 195:\ttrain_loss: 0.1832\ttrain_acc: 0.9667\tval_loss: 0.4547\tval_acc: 0.8413\n",
      "Epoch 196:\ttrain_loss: 0.1832\ttrain_acc: 0.9667\tval_loss: 0.4554\tval_acc: 0.8413\n",
      "Epoch 197:\ttrain_loss: 0.1832\ttrain_acc: 0.9667\tval_loss: 0.4511\tval_acc: 0.8413\n",
      "Epoch 198:\ttrain_loss: 0.1833\ttrain_acc: 0.9667\tval_loss: 0.5969\tval_acc: 0.7937\n",
      "Epoch 199:\ttrain_loss: 0.2074\ttrain_acc: 0.9667\tval_loss: 0.4387\tval_acc: 0.8413\n",
      "Epoch 200:\ttrain_loss: 0.1936\ttrain_acc: 0.9667\tval_loss: 0.4400\tval_acc: 0.8413\n",
      "Epoch 201:\ttrain_loss: 0.1883\ttrain_acc: 0.9667\tval_loss: 0.4409\tval_acc: 0.8413\n",
      "Epoch 202:\ttrain_loss: 0.1856\ttrain_acc: 0.9667\tval_loss: 0.4417\tval_acc: 0.8413\n",
      "Epoch 203:\ttrain_loss: 0.1842\ttrain_acc: 0.9667\tval_loss: 0.4422\tval_acc: 0.8413\n",
      "Epoch 204:\ttrain_loss: 0.1836\ttrain_acc: 0.9667\tval_loss: 0.4429\tval_acc: 0.8413\n",
      "Epoch 205:\ttrain_loss: 0.1832\ttrain_acc: 0.9667\tval_loss: 0.4432\tval_acc: 0.8413\n",
      "Epoch 206:\ttrain_loss: 0.1830\ttrain_acc: 0.9667\tval_loss: 0.4433\tval_acc: 0.8413\n",
      "Epoch 207:\ttrain_loss: 0.1829\ttrain_acc: 0.9667\tval_loss: 0.4436\tval_acc: 0.8413\n",
      "Epoch 208:\ttrain_loss: 0.1829\ttrain_acc: 0.9667\tval_loss: 0.4827\tval_acc: 0.8254\n",
      "Epoch 209:\ttrain_loss: 0.1829\ttrain_acc: 0.9667\tval_loss: 0.6301\tval_acc: 0.7778\n",
      "Epoch 210:\ttrain_loss: 0.3098\ttrain_acc: 0.9000\tval_loss: 0.5045\tval_acc: 0.8095\n",
      "Epoch 211:\ttrain_loss: 0.3072\ttrain_acc: 0.9000\tval_loss: 0.5320\tval_acc: 0.7937\n",
      "Epoch 212:\ttrain_loss: 0.2370\ttrain_acc: 0.9333\tval_loss: 0.5490\tval_acc: 0.7937\n",
      "Epoch 213:\ttrain_loss: 0.2356\ttrain_acc: 0.9333\tval_loss: 0.5549\tval_acc: 0.7937\n",
      "Epoch 214:\ttrain_loss: 0.2299\ttrain_acc: 0.9333\tval_loss: 0.5574\tval_acc: 0.7937\n",
      "Epoch 215:\ttrain_loss: 0.2279\ttrain_acc: 0.9333\tval_loss: 0.6032\tval_acc: 0.7778\n",
      "Epoch 216:\ttrain_loss: 0.3114\ttrain_acc: 0.9000\tval_loss: 0.5932\tval_acc: 0.7778\n",
      "Epoch 217:\ttrain_loss: 0.3153\ttrain_acc: 0.9000\tval_loss: 0.4805\tval_acc: 0.8254\n",
      "Epoch 218:\ttrain_loss: 0.2439\ttrain_acc: 0.9333\tval_loss: 0.6391\tval_acc: 0.7619\n",
      "Epoch 219:\ttrain_loss: 0.3157\ttrain_acc: 0.9000\tval_loss: 0.5664\tval_acc: 0.7778\n",
      "Epoch 220:\ttrain_loss: 0.3322\ttrain_acc: 0.9000\tval_loss: 0.5526\tval_acc: 0.7619\n",
      "Epoch 221:\ttrain_loss: 0.3464\ttrain_acc: 0.9000\tval_loss: 0.5487\tval_acc: 0.7619\n",
      "Epoch 222:\ttrain_loss: 0.3529\ttrain_acc: 0.9000\tval_loss: 0.5461\tval_acc: 0.7619\n",
      "Epoch 223:\ttrain_loss: 0.3552\ttrain_acc: 0.9000\tval_loss: 0.5384\tval_acc: 0.7619\n",
      "Epoch 224:\ttrain_loss: 0.3560\ttrain_acc: 0.9000\tval_loss: 0.5286\tval_acc: 0.7778\n",
      "Epoch 225:\ttrain_loss: 0.3563\ttrain_acc: 0.9000\tval_loss: 0.4399\tval_acc: 0.8413\n",
      "Epoch 226:\ttrain_loss: 0.2292\ttrain_acc: 0.9667\tval_loss: 0.4402\tval_acc: 0.8413\n",
      "Epoch 227:\ttrain_loss: 0.2019\ttrain_acc: 0.9667\tval_loss: 0.4448\tval_acc: 0.8413\n",
      "Epoch 228:\ttrain_loss: 0.1918\ttrain_acc: 0.9667\tval_loss: 0.4484\tval_acc: 0.8413\n",
      "Epoch 229:\ttrain_loss: 0.1875\ttrain_acc: 0.9667\tval_loss: 0.4510\tval_acc: 0.8413\n",
      "Epoch 230:\ttrain_loss: 0.1856\ttrain_acc: 0.9667\tval_loss: 0.4527\tval_acc: 0.8413\n",
      "Epoch 231:\ttrain_loss: 0.1847\ttrain_acc: 0.9667\tval_loss: 0.4540\tval_acc: 0.8413\n",
      "Epoch 232:\ttrain_loss: 0.1842\ttrain_acc: 0.9667\tval_loss: 0.4549\tval_acc: 0.8413\n",
      "Epoch 233:\ttrain_loss: 0.1840\ttrain_acc: 0.9667\tval_loss: 0.4570\tval_acc: 0.8413\n",
      "Epoch 234:\ttrain_loss: 0.1838\ttrain_acc: 0.9667\tval_loss: 0.4774\tval_acc: 0.8254\n",
      "Epoch 235:\ttrain_loss: 0.1837\ttrain_acc: 0.9667\tval_loss: 0.4829\tval_acc: 0.8254\n",
      "Epoch 236:\ttrain_loss: 0.1836\ttrain_acc: 0.9667\tval_loss: 0.4843\tval_acc: 0.8254\n",
      "Epoch 237:\ttrain_loss: 0.1834\ttrain_acc: 0.9667\tval_loss: 0.4848\tval_acc: 0.8254\n",
      "Epoch 238:\ttrain_loss: 0.1833\ttrain_acc: 0.9667\tval_loss: 0.4850\tval_acc: 0.8254\n",
      "Epoch 239:\ttrain_loss: 0.1832\ttrain_acc: 0.9667\tval_loss: 0.4736\tval_acc: 0.8254\n",
      "Epoch 240:\ttrain_loss: 0.1832\ttrain_acc: 0.9667\tval_loss: 0.4850\tval_acc: 0.8095\n",
      "Epoch 241:\ttrain_loss: 0.3179\ttrain_acc: 0.9000\tval_loss: 0.5288\tval_acc: 0.7937\n",
      "Epoch 242:\ttrain_loss: 0.2325\ttrain_acc: 0.9333\tval_loss: 0.5292\tval_acc: 0.7937\n",
      "Epoch 243:\ttrain_loss: 0.2325\ttrain_acc: 0.9333\tval_loss: 0.5310\tval_acc: 0.7937\n",
      "Epoch 244:\ttrain_loss: 0.2296\ttrain_acc: 0.9333\tval_loss: 0.5317\tval_acc: 0.7937\n",
      "Epoch 245:\ttrain_loss: 0.2286\ttrain_acc: 0.9333\tval_loss: 0.5321\tval_acc: 0.7937\n",
      "Epoch 246:\ttrain_loss: 0.2282\ttrain_acc: 0.9333\tval_loss: 0.5326\tval_acc: 0.7937\n",
      "Epoch 247:\ttrain_loss: 0.2278\ttrain_acc: 0.9333\tval_loss: 0.5330\tval_acc: 0.7937\n",
      "Epoch 248:\ttrain_loss: 0.2273\ttrain_acc: 0.9333\tval_loss: 0.5332\tval_acc: 0.7937\n",
      "Epoch 249:\ttrain_loss: 0.2270\ttrain_acc: 0.9333\tval_loss: 0.5093\tval_acc: 0.8095\n",
      "Epoch 250:\ttrain_loss: 0.2267\ttrain_acc: 0.9333\tval_loss: 0.4855\tval_acc: 0.8254\n",
      "Epoch 251:\ttrain_loss: 0.2222\ttrain_acc: 0.9333\tval_loss: 0.4614\tval_acc: 0.8413\n",
      "Epoch 252:\ttrain_loss: 0.2035\ttrain_acc: 0.9667\tval_loss: 0.6579\tval_acc: 0.7778\n",
      "Epoch 253:\ttrain_loss: 0.3096\ttrain_acc: 0.9000\tval_loss: 0.5894\tval_acc: 0.7778\n",
      "Epoch 254:\ttrain_loss: 0.3255\ttrain_acc: 0.9000\tval_loss: 0.5516\tval_acc: 0.7778\n",
      "Epoch 255:\ttrain_loss: 0.3455\ttrain_acc: 0.9000\tval_loss: 0.5333\tval_acc: 0.7778\n",
      "Epoch 256:\ttrain_loss: 0.3589\ttrain_acc: 0.9000\tval_loss: 0.5255\tval_acc: 0.7778\n",
      "Epoch 257:\ttrain_loss: 0.3651\ttrain_acc: 0.9000\tval_loss: 0.5222\tval_acc: 0.7778\n",
      "Epoch 258:\ttrain_loss: 0.3674\ttrain_acc: 0.9000\tval_loss: 0.5208\tval_acc: 0.7778\n",
      "Epoch 259:\ttrain_loss: 0.3426\ttrain_acc: 0.9000\tval_loss: 0.4905\tval_acc: 0.8095\n",
      "Epoch 260:\ttrain_loss: 0.2233\ttrain_acc: 0.9667\tval_loss: 0.4578\tval_acc: 0.8254\n",
      "Epoch 261:\ttrain_loss: 0.3117\ttrain_acc: 0.9000\tval_loss: 0.5176\tval_acc: 0.8095\n",
      "Epoch 262:\ttrain_loss: 0.3205\ttrain_acc: 0.9000\tval_loss: 0.5014\tval_acc: 0.8095\n",
      "Epoch 263:\ttrain_loss: 0.2634\ttrain_acc: 0.9333\tval_loss: 0.4534\tval_acc: 0.8413\n",
      "Epoch 264:\ttrain_loss: 0.2532\ttrain_acc: 0.9333\tval_loss: 0.4960\tval_acc: 0.8254\n",
      "Epoch 265:\ttrain_loss: 0.2085\ttrain_acc: 0.9667\tval_loss: 0.4977\tval_acc: 0.8254\n",
      "Epoch 266:\ttrain_loss: 0.2002\ttrain_acc: 0.9667\tval_loss: 0.4990\tval_acc: 0.8254\n",
      "Epoch 267:\ttrain_loss: 0.1964\ttrain_acc: 0.9667\tval_loss: 0.4998\tval_acc: 0.8254\n",
      "Epoch 268:\ttrain_loss: 0.1944\ttrain_acc: 0.9667\tval_loss: 0.5005\tval_acc: 0.8254\n",
      "Epoch 269:\ttrain_loss: 0.1933\ttrain_acc: 0.9667\tval_loss: 0.5011\tval_acc: 0.8254\n",
      "Epoch 270:\ttrain_loss: 0.1926\ttrain_acc: 0.9667\tval_loss: 0.5015\tval_acc: 0.8254\n",
      "Epoch 271:\ttrain_loss: 0.1921\ttrain_acc: 0.9667\tval_loss: 0.5019\tval_acc: 0.8254\n",
      "Epoch 272:\ttrain_loss: 0.1917\ttrain_acc: 0.9667\tval_loss: 0.5022\tval_acc: 0.8254\n",
      "Epoch 273:\ttrain_loss: 0.1914\ttrain_acc: 0.9667\tval_loss: 0.5026\tval_acc: 0.8254\n",
      "Epoch 274:\ttrain_loss: 0.1911\ttrain_acc: 0.9667\tval_loss: 0.5030\tval_acc: 0.8254\n",
      "Epoch 275:\ttrain_loss: 0.1909\ttrain_acc: 0.9667\tval_loss: 0.5033\tval_acc: 0.8254\n",
      "Epoch 276:\ttrain_loss: 0.1908\ttrain_acc: 0.9667\tval_loss: 0.5034\tval_acc: 0.8254\n",
      "Epoch 277:\ttrain_loss: 0.1907\ttrain_acc: 0.9667\tval_loss: 0.5015\tval_acc: 0.8254\n",
      "Epoch 278:\ttrain_loss: 0.1905\ttrain_acc: 0.9667\tval_loss: 0.4948\tval_acc: 0.8254\n",
      "Epoch 279:\ttrain_loss: 0.1905\ttrain_acc: 0.9667\tval_loss: 0.4951\tval_acc: 0.8254\n",
      "Epoch 280:\ttrain_loss: 0.1904\ttrain_acc: 0.9667\tval_loss: 0.4918\tval_acc: 0.8254\n",
      "Epoch 281:\ttrain_loss: 0.1904\ttrain_acc: 0.9667\tval_loss: 0.4596\tval_acc: 0.8413\n",
      "Epoch 282:\ttrain_loss: 0.1904\ttrain_acc: 0.9667\tval_loss: 0.4579\tval_acc: 0.8413\n",
      "Epoch 283:\ttrain_loss: 0.1904\ttrain_acc: 0.9667\tval_loss: 0.4578\tval_acc: 0.8413\n",
      "Epoch 284:\ttrain_loss: 0.1903\ttrain_acc: 0.9667\tval_loss: 0.3453\tval_acc: 0.8889\n",
      "Epoch 285:\ttrain_loss: 0.1903\ttrain_acc: 0.9667\tval_loss: 0.4317\tval_acc: 0.8413\n",
      "Epoch 286:\ttrain_loss: 0.2292\ttrain_acc: 0.9333\tval_loss: 0.4701\tval_acc: 0.8254\n",
      "Epoch 287:\ttrain_loss: 0.2287\ttrain_acc: 0.9333\tval_loss: 0.4796\tval_acc: 0.8254\n",
      "Epoch 288:\ttrain_loss: 0.2068\ttrain_acc: 0.9667\tval_loss: 0.5397\tval_acc: 0.7778\n",
      "Epoch 289:\ttrain_loss: 0.4583\ttrain_acc: 0.8000\tval_loss: 0.5322\tval_acc: 0.7778\n",
      "Epoch 290:\ttrain_loss: 0.4313\ttrain_acc: 0.8000\tval_loss: 0.5449\tval_acc: 0.7778\n",
      "Epoch 291:\ttrain_loss: 0.4233\ttrain_acc: 0.8000\tval_loss: 0.5508\tval_acc: 0.7778\n",
      "Epoch 292:\ttrain_loss: 0.4185\ttrain_acc: 0.8000\tval_loss: 0.5531\tval_acc: 0.7778\n",
      "Epoch 293:\ttrain_loss: 0.4149\ttrain_acc: 0.8000\tval_loss: 0.4712\tval_acc: 0.8413\n",
      "Epoch 294:\ttrain_loss: 0.2782\ttrain_acc: 0.9667\tval_loss: 0.5013\tval_acc: 0.8254\n",
      "Epoch 295:\ttrain_loss: 0.2529\ttrain_acc: 0.9667\tval_loss: 0.4581\tval_acc: 0.8413\n",
      "Epoch 296:\ttrain_loss: 0.2352\ttrain_acc: 0.9667\tval_loss: 0.4546\tval_acc: 0.8413\n",
      "Epoch 297:\ttrain_loss: 0.2288\ttrain_acc: 0.9667\tval_loss: 0.4529\tval_acc: 0.8413\n",
      "Epoch 298:\ttrain_loss: 0.2260\ttrain_acc: 0.9667\tval_loss: 0.5584\tval_acc: 0.7937\n",
      "Epoch 299:\ttrain_loss: 0.3651\ttrain_acc: 0.8667\tval_loss: 0.5198\tval_acc: 0.7937\n",
      "Epoch 300:\ttrain_loss: 0.2836\ttrain_acc: 0.9333\tval_loss: 0.4812\tval_acc: 0.8095\n",
      "Epoch 301:\ttrain_loss: 0.2738\ttrain_acc: 0.9667\tval_loss: 0.5481\tval_acc: 0.7937\n",
      "Epoch 302:\ttrain_loss: 0.2312\ttrain_acc: 0.9667\tval_loss: 0.5567\tval_acc: 0.7937\n",
      "Epoch 303:\ttrain_loss: 0.2057\ttrain_acc: 0.9667\tval_loss: 0.5650\tval_acc: 0.7937\n",
      "Epoch 304:\ttrain_loss: 0.1937\ttrain_acc: 0.9667\tval_loss: 0.5708\tval_acc: 0.7778\n",
      "Epoch 305:\ttrain_loss: 0.1884\ttrain_acc: 0.9667\tval_loss: 0.5752\tval_acc: 0.7778\n",
      "Epoch 306:\ttrain_loss: 0.1861\ttrain_acc: 0.9667\tval_loss: 0.5799\tval_acc: 0.7778\n",
      "Epoch 307:\ttrain_loss: 0.1851\ttrain_acc: 0.9667\tval_loss: 0.5851\tval_acc: 0.7778\n",
      "Epoch 308:\ttrain_loss: 0.1846\ttrain_acc: 0.9667\tval_loss: 0.5896\tval_acc: 0.7778\n",
      "Epoch 309:\ttrain_loss: 0.1843\ttrain_acc: 0.9667\tval_loss: 0.5922\tval_acc: 0.7778\n",
      "Epoch 310:\ttrain_loss: 0.1842\ttrain_acc: 0.9667\tval_loss: 0.5936\tval_acc: 0.7778\n",
      "Epoch 311:\ttrain_loss: 0.1841\ttrain_acc: 0.9667\tval_loss: 0.5938\tval_acc: 0.7778\n",
      "Epoch 312:\ttrain_loss: 0.1841\ttrain_acc: 0.9667\tval_loss: 0.5926\tval_acc: 0.7778\n",
      "Epoch 313:\ttrain_loss: 0.1840\ttrain_acc: 0.9667\tval_loss: 0.5725\tval_acc: 0.7778\n",
      "Epoch 314:\ttrain_loss: 0.1839\ttrain_acc: 0.9667\tval_loss: 0.5550\tval_acc: 0.7937\n",
      "Epoch 315:\ttrain_loss: 0.1839\ttrain_acc: 0.9667\tval_loss: 0.5543\tval_acc: 0.7937\n",
      "Epoch 316:\ttrain_loss: 0.1839\ttrain_acc: 0.9667\tval_loss: 0.5547\tval_acc: 0.7937\n",
      "Epoch 317:\ttrain_loss: 0.1838\ttrain_acc: 0.9667\tval_loss: 0.5545\tval_acc: 0.7937\n",
      "Epoch 318:\ttrain_loss: 0.1838\ttrain_acc: 0.9667\tval_loss: 0.5548\tval_acc: 0.7937\n",
      "Epoch 319:\ttrain_loss: 0.1837\ttrain_acc: 0.9667\tval_loss: 0.5547\tval_acc: 0.7937\n",
      "Epoch 320:\ttrain_loss: 0.1837\ttrain_acc: 0.9667\tval_loss: 0.5548\tval_acc: 0.7937\n",
      "Epoch 321:\ttrain_loss: 0.1837\ttrain_acc: 0.9667\tval_loss: 0.5442\tval_acc: 0.8095\n",
      "Epoch 322:\ttrain_loss: 0.2227\ttrain_acc: 0.9333\tval_loss: 0.5256\tval_acc: 0.7778\n",
      "Epoch 323:\ttrain_loss: 0.4275\ttrain_acc: 0.8333\tval_loss: 0.5024\tval_acc: 0.7937\n",
      "Epoch 324:\ttrain_loss: 0.2971\ttrain_acc: 0.9667\tval_loss: 0.4794\tval_acc: 0.8095\n",
      "Epoch 325:\ttrain_loss: 0.3753\ttrain_acc: 0.8667\tval_loss: 0.4810\tval_acc: 0.8095\n",
      "Epoch 326:\ttrain_loss: 0.3726\ttrain_acc: 0.8667\tval_loss: 0.4975\tval_acc: 0.8095\n",
      "Epoch 327:\ttrain_loss: 0.2846\ttrain_acc: 0.9000\tval_loss: 0.6703\tval_acc: 0.7619\n",
      "Epoch 328:\ttrain_loss: 0.3092\ttrain_acc: 0.9333\tval_loss: 0.6308\tval_acc: 0.7619\n",
      "Epoch 329:\ttrain_loss: 0.2682\ttrain_acc: 0.9333\tval_loss: 0.3874\tval_acc: 0.8730\n",
      "Epoch 330:\ttrain_loss: 0.2106\ttrain_acc: 0.9667\tval_loss: 0.3859\tval_acc: 0.8730\n",
      "Epoch 331:\ttrain_loss: 0.2005\ttrain_acc: 0.9667\tval_loss: 0.3859\tval_acc: 0.8730\n",
      "Epoch 332:\ttrain_loss: 0.1961\ttrain_acc: 0.9667\tval_loss: 0.3861\tval_acc: 0.8730\n",
      "Epoch 333:\ttrain_loss: 0.1941\ttrain_acc: 0.9667\tval_loss: 0.3863\tval_acc: 0.8730\n",
      "Epoch 334:\ttrain_loss: 0.1933\ttrain_acc: 0.9667\tval_loss: 0.3865\tval_acc: 0.8730\n",
      "Epoch 335:\ttrain_loss: 0.1928\ttrain_acc: 0.9667\tval_loss: 0.3867\tval_acc: 0.8730\n",
      "Epoch 336:\ttrain_loss: 0.1926\ttrain_acc: 0.9667\tval_loss: 0.3868\tval_acc: 0.8730\n",
      "Epoch 337:\ttrain_loss: 0.1925\ttrain_acc: 0.9667\tval_loss: 0.3870\tval_acc: 0.8730\n",
      "Epoch 338:\ttrain_loss: 0.1925\ttrain_acc: 0.9667\tval_loss: 0.3870\tval_acc: 0.8730\n",
      "Epoch 339:\ttrain_loss: 0.1925\ttrain_acc: 0.9667\tval_loss: 0.3871\tval_acc: 0.8730\n",
      "Epoch 340:\ttrain_loss: 0.1926\ttrain_acc: 0.9667\tval_loss: 0.3872\tval_acc: 0.8730\n",
      "Epoch 341:\ttrain_loss: 0.1926\ttrain_acc: 0.9667\tval_loss: 0.4028\tval_acc: 0.8730\n",
      "Epoch 342:\ttrain_loss: 0.1878\ttrain_acc: 0.9667\tval_loss: 0.4395\tval_acc: 0.8571\n",
      "Epoch 343:\ttrain_loss: 0.1950\ttrain_acc: 0.9667\tval_loss: 0.4020\tval_acc: 0.8571\n",
      "Epoch 344:\ttrain_loss: 0.2595\ttrain_acc: 0.9333\tval_loss: 0.4017\tval_acc: 0.8571\n",
      "Epoch 345:\ttrain_loss: 0.2563\ttrain_acc: 0.9333\tval_loss: 0.4016\tval_acc: 0.8571\n",
      "Epoch 346:\ttrain_loss: 0.2549\ttrain_acc: 0.9333\tval_loss: 0.4016\tval_acc: 0.8571\n",
      "Epoch 347:\ttrain_loss: 0.2542\ttrain_acc: 0.9333\tval_loss: 0.4016\tval_acc: 0.8571\n",
      "Epoch 348:\ttrain_loss: 0.2540\ttrain_acc: 0.9333\tval_loss: 0.4016\tval_acc: 0.8571\n",
      "Epoch 349:\ttrain_loss: 0.2539\ttrain_acc: 0.9333\tval_loss: 0.4016\tval_acc: 0.8571\n",
      "Epoch 350:\ttrain_loss: 0.2538\ttrain_acc: 0.9333\tval_loss: 0.4016\tval_acc: 0.8571\n",
      "Epoch 351:\ttrain_loss: 0.2538\ttrain_acc: 0.9333\tval_loss: 0.4016\tval_acc: 0.8571\n",
      "Epoch 352:\ttrain_loss: 0.2539\ttrain_acc: 0.9333\tval_loss: 0.4016\tval_acc: 0.8571\n",
      "Epoch 353:\ttrain_loss: 0.2538\ttrain_acc: 0.9333\tval_loss: 0.4148\tval_acc: 0.8571\n",
      "Epoch 354:\ttrain_loss: 0.1940\ttrain_acc: 0.9667\tval_loss: 0.5359\tval_acc: 0.8254\n",
      "Epoch 355:\ttrain_loss: 0.2861\ttrain_acc: 0.9333\tval_loss: 0.4885\tval_acc: 0.8095\n",
      "Epoch 356:\ttrain_loss: 0.2690\ttrain_acc: 0.9333\tval_loss: 0.4910\tval_acc: 0.8095\n",
      "Epoch 357:\ttrain_loss: 0.2674\ttrain_acc: 0.9333\tval_loss: 0.4920\tval_acc: 0.8095\n",
      "Epoch 358:\ttrain_loss: 0.2674\ttrain_acc: 0.9333\tval_loss: 0.4924\tval_acc: 0.8095\n",
      "Epoch 359:\ttrain_loss: 0.2095\ttrain_acc: 0.9667\tval_loss: 0.4680\tval_acc: 0.8254\n",
      "Epoch 360:\ttrain_loss: 0.2815\ttrain_acc: 0.9000\tval_loss: 0.5856\tval_acc: 0.7937\n",
      "Epoch 361:\ttrain_loss: 0.3707\ttrain_acc: 0.9000\tval_loss: 0.5549\tval_acc: 0.7937\n",
      "Epoch 362:\ttrain_loss: 0.3635\ttrain_acc: 0.9000\tval_loss: 0.5410\tval_acc: 0.7937\n",
      "Epoch 363:\ttrain_loss: 0.3551\ttrain_acc: 0.9000\tval_loss: 0.5482\tval_acc: 0.7778\n",
      "Epoch 364:\ttrain_loss: 0.3500\ttrain_acc: 0.9000\tval_loss: 0.6892\tval_acc: 0.6984\n",
      "Epoch 365:\ttrain_loss: 0.4537\ttrain_acc: 0.8333\tval_loss: 0.5407\tval_acc: 0.7460\n",
      "Epoch 366:\ttrain_loss: 0.4726\ttrain_acc: 0.8400\tval_loss: 0.5203\tval_acc: 0.7778\n",
      "Epoch 367:\ttrain_loss: 0.3793\ttrain_acc: 0.9000\tval_loss: 0.5251\tval_acc: 0.7778\n",
      "Epoch 368:\ttrain_loss: 0.3911\ttrain_acc: 0.8667\tval_loss: 0.4657\tval_acc: 0.8254\n",
      "Epoch 369:\ttrain_loss: 0.2218\ttrain_acc: 0.9667\tval_loss: 0.4705\tval_acc: 0.8254\n",
      "Epoch 370:\ttrain_loss: 0.1976\ttrain_acc: 0.9667\tval_loss: 0.4690\tval_acc: 0.8254\n",
      "Epoch 371:\ttrain_loss: 0.1889\ttrain_acc: 0.9667\tval_loss: 0.4612\tval_acc: 0.8254\n",
      "Epoch 372:\ttrain_loss: 0.1853\ttrain_acc: 0.9667\tval_loss: 0.4625\tval_acc: 0.8413\n",
      "Epoch 373:\ttrain_loss: 0.1839\ttrain_acc: 0.9667\tval_loss: 0.4767\tval_acc: 0.8254\n",
      "Epoch 374:\ttrain_loss: 0.1833\ttrain_acc: 0.9667\tval_loss: 0.4798\tval_acc: 0.8254\n",
      "Epoch 375:\ttrain_loss: 0.1832\ttrain_acc: 0.9667\tval_loss: 0.4818\tval_acc: 0.8254\n",
      "Epoch 376:\ttrain_loss: 0.1831\ttrain_acc: 0.9667\tval_loss: 0.4830\tval_acc: 0.8254\n",
      "Epoch 377:\ttrain_loss: 0.1830\ttrain_acc: 0.9667\tval_loss: 0.4838\tval_acc: 0.8254\n",
      "Epoch 378:\ttrain_loss: 0.1830\ttrain_acc: 0.9667\tval_loss: 0.4844\tval_acc: 0.8254\n",
      "Epoch 379:\ttrain_loss: 0.1830\ttrain_acc: 0.9667\tval_loss: 0.4846\tval_acc: 0.8254\n",
      "Epoch 380:\ttrain_loss: 0.1829\ttrain_acc: 0.9667\tval_loss: 0.4848\tval_acc: 0.8254\n",
      "Epoch 381:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.4847\tval_acc: 0.8254\n",
      "Epoch 382:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.4845\tval_acc: 0.8254\n",
      "Epoch 383:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.4839\tval_acc: 0.8254\n",
      "Epoch 384:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.4796\tval_acc: 0.8254\n",
      "Epoch 385:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.4745\tval_acc: 0.8254\n",
      "Epoch 386:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.4592\tval_acc: 0.8413\n",
      "Epoch 387:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.4593\tval_acc: 0.8413\n",
      "Epoch 388:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.4674\tval_acc: 0.8413\n",
      "Epoch 389:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.4852\tval_acc: 0.8254\n",
      "Epoch 390:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.4577\tval_acc: 0.8413\n",
      "Epoch 391:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.4871\tval_acc: 0.8254\n",
      "Epoch 392:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5128\tval_acc: 0.8254\n",
      "Epoch 393:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5079\tval_acc: 0.7937\n",
      "Epoch 394:\ttrain_loss: 0.2212\ttrain_acc: 0.9667\tval_loss: 0.4530\tval_acc: 0.8413\n",
      "Epoch 395:\ttrain_loss: 0.2030\ttrain_acc: 0.9667\tval_loss: 0.4545\tval_acc: 0.8413\n",
      "Epoch 396:\ttrain_loss: 0.1935\ttrain_acc: 0.9667\tval_loss: 0.4557\tval_acc: 0.8413\n",
      "Epoch 397:\ttrain_loss: 0.1885\ttrain_acc: 0.9667\tval_loss: 0.4564\tval_acc: 0.8413\n",
      "Epoch 398:\ttrain_loss: 0.1859\ttrain_acc: 0.9667\tval_loss: 0.4569\tval_acc: 0.8413\n",
      "Epoch 399:\ttrain_loss: 0.1845\ttrain_acc: 0.9667\tval_loss: 0.4570\tval_acc: 0.8413\n",
      "Epoch 400:\ttrain_loss: 0.1838\ttrain_acc: 0.9667\tval_loss: 0.4573\tval_acc: 0.8413\n",
      "Epoch 401:\ttrain_loss: 0.1834\ttrain_acc: 0.9667\tval_loss: 0.4571\tval_acc: 0.8413\n",
      "Epoch 402:\ttrain_loss: 0.1833\ttrain_acc: 0.9667\tval_loss: 0.4572\tval_acc: 0.8413\n",
      "Epoch 403:\ttrain_loss: 0.1831\ttrain_acc: 0.9667\tval_loss: 0.4574\tval_acc: 0.8413\n",
      "Epoch 404:\ttrain_loss: 0.1830\ttrain_acc: 0.9667\tval_loss: 0.4573\tval_acc: 0.8413\n",
      "Epoch 405:\ttrain_loss: 0.1830\ttrain_acc: 0.9667\tval_loss: 0.4571\tval_acc: 0.8413\n",
      "Epoch 406:\ttrain_loss: 0.1830\ttrain_acc: 0.9667\tval_loss: 0.4567\tval_acc: 0.8413\n",
      "Epoch 407:\ttrain_loss: 0.1830\ttrain_acc: 0.9667\tval_loss: 0.4571\tval_acc: 0.8413\n",
      "Epoch 408:\ttrain_loss: 0.1829\ttrain_acc: 0.9667\tval_loss: 0.4575\tval_acc: 0.8413\n",
      "Epoch 409:\ttrain_loss: 0.1829\ttrain_acc: 0.9667\tval_loss: 0.4539\tval_acc: 0.8413\n",
      "Epoch 410:\ttrain_loss: 0.1829\ttrain_acc: 0.9667\tval_loss: 0.4443\tval_acc: 0.8413\n",
      "Epoch 411:\ttrain_loss: 0.1829\ttrain_acc: 0.9667\tval_loss: 0.5287\tval_acc: 0.8095\n",
      "Epoch 412:\ttrain_loss: 0.1829\ttrain_acc: 0.9667\tval_loss: 0.5167\tval_acc: 0.8095\n",
      "Epoch 413:\ttrain_loss: 0.1951\ttrain_acc: 0.9667\tval_loss: 0.5209\tval_acc: 0.8095\n",
      "Epoch 414:\ttrain_loss: 0.1894\ttrain_acc: 0.9667\tval_loss: 0.4948\tval_acc: 0.8254\n",
      "Epoch 415:\ttrain_loss: 0.1862\ttrain_acc: 0.9667\tval_loss: 0.4962\tval_acc: 0.8254\n",
      "Epoch 416:\ttrain_loss: 0.1844\ttrain_acc: 0.9667\tval_loss: 0.4966\tval_acc: 0.8254\n",
      "Epoch 417:\ttrain_loss: 0.1834\ttrain_acc: 0.9667\tval_loss: 0.4972\tval_acc: 0.8254\n",
      "Epoch 418:\ttrain_loss: 0.1830\ttrain_acc: 0.9667\tval_loss: 0.4980\tval_acc: 0.8254\n",
      "Epoch 419:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.5190\tval_acc: 0.8095\n",
      "Epoch 420:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.4499\tval_acc: 0.8413\n",
      "Epoch 421:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.4532\tval_acc: 0.8254\n",
      "Epoch 422:\ttrain_loss: 0.1825\ttrain_acc: 0.9667\tval_loss: 0.4300\tval_acc: 0.8413\n",
      "Epoch 423:\ttrain_loss: 0.2525\ttrain_acc: 0.9333\tval_loss: 0.4916\tval_acc: 0.8095\n",
      "Epoch 424:\ttrain_loss: 0.1984\ttrain_acc: 0.9667\tval_loss: 0.5082\tval_acc: 0.8254\n",
      "Epoch 425:\ttrain_loss: 0.2018\ttrain_acc: 0.9667\tval_loss: 0.5043\tval_acc: 0.8254\n",
      "Epoch 426:\ttrain_loss: 0.2031\ttrain_acc: 0.9667\tval_loss: 0.5014\tval_acc: 0.8254\n",
      "Epoch 427:\ttrain_loss: 0.2035\ttrain_acc: 0.9667\tval_loss: 0.4997\tval_acc: 0.8254\n",
      "Epoch 428:\ttrain_loss: 0.2032\ttrain_acc: 0.9667\tval_loss: 0.4983\tval_acc: 0.8254\n",
      "Epoch 429:\ttrain_loss: 0.2028\ttrain_acc: 0.9667\tval_loss: 0.4970\tval_acc: 0.8254\n",
      "Epoch 430:\ttrain_loss: 0.2023\ttrain_acc: 0.9667\tval_loss: 0.4963\tval_acc: 0.8254\n",
      "Epoch 431:\ttrain_loss: 0.2020\ttrain_acc: 0.9667\tval_loss: 0.4955\tval_acc: 0.8254\n",
      "Epoch 432:\ttrain_loss: 0.2017\ttrain_acc: 0.9667\tval_loss: 0.4950\tval_acc: 0.8254\n",
      "Epoch 433:\ttrain_loss: 0.2014\ttrain_acc: 0.9667\tval_loss: 0.4111\tval_acc: 0.8571\n",
      "Epoch 434:\ttrain_loss: 0.1902\ttrain_acc: 0.9667\tval_loss: 0.4123\tval_acc: 0.8571\n",
      "Epoch 435:\ttrain_loss: 0.1858\ttrain_acc: 0.9667\tval_loss: 0.4131\tval_acc: 0.8571\n",
      "Epoch 436:\ttrain_loss: 0.1837\ttrain_acc: 0.9667\tval_loss: 0.4135\tval_acc: 0.8571\n",
      "Epoch 437:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.4139\tval_acc: 0.8571\n",
      "Epoch 438:\ttrain_loss: 0.1822\ttrain_acc: 0.9667\tval_loss: 0.4143\tval_acc: 0.8571\n",
      "Epoch 439:\ttrain_loss: 0.1819\ttrain_acc: 0.9667\tval_loss: 0.4145\tval_acc: 0.8571\n",
      "Epoch 440:\ttrain_loss: 0.1819\ttrain_acc: 0.9667\tval_loss: 0.4146\tval_acc: 0.8571\n",
      "Epoch 441:\ttrain_loss: 0.1819\ttrain_acc: 0.9667\tval_loss: 0.4149\tval_acc: 0.8571\n",
      "Epoch 442:\ttrain_loss: 0.1819\ttrain_acc: 0.9667\tval_loss: 0.4157\tval_acc: 0.8571\n",
      "Epoch 443:\ttrain_loss: 0.1820\ttrain_acc: 0.9667\tval_loss: 0.4737\tval_acc: 0.8254\n",
      "Epoch 444:\ttrain_loss: 0.1821\ttrain_acc: 0.9667\tval_loss: 0.5091\tval_acc: 0.8254\n",
      "Epoch 445:\ttrain_loss: 0.2234\ttrain_acc: 0.9333\tval_loss: 0.4342\tval_acc: 0.8571\n",
      "Epoch 446:\ttrain_loss: 0.2316\ttrain_acc: 0.9333\tval_loss: 0.4294\tval_acc: 0.8571\n",
      "Epoch 447:\ttrain_loss: 0.2384\ttrain_acc: 0.9333\tval_loss: 0.4261\tval_acc: 0.8571\n",
      "Epoch 448:\ttrain_loss: 0.2437\ttrain_acc: 0.9333\tval_loss: 0.4236\tval_acc: 0.8571\n",
      "Epoch 449:\ttrain_loss: 0.2474\ttrain_acc: 0.9333\tval_loss: 0.4221\tval_acc: 0.8571\n",
      "Epoch 450:\ttrain_loss: 0.2017\ttrain_acc: 0.9667\tval_loss: 0.5422\tval_acc: 0.7619\n",
      "Epoch 451:\ttrain_loss: 0.4785\ttrain_acc: 0.8000\tval_loss: 0.5053\tval_acc: 0.7937\n",
      "Epoch 452:\ttrain_loss: 0.3836\ttrain_acc: 0.9000\tval_loss: 0.5681\tval_acc: 0.7302\n",
      "Epoch 453:\ttrain_loss: 0.5225\ttrain_acc: 0.7667\tval_loss: 0.5704\tval_acc: 0.7937\n",
      "Epoch 454:\ttrain_loss: 0.4413\ttrain_acc: 0.8000\tval_loss: 0.5474\tval_acc: 0.7937\n",
      "Epoch 455:\ttrain_loss: 0.4395\ttrain_acc: 0.8000\tval_loss: 0.5428\tval_acc: 0.7937\n",
      "Epoch 456:\ttrain_loss: 0.4052\ttrain_acc: 0.8667\tval_loss: 0.5181\tval_acc: 0.8413\n",
      "Epoch 457:\ttrain_loss: 0.3270\ttrain_acc: 0.9333\tval_loss: 0.4696\tval_acc: 0.8254\n",
      "Epoch 458:\ttrain_loss: 0.2919\ttrain_acc: 0.9000\tval_loss: 0.4863\tval_acc: 0.8413\n",
      "Epoch 459:\ttrain_loss: 0.3093\ttrain_acc: 0.9333\tval_loss: 0.6150\tval_acc: 0.7778\n",
      "Epoch 460:\ttrain_loss: 0.3516\ttrain_acc: 0.9000\tval_loss: 0.5485\tval_acc: 0.7937\n",
      "Epoch 461:\ttrain_loss: 0.3426\ttrain_acc: 0.9000\tval_loss: 0.5396\tval_acc: 0.7937\n",
      "Epoch 462:\ttrain_loss: 0.3381\ttrain_acc: 0.9000\tval_loss: 0.5337\tval_acc: 0.7937\n",
      "Epoch 463:\ttrain_loss: 0.3357\ttrain_acc: 0.9000\tval_loss: 0.5309\tval_acc: 0.7937\n",
      "Epoch 464:\ttrain_loss: 0.3346\ttrain_acc: 0.9000\tval_loss: 0.5298\tval_acc: 0.7937\n",
      "Epoch 465:\ttrain_loss: 0.3340\ttrain_acc: 0.9000\tval_loss: 0.5293\tval_acc: 0.7937\n",
      "Epoch 466:\ttrain_loss: 0.3336\ttrain_acc: 0.9000\tval_loss: 0.5290\tval_acc: 0.7937\n",
      "Epoch 467:\ttrain_loss: 0.3334\ttrain_acc: 0.9000\tval_loss: 0.4901\tval_acc: 0.8095\n",
      "Epoch 468:\ttrain_loss: 0.2655\ttrain_acc: 0.9333\tval_loss: 0.5263\tval_acc: 0.7937\n",
      "Epoch 469:\ttrain_loss: 0.2826\ttrain_acc: 0.9333\tval_loss: 0.5202\tval_acc: 0.7937\n",
      "Epoch 470:\ttrain_loss: 0.2842\ttrain_acc: 0.9333\tval_loss: 0.5179\tval_acc: 0.7937\n",
      "Epoch 471:\ttrain_loss: 0.2846\ttrain_acc: 0.9333\tval_loss: 0.4961\tval_acc: 0.8095\n",
      "Epoch 472:\ttrain_loss: 0.2067\ttrain_acc: 0.9667\tval_loss: 0.5107\tval_acc: 0.8095\n",
      "Epoch 473:\ttrain_loss: 0.1928\ttrain_acc: 0.9667\tval_loss: 0.5207\tval_acc: 0.8095\n",
      "Epoch 474:\ttrain_loss: 0.1869\ttrain_acc: 0.9667\tval_loss: 0.5275\tval_acc: 0.8095\n",
      "Epoch 475:\ttrain_loss: 0.1844\ttrain_acc: 0.9667\tval_loss: 0.5322\tval_acc: 0.8095\n",
      "Epoch 476:\ttrain_loss: 0.1833\ttrain_acc: 0.9667\tval_loss: 0.5353\tval_acc: 0.8095\n",
      "Epoch 477:\ttrain_loss: 0.1829\ttrain_acc: 0.9667\tval_loss: 0.5375\tval_acc: 0.8095\n",
      "Epoch 478:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5391\tval_acc: 0.8095\n",
      "Epoch 479:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.5402\tval_acc: 0.8095\n",
      "Epoch 480:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5409\tval_acc: 0.8095\n",
      "Epoch 481:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5417\tval_acc: 0.8095\n",
      "Epoch 482:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5419\tval_acc: 0.8095\n",
      "Epoch 483:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5424\tval_acc: 0.8095\n",
      "Epoch 484:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5427\tval_acc: 0.8095\n",
      "Epoch 485:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.5427\tval_acc: 0.8095\n",
      "Epoch 486:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5431\tval_acc: 0.8095\n",
      "Epoch 487:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.5436\tval_acc: 0.8095\n",
      "Epoch 488:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.5433\tval_acc: 0.8095\n",
      "Epoch 489:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5436\tval_acc: 0.8095\n",
      "Epoch 490:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5438\tval_acc: 0.8095\n",
      "Epoch 491:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5437\tval_acc: 0.8095\n",
      "Epoch 492:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5437\tval_acc: 0.8095\n",
      "Epoch 493:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5439\tval_acc: 0.8095\n",
      "Epoch 494:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5441\tval_acc: 0.8095\n",
      "Epoch 495:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.5565\tval_acc: 0.8095\n",
      "Epoch 496:\ttrain_loss: 0.2203\ttrain_acc: 0.9333\tval_loss: 0.6150\tval_acc: 0.7778\n",
      "Epoch 497:\ttrain_loss: 0.2675\ttrain_acc: 0.9333\tval_loss: 0.6057\tval_acc: 0.7619\n",
      "Epoch 498:\ttrain_loss: 0.2336\ttrain_acc: 0.9333\tval_loss: 0.5184\tval_acc: 0.7937\n",
      "Epoch 499:\ttrain_loss: 0.3756\ttrain_acc: 0.8667\tval_loss: 0.5444\tval_acc: 0.7778\n",
      "Epoch 500:\ttrain_loss: 0.2853\ttrain_acc: 0.9333\tval_loss: 0.5628\tval_acc: 0.7937\n",
      "Epoch 501:\ttrain_loss: 0.2375\ttrain_acc: 0.9333\tval_loss: 0.5684\tval_acc: 0.7937\n",
      "Epoch 502:\ttrain_loss: 0.2299\ttrain_acc: 0.9333\tval_loss: 0.5716\tval_acc: 0.7937\n",
      "Epoch 503:\ttrain_loss: 0.2272\ttrain_acc: 0.9333\tval_loss: 0.5729\tval_acc: 0.7937\n",
      "Epoch 504:\ttrain_loss: 0.2263\ttrain_acc: 0.9333\tval_loss: 0.5731\tval_acc: 0.7937\n",
      "Epoch 505:\ttrain_loss: 0.2261\ttrain_acc: 0.9333\tval_loss: 0.5727\tval_acc: 0.7937\n",
      "Epoch 506:\ttrain_loss: 0.2263\ttrain_acc: 0.9333\tval_loss: 0.5722\tval_acc: 0.7937\n",
      "Epoch 507:\ttrain_loss: 0.2266\ttrain_acc: 0.9333\tval_loss: 0.5719\tval_acc: 0.7937\n",
      "Epoch 508:\ttrain_loss: 0.2268\ttrain_acc: 0.9333\tval_loss: 0.5714\tval_acc: 0.7937\n",
      "Epoch 509:\ttrain_loss: 0.2271\ttrain_acc: 0.9333\tval_loss: 0.5711\tval_acc: 0.7937\n",
      "Epoch 510:\ttrain_loss: 0.2273\ttrain_acc: 0.9333\tval_loss: 0.5708\tval_acc: 0.7937\n",
      "Epoch 511:\ttrain_loss: 0.2274\ttrain_acc: 0.9333\tval_loss: 0.5704\tval_acc: 0.7937\n",
      "Epoch 512:\ttrain_loss: 0.2277\ttrain_acc: 0.9333\tval_loss: 0.5703\tval_acc: 0.7937\n",
      "Epoch 513:\ttrain_loss: 0.2277\ttrain_acc: 0.9333\tval_loss: 0.5698\tval_acc: 0.7937\n",
      "Epoch 514:\ttrain_loss: 0.1877\ttrain_acc: 0.9667\tval_loss: 0.4635\tval_acc: 0.8413\n",
      "Epoch 515:\ttrain_loss: 0.1919\ttrain_acc: 0.9667\tval_loss: 0.4652\tval_acc: 0.8413\n",
      "Epoch 516:\ttrain_loss: 0.1872\ttrain_acc: 0.9667\tval_loss: 0.4675\tval_acc: 0.8413\n",
      "Epoch 517:\ttrain_loss: 0.1848\ttrain_acc: 0.9667\tval_loss: 0.4681\tval_acc: 0.8413\n",
      "Epoch 518:\ttrain_loss: 0.1836\ttrain_acc: 0.9667\tval_loss: 0.4687\tval_acc: 0.8413\n",
      "Epoch 519:\ttrain_loss: 0.1830\ttrain_acc: 0.9667\tval_loss: 0.4694\tval_acc: 0.8413\n",
      "Epoch 520:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.4696\tval_acc: 0.8413\n",
      "Epoch 521:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.4698\tval_acc: 0.8413\n",
      "Epoch 522:\ttrain_loss: 0.1825\ttrain_acc: 0.9667\tval_loss: 0.4703\tval_acc: 0.8413\n",
      "Epoch 523:\ttrain_loss: 0.1825\ttrain_acc: 0.9667\tval_loss: 0.4699\tval_acc: 0.8413\n",
      "Epoch 524:\ttrain_loss: 0.1825\ttrain_acc: 0.9667\tval_loss: 0.4647\tval_acc: 0.8413\n",
      "Epoch 525:\ttrain_loss: 0.1825\ttrain_acc: 0.9667\tval_loss: 0.4302\tval_acc: 0.8571\n",
      "Epoch 526:\ttrain_loss: 0.1825\ttrain_acc: 0.9667\tval_loss: 0.4291\tval_acc: 0.8571\n",
      "Epoch 527:\ttrain_loss: 0.1825\ttrain_acc: 0.9667\tval_loss: 0.4290\tval_acc: 0.8571\n",
      "Epoch 528:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.4307\tval_acc: 0.8571\n",
      "Epoch 529:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.4518\tval_acc: 0.8413\n",
      "Epoch 530:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.4566\tval_acc: 0.8413\n",
      "Epoch 531:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.4574\tval_acc: 0.8413\n",
      "Epoch 532:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.4580\tval_acc: 0.8413\n",
      "Epoch 533:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.4579\tval_acc: 0.8413\n",
      "Epoch 534:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.4584\tval_acc: 0.8413\n",
      "Epoch 535:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.4581\tval_acc: 0.8413\n",
      "Epoch 536:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.4608\tval_acc: 0.8413\n",
      "Epoch 537:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.4873\tval_acc: 0.8254\n",
      "Epoch 538:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.4845\tval_acc: 0.8413\n",
      "Epoch 539:\ttrain_loss: 0.2209\ttrain_acc: 0.9333\tval_loss: 0.4771\tval_acc: 0.8413\n",
      "Epoch 540:\ttrain_loss: 0.2302\ttrain_acc: 0.9333\tval_loss: 0.4641\tval_acc: 0.8413\n",
      "Epoch 541:\ttrain_loss: 0.2442\ttrain_acc: 0.9333\tval_loss: 0.4555\tval_acc: 0.8413\n",
      "Epoch 542:\ttrain_loss: 0.2552\ttrain_acc: 0.9333\tval_loss: 0.4503\tval_acc: 0.8413\n",
      "Epoch 543:\ttrain_loss: 0.2125\ttrain_acc: 0.9667\tval_loss: 0.3912\tval_acc: 0.8571\n",
      "Epoch 544:\ttrain_loss: 0.2039\ttrain_acc: 0.9667\tval_loss: 0.4306\tval_acc: 0.8571\n",
      "Epoch 545:\ttrain_loss: 0.1920\ttrain_acc: 0.9667\tval_loss: 0.4344\tval_acc: 0.8571\n",
      "Epoch 546:\ttrain_loss: 0.1869\ttrain_acc: 0.9667\tval_loss: 0.4370\tval_acc: 0.8571\n",
      "Epoch 547:\ttrain_loss: 0.1846\ttrain_acc: 0.9667\tval_loss: 0.4388\tval_acc: 0.8571\n",
      "Epoch 548:\ttrain_loss: 0.1836\ttrain_acc: 0.9667\tval_loss: 0.4398\tval_acc: 0.8571\n",
      "Epoch 549:\ttrain_loss: 0.1831\ttrain_acc: 0.9667\tval_loss: 0.4402\tval_acc: 0.8571\n",
      "Epoch 550:\ttrain_loss: 0.1828\ttrain_acc: 0.9667\tval_loss: 0.4406\tval_acc: 0.8571\n",
      "Epoch 551:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.4407\tval_acc: 0.8571\n",
      "Epoch 552:\ttrain_loss: 0.1825\ttrain_acc: 0.9667\tval_loss: 0.4408\tval_acc: 0.8571\n",
      "Epoch 553:\ttrain_loss: 0.1825\ttrain_acc: 0.9667\tval_loss: 0.4413\tval_acc: 0.8571\n",
      "Epoch 554:\ttrain_loss: 0.1825\ttrain_acc: 0.9667\tval_loss: 0.4414\tval_acc: 0.8571\n",
      "Epoch 555:\ttrain_loss: 0.1825\ttrain_acc: 0.9667\tval_loss: 0.4416\tval_acc: 0.8571\n",
      "Epoch 556:\ttrain_loss: 0.1825\ttrain_acc: 0.9667\tval_loss: 0.4475\tval_acc: 0.8571\n",
      "Epoch 557:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.4685\tval_acc: 0.8413\n",
      "Epoch 558:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.4706\tval_acc: 0.8413\n",
      "Epoch 559:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.4712\tval_acc: 0.8413\n",
      "Epoch 560:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.4711\tval_acc: 0.8413\n",
      "Epoch 561:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.4715\tval_acc: 0.8413\n",
      "Epoch 562:\ttrain_loss: 0.1826\ttrain_acc: 0.9667\tval_loss: 0.5139\tval_acc: 0.8254\n",
      "Epoch 563:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.5136\tval_acc: 0.8254\n",
      "Epoch 564:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.5126\tval_acc: 0.8254\n",
      "Epoch 565:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.4724\tval_acc: 0.8413\n",
      "Epoch 566:\ttrain_loss: 0.1827\ttrain_acc: 0.9667\tval_loss: 0.4850\tval_acc: 0.8413\n",
      "Epoch 567:\ttrain_loss: 0.2204\ttrain_acc: 0.9333\tval_loss: 0.4710\tval_acc: 0.8413\n",
      "Epoch 568:\ttrain_loss: 0.3895\ttrain_acc: 0.8667\tval_loss: 0.4510\tval_acc: 0.8413\n",
      "Epoch 569:\ttrain_loss: 0.2376\ttrain_acc: 0.9667\tval_loss: 0.3634\tval_acc: 0.8889\n",
      "Epoch 570:\ttrain_loss: 0.2169\ttrain_acc: 0.9667\tval_loss: 0.3611\tval_acc: 0.8889\n",
      "Epoch 571:\ttrain_loss: 0.2042\ttrain_acc: 0.9667\tval_loss: 0.3593\tval_acc: 0.8889\n",
      "Epoch 572:\ttrain_loss: 0.1994\ttrain_acc: 0.9667\tval_loss: 0.3588\tval_acc: 0.8889\n",
      "Epoch 573:\ttrain_loss: 0.1978\ttrain_acc: 0.9667\tval_loss: 0.3596\tval_acc: 0.8889\n",
      "Epoch 574:\ttrain_loss: 0.1926\ttrain_acc: 0.9667\tval_loss: 0.3595\tval_acc: 0.8889\n",
      "Epoch 575:\ttrain_loss: 0.1906\ttrain_acc: 0.9667\tval_loss: 0.5190\tval_acc: 0.8254\n",
      "Epoch 576:\ttrain_loss: 0.2254\ttrain_acc: 0.9333\tval_loss: 0.4705\tval_acc: 0.8413\n",
      "Epoch 577:\ttrain_loss: 0.1963\ttrain_acc: 0.9667\tval_loss: 0.4703\tval_acc: 0.8413\n",
      "Epoch 578:\ttrain_loss: 0.1940\ttrain_acc: 0.9667\tval_loss: 0.4697\tval_acc: 0.8413\n",
      "Epoch 579:\ttrain_loss: 0.1929\ttrain_acc: 0.9667\tval_loss: 0.4689\tval_acc: 0.8413\n",
      "Epoch 580:\ttrain_loss: 0.1922\ttrain_acc: 0.9667\tval_loss: 0.4682\tval_acc: 0.8413\n",
      "Epoch 581:\ttrain_loss: 0.1917\ttrain_acc: 0.9667\tval_loss: 0.4675\tval_acc: 0.8413\n",
      "Epoch 582:\ttrain_loss: 0.1914\ttrain_acc: 0.9667\tval_loss: 0.4670\tval_acc: 0.8413\n",
      "Epoch 583:\ttrain_loss: 0.1912\ttrain_acc: 0.9667\tval_loss: 0.4665\tval_acc: 0.8413\n",
      "Epoch 584:\ttrain_loss: 0.1910\ttrain_acc: 0.9667\tval_loss: 0.4661\tval_acc: 0.8413\n",
      "Epoch 585:\ttrain_loss: 0.1909\ttrain_acc: 0.9667\tval_loss: 0.4658\tval_acc: 0.8413\n",
      "Epoch 586:\ttrain_loss: 0.1908\ttrain_acc: 0.9667\tval_loss: 0.4654\tval_acc: 0.8413\n",
      "Epoch 587:\ttrain_loss: 0.1907\ttrain_acc: 0.9667\tval_loss: 0.4651\tval_acc: 0.8413\n",
      "Epoch 588:\ttrain_loss: 0.1906\ttrain_acc: 0.9667\tval_loss: 0.4648\tval_acc: 0.8413\n",
      "Epoch 589:\ttrain_loss: 0.1905\ttrain_acc: 0.9667\tval_loss: 0.4646\tval_acc: 0.8413\n",
      "Epoch 590:\ttrain_loss: 0.1905\ttrain_acc: 0.9667\tval_loss: 0.4644\tval_acc: 0.8413\n",
      "Epoch 591:\ttrain_loss: 0.1904\ttrain_acc: 0.9667\tval_loss: 0.4642\tval_acc: 0.8413\n",
      "Epoch 592:\ttrain_loss: 0.1903\ttrain_acc: 0.9667\tval_loss: 0.4641\tval_acc: 0.8413\n",
      "Epoch 593:\ttrain_loss: 0.1903\ttrain_acc: 0.9667\tval_loss: 0.4640\tval_acc: 0.8413\n",
      "Epoch 594:\ttrain_loss: 0.1902\ttrain_acc: 0.9667\tval_loss: 0.4639\tval_acc: 0.8413\n",
      "Epoch 595:\ttrain_loss: 0.1902\ttrain_acc: 0.9667\tval_loss: 0.4639\tval_acc: 0.8413\n",
      "Epoch 596:\ttrain_loss: 0.1902\ttrain_acc: 0.9667\tval_loss: 0.4926\tval_acc: 0.8254\n",
      "Epoch 597:\ttrain_loss: 0.1901\ttrain_acc: 0.9667\tval_loss: 0.4558\tval_acc: 0.8413\n",
      "Epoch 598:\ttrain_loss: 0.2356\ttrain_acc: 0.9333\tval_loss: 0.4738\tval_acc: 0.8254\n",
      "Epoch 599:\ttrain_loss: 0.2527\ttrain_acc: 0.9333\tval_loss: 0.4771\tval_acc: 0.8254\n",
      "Epoch 600:\ttrain_loss: 0.2475\ttrain_acc: 0.9333\tval_loss: 0.4794\tval_acc: 0.8254\n",
      "Epoch 601:\ttrain_loss: 0.2449\ttrain_acc: 0.9333\tval_loss: 0.4817\tval_acc: 0.8254\n",
      "Epoch 602:\ttrain_loss: 0.2411\ttrain_acc: 0.9333\tval_loss: 0.4838\tval_acc: 0.8254\n",
      "Epoch 603:\ttrain_loss: 0.2375\ttrain_acc: 0.9333\tval_loss: 0.4851\tval_acc: 0.8254\n",
      "Epoch 604:\ttrain_loss: 0.2358\ttrain_acc: 0.9333\tval_loss: 0.4860\tval_acc: 0.8254\n",
      "Epoch 605:\ttrain_loss: 0.2347\ttrain_acc: 0.9333\tval_loss: 0.4867\tval_acc: 0.8254\n",
      "Epoch 606:\ttrain_loss: 0.2339\ttrain_acc: 0.9333\tval_loss: 0.4873\tval_acc: 0.8254\n",
      "Epoch 607:\ttrain_loss: 0.2334\ttrain_acc: 0.9333\tval_loss: 0.4877\tval_acc: 0.8254\n",
      "Epoch 608:\ttrain_loss: 0.2330\ttrain_acc: 0.9333\tval_loss: 0.4882\tval_acc: 0.8254\n",
      "Epoch 609:\ttrain_loss: 0.2326\ttrain_acc: 0.9333\tval_loss: 0.4922\tval_acc: 0.8254\n",
      "Epoch 610:\ttrain_loss: 0.2323\ttrain_acc: 0.9333\tval_loss: 0.5078\tval_acc: 0.8095\n",
      "Epoch 611:\ttrain_loss: 0.2321\ttrain_acc: 0.9333\tval_loss: 0.5259\tval_acc: 0.8095\n",
      "Epoch 612:\ttrain_loss: 0.2320\ttrain_acc: 0.9333\tval_loss: 0.5258\tval_acc: 0.8095\n",
      "Epoch 613:\ttrain_loss: 0.2319\ttrain_acc: 0.9333\tval_loss: 0.5265\tval_acc: 0.8095\n",
      "Epoch 614:\ttrain_loss: 0.2317\ttrain_acc: 0.9333\tval_loss: 0.4895\tval_acc: 0.8254\n",
      "Epoch 615:\ttrain_loss: 0.2316\ttrain_acc: 0.9333\tval_loss: 0.5269\tval_acc: 0.8095\n",
      "Epoch 616:\ttrain_loss: 0.2315\ttrain_acc: 0.9333\tval_loss: 0.4892\tval_acc: 0.8254\n",
      "Epoch 617:\ttrain_loss: 0.2313\ttrain_acc: 0.9333\tval_loss: 0.5415\tval_acc: 0.8095\n",
      "Epoch 618:\ttrain_loss: 0.2861\ttrain_acc: 0.9333\tval_loss: 0.5429\tval_acc: 0.8095\n",
      "Epoch 619:\ttrain_loss: 0.2086\ttrain_acc: 0.9667\tval_loss: 0.4754\tval_acc: 0.8254\n",
      "Epoch 620:\ttrain_loss: 0.2029\ttrain_acc: 0.9667\tval_loss: 0.4766\tval_acc: 0.8254\n",
      "Epoch 621:\ttrain_loss: 0.2023\ttrain_acc: 0.9667\tval_loss: 0.4774\tval_acc: 0.8254\n",
      "Epoch 622:\ttrain_loss: 0.2022\ttrain_acc: 0.9667\tval_loss: 0.4782\tval_acc: 0.8254\n",
      "Epoch 623:\ttrain_loss: 0.2022\ttrain_acc: 0.9667\tval_loss: 0.4523\tval_acc: 0.8413\n",
      "Epoch 624:\ttrain_loss: 0.1989\ttrain_acc: 0.9667\tval_loss: 0.6930\tval_acc: 0.7619\n",
      "Epoch 625:\ttrain_loss: 0.3938\ttrain_acc: 0.8667\tval_loss: 0.5952\tval_acc: 0.7619\n",
      "Epoch 626:\ttrain_loss: 0.3922\ttrain_acc: 0.8667\tval_loss: 0.5588\tval_acc: 0.7619\n",
      "Epoch 627:\ttrain_loss: 0.4094\ttrain_acc: 0.8667\tval_loss: 0.5465\tval_acc: 0.7619\n",
      "Epoch 628:\ttrain_loss: 0.4170\ttrain_acc: 0.8667\tval_loss: 0.5404\tval_acc: 0.7619\n",
      "Epoch 629:\ttrain_loss: 0.4225\ttrain_acc: 0.8667\tval_loss: 0.5373\tval_acc: 0.7619\n",
      "Epoch 630:\ttrain_loss: 0.4244\ttrain_acc: 0.8667\tval_loss: 0.5369\tval_acc: 0.7619\n",
      "Epoch 631:\ttrain_loss: 0.4252\ttrain_acc: 0.8667\tval_loss: 0.5539\tval_acc: 0.7460\n",
      "Epoch 632:\ttrain_loss: 0.4255\ttrain_acc: 0.8667\tval_loss: 0.5491\tval_acc: 0.7460\n",
      "Epoch 633:\ttrain_loss: 0.4328\ttrain_acc: 0.8667\tval_loss: 0.5705\tval_acc: 0.7143\n",
      "Epoch 634:\ttrain_loss: 0.4699\ttrain_acc: 0.8333\tval_loss: 0.4937\tval_acc: 0.7937\n",
      "Epoch 635:\ttrain_loss: 0.4438\ttrain_acc: 0.8667\tval_loss: 0.4924\tval_acc: 0.7937\n",
      "Epoch 636:\ttrain_loss: 0.4268\ttrain_acc: 0.8667\tval_loss: 0.4916\tval_acc: 0.7937\n",
      "Epoch 637:\ttrain_loss: 0.4229\ttrain_acc: 0.8667\tval_loss: 0.4907\tval_acc: 0.7937\n",
      "Epoch 638:\ttrain_loss: 0.4218\ttrain_acc: 0.8667\tval_loss: 0.4902\tval_acc: 0.7937\n",
      "Epoch 639:\ttrain_loss: 0.4214\ttrain_acc: 0.8667\tval_loss: 0.4899\tval_acc: 0.7937\n",
      "Epoch 640:\ttrain_loss: 0.4210\ttrain_acc: 0.8667\tval_loss: 0.4897\tval_acc: 0.7937\n",
      "Epoch 641:\ttrain_loss: 0.4208\ttrain_acc: 0.8667\tval_loss: 0.4896\tval_acc: 0.7937\n",
      "Epoch 642:\ttrain_loss: 0.4206\ttrain_acc: 0.8667\tval_loss: 0.4895\tval_acc: 0.7937\n",
      "Epoch 643:\ttrain_loss: 0.4205\ttrain_acc: 0.8667\tval_loss: 0.4895\tval_acc: 0.7937\n",
      "Epoch 644:\ttrain_loss: 0.4205\ttrain_acc: 0.8667\tval_loss: 0.4894\tval_acc: 0.7937\n",
      "Epoch 645:\ttrain_loss: 0.4205\ttrain_acc: 0.8667\tval_loss: 0.4894\tval_acc: 0.7937\n",
      "Epoch 646:\ttrain_loss: 0.4204\ttrain_acc: 0.8667\tval_loss: 0.5080\tval_acc: 0.7778\n",
      "Epoch 647:\ttrain_loss: 0.4204\ttrain_acc: 0.8667\tval_loss: 0.5336\tval_acc: 0.7460\n",
      "Epoch 648:\ttrain_loss: 0.4456\ttrain_acc: 0.8667\tval_loss: 0.5766\tval_acc: 0.6984\n",
      "Epoch 649:\ttrain_loss: 0.4803\ttrain_acc: 0.8333\tval_loss: 0.6609\tval_acc: 0.5714\n",
      "Epoch 650:\ttrain_loss: 0.5859\ttrain_acc: 0.7000\tval_loss: 0.6396\tval_acc: 0.5714\n",
      "Epoch 651:\ttrain_loss: 0.5891\ttrain_acc: 0.7000\tval_loss: 0.6371\tval_acc: 0.5714\n",
      "Epoch 652:\ttrain_loss: 0.5872\ttrain_acc: 0.7000\tval_loss: 0.7422\tval_acc: 0.4286\n",
      "Epoch 653:\ttrain_loss: 0.6314\ttrain_acc: 0.6667\tval_loss: 0.7083\tval_acc: 0.4286\n",
      "Epoch 654:\ttrain_loss: 0.6355\ttrain_acc: 0.6667\tval_loss: 0.7055\tval_acc: 0.4286\n",
      "Epoch 655:\ttrain_loss: 0.6359\ttrain_acc: 0.6667\tval_loss: 0.7046\tval_acc: 0.4286\n",
      "Epoch 656:\ttrain_loss: 0.6362\ttrain_acc: 0.6667\tval_loss: 0.6983\tval_acc: 0.4286\n",
      "Epoch 657:\ttrain_loss: 0.6361\ttrain_acc: 0.6667\tval_loss: 0.7120\tval_acc: 0.4127\n",
      "Epoch 658:\ttrain_loss: 0.6395\ttrain_acc: 0.6667\tval_loss: 0.6432\tval_acc: 0.5079\n",
      "Epoch 659:\ttrain_loss: 0.6137\ttrain_acc: 0.7000\tval_loss: 0.6603\tval_acc: 0.4921\n",
      "Epoch 660:\ttrain_loss: 0.6172\ttrain_acc: 0.7000\tval_loss: 0.6608\tval_acc: 0.4921\n",
      "Epoch 661:\ttrain_loss: 0.6179\ttrain_acc: 0.7000\tval_loss: 0.6666\tval_acc: 0.4762\n",
      "Epoch 662:\ttrain_loss: 0.6122\ttrain_acc: 0.7000\tval_loss: 0.7091\tval_acc: 0.4127\n",
      "Epoch 663:\ttrain_loss: 0.6020\ttrain_acc: 0.6800\tval_loss: 0.6725\tval_acc: 0.4921\n",
      "Epoch 664:\ttrain_loss: 0.6106\ttrain_acc: 0.7000\tval_loss: 0.6745\tval_acc: 0.4762\n",
      "Epoch 665:\ttrain_loss: 0.6153\ttrain_acc: 0.7000\tval_loss: 0.6192\tval_acc: 0.5556\n",
      "Epoch 666:\ttrain_loss: 0.5755\ttrain_acc: 0.7200\tval_loss: 0.6458\tval_acc: 0.5556\n",
      "Epoch 667:\ttrain_loss: 0.5716\ttrain_acc: 0.7200\tval_loss: 0.6009\tval_acc: 0.6190\n",
      "Epoch 668:\ttrain_loss: 0.5739\ttrain_acc: 0.7333\tval_loss: 0.6522\tval_acc: 0.5238\n",
      "Epoch 669:\ttrain_loss: 0.6084\ttrain_acc: 0.7000\tval_loss: 0.6441\tval_acc: 0.5397\n",
      "Epoch 670:\ttrain_loss: 0.6061\ttrain_acc: 0.7000\tval_loss: 0.5775\tval_acc: 0.6349\n",
      "Epoch 671:\ttrain_loss: 0.5580\ttrain_acc: 0.7667\tval_loss: 0.6199\tval_acc: 0.6032\n",
      "Epoch 672:\ttrain_loss: 0.5393\ttrain_acc: 0.7333\tval_loss: 0.5716\tval_acc: 0.6667\n",
      "Epoch 673:\ttrain_loss: 0.5173\ttrain_acc: 0.8000\tval_loss: 0.5730\tval_acc: 0.6667\n",
      "Epoch 674:\ttrain_loss: 0.5167\ttrain_acc: 0.8000\tval_loss: 0.5736\tval_acc: 0.6667\n",
      "Epoch 675:\ttrain_loss: 0.5169\ttrain_acc: 0.8000\tval_loss: 0.5740\tval_acc: 0.6667\n",
      "Epoch 676:\ttrain_loss: 0.5170\ttrain_acc: 0.8000\tval_loss: 0.5626\tval_acc: 0.6984\n",
      "Epoch 677:\ttrain_loss: 0.5193\ttrain_acc: 0.8000\tval_loss: 0.6228\tval_acc: 0.5873\n",
      "Epoch 678:\ttrain_loss: 0.5568\ttrain_acc: 0.7667\tval_loss: 0.6258\tval_acc: 0.5714\n",
      "Epoch 679:\ttrain_loss: 0.5607\ttrain_acc: 0.7667\tval_loss: 0.6260\tval_acc: 0.5714\n",
      "Epoch 680:\ttrain_loss: 0.5618\ttrain_acc: 0.7667\tval_loss: 0.6392\tval_acc: 0.5556\n",
      "Epoch 681:\ttrain_loss: 0.5947\ttrain_acc: 0.7000\tval_loss: 0.6347\tval_acc: 0.5556\n",
      "Epoch 682:\ttrain_loss: 0.5923\ttrain_acc: 0.7000\tval_loss: 0.6342\tval_acc: 0.5556\n",
      "Epoch 683:\ttrain_loss: 0.5918\ttrain_acc: 0.7000\tval_loss: 0.6333\tval_acc: 0.5556\n",
      "Epoch 684:\ttrain_loss: 0.5885\ttrain_acc: 0.6800\tval_loss: 0.6330\tval_acc: 0.5556\n",
      "Epoch 685:\ttrain_loss: 0.5632\ttrain_acc: 0.6800\tval_loss: 0.6457\tval_acc: 0.5397\n",
      "Epoch 686:\ttrain_loss: 0.5665\ttrain_acc: 0.7000\tval_loss: 0.6026\tval_acc: 0.6032\n",
      "Epoch 687:\ttrain_loss: 0.5711\ttrain_acc: 0.7333\tval_loss: 0.6280\tval_acc: 0.5873\n",
      "Epoch 688:\ttrain_loss: 0.5729\ttrain_acc: 0.7333\tval_loss: 0.6449\tval_acc: 0.5397\n",
      "Epoch 689:\ttrain_loss: 0.5674\ttrain_acc: 0.7000\tval_loss: 0.6589\tval_acc: 0.5238\n",
      "Epoch 690:\ttrain_loss: 0.5933\ttrain_acc: 0.7000\tval_loss: 0.6569\tval_acc: 0.5238\n",
      "Epoch 691:\ttrain_loss: 0.5892\ttrain_acc: 0.6667\tval_loss: 0.6254\tval_acc: 0.5873\n",
      "Epoch 692:\ttrain_loss: 0.5853\ttrain_acc: 0.7333\tval_loss: 0.6426\tval_acc: 0.5714\n",
      "Epoch 693:\ttrain_loss: 0.5818\ttrain_acc: 0.7333\tval_loss: 0.6417\tval_acc: 0.5714\n",
      "Epoch 694:\ttrain_loss: 0.5797\ttrain_acc: 0.7333\tval_loss: 0.6413\tval_acc: 0.5714\n",
      "Epoch 695:\ttrain_loss: 0.5786\ttrain_acc: 0.7333\tval_loss: 0.6412\tval_acc: 0.5714\n",
      "Epoch 696:\ttrain_loss: 0.5782\ttrain_acc: 0.7333\tval_loss: 0.6415\tval_acc: 0.5714\n",
      "Epoch 697:\ttrain_loss: 0.5922\ttrain_acc: 0.7333\tval_loss: 0.6419\tval_acc: 0.5397\n",
      "Epoch 698:\ttrain_loss: 0.5996\ttrain_acc: 0.7000\tval_loss: 0.6404\tval_acc: 0.5397\n",
      "Epoch 699:\ttrain_loss: 0.6003\ttrain_acc: 0.7000\tval_loss: 0.6412\tval_acc: 0.5397\n",
      "Epoch 700:\ttrain_loss: 0.6019\ttrain_acc: 0.7000\tval_loss: 0.6672\tval_acc: 0.4921\n",
      "Epoch 701:\ttrain_loss: 0.5975\ttrain_acc: 0.6667\tval_loss: 0.6468\tval_acc: 0.5397\n",
      "Epoch 702:\ttrain_loss: 0.6024\ttrain_acc: 0.7000\tval_loss: 0.6501\tval_acc: 0.5397\n",
      "Epoch 703:\ttrain_loss: 0.6040\ttrain_acc: 0.7000\tval_loss: 0.6503\tval_acc: 0.5397\n",
      "Epoch 704:\ttrain_loss: 0.6042\ttrain_acc: 0.7000\tval_loss: 0.6502\tval_acc: 0.5397\n",
      "Epoch 705:\ttrain_loss: 0.6041\ttrain_acc: 0.7000\tval_loss: 0.6503\tval_acc: 0.5397\n",
      "Epoch 706:\ttrain_loss: 0.6041\ttrain_acc: 0.7000\tval_loss: 0.6429\tval_acc: 0.5397\n",
      "Epoch 707:\ttrain_loss: 0.6043\ttrain_acc: 0.7000\tval_loss: 0.6441\tval_acc: 0.5397\n",
      "Epoch 708:\ttrain_loss: 0.6042\ttrain_acc: 0.7000\tval_loss: 0.6337\tval_acc: 0.5556\n",
      "Epoch 709:\ttrain_loss: 0.6042\ttrain_acc: 0.7000\tval_loss: 0.6428\tval_acc: 0.5397\n",
      "Epoch 710:\ttrain_loss: 0.6129\ttrain_acc: 0.7000\tval_loss: 0.6324\tval_acc: 0.5873\n",
      "Epoch 711:\ttrain_loss: 0.5967\ttrain_acc: 0.7333\tval_loss: 0.6331\tval_acc: 0.5873\n",
      "Epoch 712:\ttrain_loss: 0.5958\ttrain_acc: 0.7333\tval_loss: 0.6331\tval_acc: 0.5873\n",
      "Epoch 713:\ttrain_loss: 0.5955\ttrain_acc: 0.7333\tval_loss: 0.6331\tval_acc: 0.5873\n",
      "Epoch 714:\ttrain_loss: 0.5949\ttrain_acc: 0.7333\tval_loss: 0.6332\tval_acc: 0.5873\n",
      "Epoch 715:\ttrain_loss: 0.5947\ttrain_acc: 0.7333\tval_loss: 0.6331\tval_acc: 0.5873\n",
      "Epoch 716:\ttrain_loss: 0.5949\ttrain_acc: 0.7333\tval_loss: 0.6437\tval_acc: 0.5714\n",
      "Epoch 717:\ttrain_loss: 0.6169\ttrain_acc: 0.7000\tval_loss: 0.6434\tval_acc: 0.5714\n",
      "Epoch 718:\ttrain_loss: 0.6174\ttrain_acc: 0.7000\tval_loss: 0.6262\tval_acc: 0.6032\n",
      "Epoch 719:\ttrain_loss: 0.6290\ttrain_acc: 0.6333\tval_loss: 0.6526\tval_acc: 0.5714\n",
      "Epoch 720:\ttrain_loss: 0.6435\ttrain_acc: 0.6333\tval_loss: 0.6600\tval_acc: 0.5714\n",
      "Epoch 721:\ttrain_loss: 0.6533\ttrain_acc: 0.6333\tval_loss: 0.6654\tval_acc: 0.5714\n",
      "Epoch 722:\ttrain_loss: 0.6694\ttrain_acc: 0.6333\tval_loss: 0.6681\tval_acc: 0.5714\n",
      "Epoch 723:\ttrain_loss: 0.6537\ttrain_acc: 0.6333\tval_loss: 0.6626\tval_acc: 0.5714\n",
      "Epoch 724:\ttrain_loss: 0.6488\ttrain_acc: 0.6667\tval_loss: 0.6565\tval_acc: 0.5714\n",
      "Epoch 725:\ttrain_loss: 0.6465\ttrain_acc: 0.6667\tval_loss: 0.6528\tval_acc: 0.5714\n",
      "Epoch 726:\ttrain_loss: 0.6451\ttrain_acc: 0.6667\tval_loss: 0.6505\tval_acc: 0.5714\n",
      "Epoch 727:\ttrain_loss: 0.6442\ttrain_acc: 0.6667\tval_loss: 0.6523\tval_acc: 0.5714\n",
      "Epoch 728:\ttrain_loss: 0.6606\ttrain_acc: 0.6333\tval_loss: 0.6584\tval_acc: 0.5714\n",
      "Epoch 729:\ttrain_loss: 0.6664\ttrain_acc: 0.6333\tval_loss: 0.6651\tval_acc: 0.5714\n",
      "Epoch 730:\ttrain_loss: 0.6693\ttrain_acc: 0.6333\tval_loss: 0.6676\tval_acc: 0.5714\n",
      "Epoch 731:\ttrain_loss: 0.6689\ttrain_acc: 0.6333\tval_loss: 0.6689\tval_acc: 0.5714\n",
      "Epoch 732:\ttrain_loss: 0.6687\ttrain_acc: 0.6333\tval_loss: 0.6696\tval_acc: 0.5714\n",
      "Epoch 733:\ttrain_loss: 0.6685\ttrain_acc: 0.6333\tval_loss: 0.6701\tval_acc: 0.5714\n",
      "Epoch 734:\ttrain_loss: 0.6684\ttrain_acc: 0.6333\tval_loss: 0.6708\tval_acc: 0.5714\n",
      "Epoch 735:\ttrain_loss: 0.6683\ttrain_acc: 0.6333\tval_loss: 0.6836\tval_acc: 0.5238\n",
      "Epoch 736:\ttrain_loss: 0.6560\ttrain_acc: 0.6667\tval_loss: 0.6580\tval_acc: 0.5873\n",
      "Epoch 737:\ttrain_loss: 0.6695\ttrain_acc: 0.6333\tval_loss: 0.6612\tval_acc: 0.5873\n",
      "Epoch 738:\ttrain_loss: 0.6694\ttrain_acc: 0.6333\tval_loss: 0.6619\tval_acc: 0.5873\n",
      "Epoch 739:\ttrain_loss: 0.6692\ttrain_acc: 0.6333\tval_loss: 0.6767\tval_acc: 0.5397\n",
      "Epoch 740:\ttrain_loss: 0.6671\ttrain_acc: 0.6333\tval_loss: 0.6717\tval_acc: 0.5556\n",
      "Epoch 741:\ttrain_loss: 0.6667\ttrain_acc: 0.6333\tval_loss: 0.6869\tval_acc: 0.5079\n",
      "Epoch 742:\ttrain_loss: 0.6634\ttrain_acc: 0.6000\tval_loss: 0.6491\tval_acc: 0.5873\n",
      "Epoch 743:\ttrain_loss: 0.6637\ttrain_acc: 0.6000\tval_loss: 0.6707\tval_acc: 0.5079\n",
      "Epoch 744:\ttrain_loss: 0.6541\ttrain_acc: 0.6333\tval_loss: 0.6418\tval_acc: 0.5873\n",
      "Epoch 745:\ttrain_loss: 0.6562\ttrain_acc: 0.6333\tval_loss: 0.6576\tval_acc: 0.5556\n",
      "Epoch 746:\ttrain_loss: 0.6260\ttrain_acc: 0.6333\tval_loss: 0.6388\tval_acc: 0.5873\n",
      "Epoch 747:\ttrain_loss: 0.6431\ttrain_acc: 0.7000\tval_loss: 0.6375\tval_acc: 0.5873\n",
      "Epoch 748:\ttrain_loss: 0.6432\ttrain_acc: 0.7000\tval_loss: 0.6508\tval_acc: 0.5714\n",
      "Epoch 749:\ttrain_loss: 0.6155\ttrain_acc: 0.7200\tval_loss: 0.6331\tval_acc: 0.6032\n",
      "Epoch 750:\ttrain_loss: 0.6237\ttrain_acc: 0.7200\tval_loss: 0.5971\tval_acc: 0.6825\n",
      "Epoch 751:\ttrain_loss: 0.5726\ttrain_acc: 0.8000\tval_loss: 0.5818\tval_acc: 0.7302\n",
      "Epoch 752:\ttrain_loss: 0.5429\ttrain_acc: 0.8000\tval_loss: 0.5995\tval_acc: 0.7143\n",
      "Epoch 753:\ttrain_loss: 0.5352\ttrain_acc: 0.8000\tval_loss: 0.5914\tval_acc: 0.7143\n",
      "Epoch 754:\ttrain_loss: 0.5279\ttrain_acc: 0.8000\tval_loss: 0.5851\tval_acc: 0.7143\n",
      "Epoch 755:\ttrain_loss: 0.5090\ttrain_acc: 0.8000\tval_loss: 0.5593\tval_acc: 0.7460\n",
      "Epoch 756:\ttrain_loss: 0.4879\ttrain_acc: 0.8333\tval_loss: 0.5769\tval_acc: 0.7302\n",
      "Epoch 757:\ttrain_loss: 0.5033\ttrain_acc: 0.8000\tval_loss: 0.5620\tval_acc: 0.7460\n",
      "Epoch 758:\ttrain_loss: 0.4907\ttrain_acc: 0.8333\tval_loss: 0.6340\tval_acc: 0.6825\n",
      "Epoch 759:\ttrain_loss: 0.4536\ttrain_acc: 0.8667\tval_loss: 0.6020\tval_acc: 0.7143\n",
      "Epoch 760:\ttrain_loss: 0.4586\ttrain_acc: 0.9000\tval_loss: 0.5845\tval_acc: 0.7302\n",
      "Epoch 761:\ttrain_loss: 0.4772\ttrain_acc: 0.9333\tval_loss: 0.5312\tval_acc: 0.8095\n",
      "Epoch 762:\ttrain_loss: 0.3730\ttrain_acc: 0.9333\tval_loss: 0.5279\tval_acc: 0.7778\n",
      "Epoch 763:\ttrain_loss: 0.3567\ttrain_acc: 0.9333\tval_loss: 0.5084\tval_acc: 0.7937\n",
      "Epoch 764:\ttrain_loss: 0.3421\ttrain_acc: 0.9333\tval_loss: 0.5033\tval_acc: 0.7937\n",
      "Epoch 765:\ttrain_loss: 0.3638\ttrain_acc: 0.9000\tval_loss: 0.5728\tval_acc: 0.7302\n",
      "Epoch 766:\ttrain_loss: 0.4975\ttrain_acc: 0.8000\tval_loss: 0.5830\tval_acc: 0.7302\n",
      "Epoch 767:\ttrain_loss: 0.4972\ttrain_acc: 0.8000\tval_loss: 0.5690\tval_acc: 0.7619\n",
      "Epoch 768:\ttrain_loss: 0.4927\ttrain_acc: 0.8000\tval_loss: 0.8254\tval_acc: 0.4921\n",
      "Epoch 769:\ttrain_loss: 0.5008\ttrain_acc: 0.8000\tval_loss: 0.6753\tval_acc: 0.5873\n",
      "Epoch 770:\ttrain_loss: 0.4306\ttrain_acc: 0.8333\tval_loss: 0.4486\tval_acc: 0.8571\n",
      "Epoch 771:\ttrain_loss: 0.3609\ttrain_acc: 0.9000\tval_loss: 0.4308\tval_acc: 0.8571\n",
      "Epoch 772:\ttrain_loss: 0.3250\ttrain_acc: 0.9333\tval_loss: 0.5008\tval_acc: 0.7937\n",
      "Epoch 773:\ttrain_loss: 0.3631\ttrain_acc: 0.9333\tval_loss: 0.4903\tval_acc: 0.7937\n",
      "Epoch 774:\ttrain_loss: 0.3210\ttrain_acc: 0.9333\tval_loss: 0.4222\tval_acc: 0.8571\n",
      "Epoch 775:\ttrain_loss: 0.3021\ttrain_acc: 0.9333\tval_loss: 0.4152\tval_acc: 0.8571\n",
      "Epoch 776:\ttrain_loss: 0.2774\ttrain_acc: 0.9333\tval_loss: 0.4410\tval_acc: 0.8254\n",
      "Epoch 777:\ttrain_loss: 0.2940\ttrain_acc: 0.9667\tval_loss: 0.3749\tval_acc: 0.8889\n",
      "Epoch 778:\ttrain_loss: 0.2868\ttrain_acc: 0.9667\tval_loss: 0.6757\tval_acc: 0.6825\n",
      "Epoch 779:\ttrain_loss: 0.3538\ttrain_acc: 0.9000\tval_loss: 0.4020\tval_acc: 0.8413\n",
      "Epoch 780:\ttrain_loss: 0.2974\ttrain_acc: 0.9333\tval_loss: 0.4056\tval_acc: 0.8571\n",
      "Epoch 781:\ttrain_loss: 0.2560\ttrain_acc: 0.9667\tval_loss: 0.4120\tval_acc: 0.8571\n",
      "Epoch 782:\ttrain_loss: 0.2323\ttrain_acc: 0.9667\tval_loss: 0.4363\tval_acc: 0.8413\n",
      "Epoch 783:\ttrain_loss: 0.3612\ttrain_acc: 0.8667\tval_loss: 0.4236\tval_acc: 0.8413\n",
      "Epoch 784:\ttrain_loss: 0.3402\ttrain_acc: 0.9000\tval_loss: 0.3855\tval_acc: 0.8730\n",
      "Epoch 785:\ttrain_loss: 0.2902\ttrain_acc: 0.9333\tval_loss: 0.4235\tval_acc: 0.8413\n",
      "Epoch 786:\ttrain_loss: 0.2798\ttrain_acc: 0.9333\tval_loss: 0.3779\tval_acc: 0.8889\n",
      "Epoch 787:\ttrain_loss: 0.4169\ttrain_acc: 0.8333\tval_loss: 0.4464\tval_acc: 0.8413\n",
      "Epoch 788:\ttrain_loss: 0.4127\ttrain_acc: 0.8667\tval_loss: 0.4244\tval_acc: 0.8571\n",
      "Epoch 789:\ttrain_loss: 0.2800\ttrain_acc: 0.9333\tval_loss: 0.4167\tval_acc: 0.8571\n",
      "Epoch 790:\ttrain_loss: 0.3282\ttrain_acc: 0.9000\tval_loss: 0.4999\tval_acc: 0.7937\n",
      "Epoch 791:\ttrain_loss: 0.3607\ttrain_acc: 0.8667\tval_loss: 0.4253\tval_acc: 0.8413\n",
      "Epoch 792:\ttrain_loss: 0.3532\ttrain_acc: 0.8667\tval_loss: 0.4093\tval_acc: 0.8571\n",
      "Epoch 793:\ttrain_loss: 0.3096\ttrain_acc: 0.9333\tval_loss: 0.4089\tval_acc: 0.8571\n",
      "Epoch 794:\ttrain_loss: 0.3067\ttrain_acc: 0.9333\tval_loss: 0.4089\tval_acc: 0.8571\n",
      "Epoch 795:\ttrain_loss: 0.3050\ttrain_acc: 0.9333\tval_loss: 0.4092\tval_acc: 0.8571\n",
      "Epoch 796:\ttrain_loss: 0.3040\ttrain_acc: 0.9333\tval_loss: 0.4095\tval_acc: 0.8571\n",
      "Epoch 797:\ttrain_loss: 0.3035\ttrain_acc: 0.9333\tval_loss: 0.4100\tval_acc: 0.8571\n",
      "Epoch 798:\ttrain_loss: 0.3032\ttrain_acc: 0.9333\tval_loss: 0.4107\tval_acc: 0.8571\n",
      "Epoch 799:\ttrain_loss: 0.3031\ttrain_acc: 0.9333\tval_loss: 0.4109\tval_acc: 0.8571\n",
      "Epoch 800:\ttrain_loss: 0.3031\ttrain_acc: 0.9333\tval_loss: 0.5067\tval_acc: 0.7937\n",
      "Epoch 801:\ttrain_loss: 0.4796\ttrain_acc: 0.8000\tval_loss: 0.5461\tval_acc: 0.7619\n",
      "Epoch 802:\ttrain_loss: 0.4526\ttrain_acc: 0.8000\tval_loss: 0.4934\tval_acc: 0.8095\n",
      "Epoch 803:\ttrain_loss: 0.4529\ttrain_acc: 0.8333\tval_loss: 0.4766\tval_acc: 0.8254\n",
      "Epoch 804:\ttrain_loss: 0.3192\ttrain_acc: 0.9333\tval_loss: 0.5256\tval_acc: 0.8095\n",
      "Epoch 805:\ttrain_loss: 0.3052\ttrain_acc: 0.9333\tval_loss: 0.4348\tval_acc: 0.8254\n",
      "Epoch 806:\ttrain_loss: 0.3023\ttrain_acc: 0.9333\tval_loss: 0.4224\tval_acc: 0.8413\n",
      "Epoch 807:\ttrain_loss: 0.2986\ttrain_acc: 0.9333\tval_loss: 0.4231\tval_acc: 0.8571\n",
      "Epoch 808:\ttrain_loss: 0.2692\ttrain_acc: 0.9333\tval_loss: 0.4795\tval_acc: 0.8095\n",
      "Epoch 809:\ttrain_loss: 0.2838\ttrain_acc: 0.9333\tval_loss: 0.4831\tval_acc: 0.7937\n",
      "Epoch 810:\ttrain_loss: 0.2820\ttrain_acc: 0.9333\tval_loss: 0.4197\tval_acc: 0.8571\n",
      "Epoch 811:\ttrain_loss: 0.2795\ttrain_acc: 0.9333\tval_loss: 0.4152\tval_acc: 0.8413\n",
      "Epoch 812:\ttrain_loss: 0.2737\ttrain_acc: 0.9333\tval_loss: 0.4401\tval_acc: 0.8413\n",
      "Epoch 813:\ttrain_loss: 0.2885\ttrain_acc: 0.9333\tval_loss: 0.3947\tval_acc: 0.8571\n",
      "Epoch 814:\ttrain_loss: 0.2827\ttrain_acc: 0.9333\tval_loss: 0.4714\tval_acc: 0.8413\n",
      "Epoch 815:\ttrain_loss: 0.2786\ttrain_acc: 0.9333\tval_loss: 0.4426\tval_acc: 0.8254\n",
      "Epoch 816:\ttrain_loss: 0.2855\ttrain_acc: 0.9333\tval_loss: 0.3889\tval_acc: 0.8730\n",
      "Epoch 817:\ttrain_loss: 0.2288\ttrain_acc: 0.9667\tval_loss: 0.4179\tval_acc: 0.8413\n",
      "Epoch 818:\ttrain_loss: 0.2834\ttrain_acc: 0.9333\tval_loss: 0.4673\tval_acc: 0.8254\n",
      "Epoch 819:\ttrain_loss: 0.2665\ttrain_acc: 0.9333\tval_loss: 0.4347\tval_acc: 0.8413\n",
      "Epoch 820:\ttrain_loss: 0.2512\ttrain_acc: 0.9333\tval_loss: 0.3985\tval_acc: 0.8730\n",
      "Epoch 821:\ttrain_loss: 0.2142\ttrain_acc: 0.9667\tval_loss: 0.3818\tval_acc: 0.8571\n",
      "Epoch 822:\ttrain_loss: 0.2116\ttrain_acc: 0.9667\tval_loss: 0.3891\tval_acc: 0.8730\n",
      "Epoch 823:\ttrain_loss: 0.2169\ttrain_acc: 0.9667\tval_loss: 0.3826\tval_acc: 0.8730\n",
      "Epoch 824:\ttrain_loss: 0.2083\ttrain_acc: 0.9667\tval_loss: 0.3789\tval_acc: 0.8730\n",
      "Epoch 825:\ttrain_loss: 0.2602\ttrain_acc: 0.9333\tval_loss: 0.3903\tval_acc: 0.8730\n",
      "Epoch 826:\ttrain_loss: 0.3190\ttrain_acc: 0.9000\tval_loss: 0.3786\tval_acc: 0.8730\n",
      "Epoch 827:\ttrain_loss: 0.2625\ttrain_acc: 0.9333\tval_loss: 0.3837\tval_acc: 0.8571\n",
      "Epoch 828:\ttrain_loss: 0.2579\ttrain_acc: 0.9333\tval_loss: 0.4003\tval_acc: 0.8730\n",
      "Epoch 829:\ttrain_loss: 0.2270\ttrain_acc: 0.9333\tval_loss: 0.3523\tval_acc: 0.8889\n",
      "Epoch 830:\ttrain_loss: 0.2622\ttrain_acc: 0.9333\tval_loss: 0.3667\tval_acc: 0.8571\n",
      "Epoch 831:\ttrain_loss: 0.2041\ttrain_acc: 0.9667\tval_loss: 0.3440\tval_acc: 0.8889\n",
      "Epoch 832:\ttrain_loss: 0.1942\ttrain_acc: 0.9667\tval_loss: 0.3471\tval_acc: 0.8889\n",
      "Epoch 833:\ttrain_loss: 0.1904\ttrain_acc: 0.9667\tval_loss: 0.3531\tval_acc: 0.8889\n",
      "Epoch 834:\ttrain_loss: 0.1885\ttrain_acc: 0.9667\tval_loss: 0.3631\tval_acc: 0.8730\n",
      "Epoch 835:\ttrain_loss: 0.1876\ttrain_acc: 0.9667\tval_loss: 0.3847\tval_acc: 0.8571\n",
      "Epoch 836:\ttrain_loss: 0.1870\ttrain_acc: 0.9667\tval_loss: 0.4380\tval_acc: 0.8254\n",
      "Epoch 837:\ttrain_loss: 0.1868\ttrain_acc: 0.9667\tval_loss: 0.4776\tval_acc: 0.8254\n",
      "Epoch 838:\ttrain_loss: 0.1867\ttrain_acc: 0.9667\tval_loss: 0.4480\tval_acc: 0.8413\n",
      "Epoch 839:\ttrain_loss: 0.3427\ttrain_acc: 0.8667\tval_loss: 0.4676\tval_acc: 0.8254\n",
      "Epoch 840:\ttrain_loss: 0.2936\ttrain_acc: 0.9333\tval_loss: 0.4165\tval_acc: 0.8571\n",
      "Epoch 841:\ttrain_loss: 0.2073\ttrain_acc: 0.9667\tval_loss: 0.4313\tval_acc: 0.8254\n",
      "Epoch 842:\ttrain_loss: 0.1962\ttrain_acc: 0.9667\tval_loss: 0.4338\tval_acc: 0.8254\n",
      "Epoch 843:\ttrain_loss: 0.1906\ttrain_acc: 0.9667\tval_loss: 0.4360\tval_acc: 0.8254\n",
      "Epoch 844:\ttrain_loss: 0.1882\ttrain_acc: 0.9667\tval_loss: 0.4375\tval_acc: 0.8254\n",
      "Epoch 845:\ttrain_loss: 0.1870\ttrain_acc: 0.9667\tval_loss: 0.4438\tval_acc: 0.8254\n",
      "Epoch 846:\ttrain_loss: 0.1867\ttrain_acc: 0.9667\tval_loss: 0.4533\tval_acc: 0.8254\n",
      "Epoch 847:\ttrain_loss: 0.1863\ttrain_acc: 0.9667\tval_loss: 0.4695\tval_acc: 0.8254\n",
      "Epoch 848:\ttrain_loss: 0.1868\ttrain_acc: 0.9667\tval_loss: 0.4864\tval_acc: 0.8095\n",
      "Epoch 849:\ttrain_loss: 0.2707\ttrain_acc: 0.9333\tval_loss: 0.5114\tval_acc: 0.7778\n",
      "Epoch 850:\ttrain_loss: 0.2095\ttrain_acc: 0.9667\tval_loss: 0.3681\tval_acc: 0.8730\n",
      "Epoch 851:\ttrain_loss: 0.2069\ttrain_acc: 0.9667\tval_loss: 0.4380\tval_acc: 0.8413\n",
      "Epoch 852:\ttrain_loss: 0.2018\ttrain_acc: 0.9667\tval_loss: 0.4481\tval_acc: 0.8095\n",
      "Epoch 853:\ttrain_loss: 0.1998\ttrain_acc: 0.9667\tval_loss: 0.4551\tval_acc: 0.8095\n",
      "Epoch 854:\ttrain_loss: 0.1933\ttrain_acc: 0.9667\tval_loss: 0.4616\tval_acc: 0.8095\n",
      "Epoch 855:\ttrain_loss: 0.1889\ttrain_acc: 0.9667\tval_loss: 0.4664\tval_acc: 0.8095\n",
      "Epoch 856:\ttrain_loss: 0.1863\ttrain_acc: 0.9667\tval_loss: 0.4691\tval_acc: 0.8095\n",
      "Epoch 857:\ttrain_loss: 0.1848\ttrain_acc: 0.9667\tval_loss: 0.4704\tval_acc: 0.8095\n",
      "Epoch 858:\ttrain_loss: 0.1839\ttrain_acc: 0.9667\tval_loss: 0.4746\tval_acc: 0.8095\n",
      "Epoch 859:\ttrain_loss: 0.1831\ttrain_acc: 0.9667\tval_loss: 0.4795\tval_acc: 0.8095\n",
      "Epoch 860:\ttrain_loss: 0.1833\ttrain_acc: 0.9667\tval_loss: 0.5072\tval_acc: 0.8095\n",
      "Epoch 861:\ttrain_loss: 0.1824\ttrain_acc: 0.9667\tval_loss: 0.5031\tval_acc: 0.8095\n",
      "Epoch 862:\ttrain_loss: 0.1830\ttrain_acc: 0.9667\tval_loss: 0.6724\tval_acc: 0.7619\n",
      "Epoch 863:\ttrain_loss: 0.2594\ttrain_acc: 0.9000\tval_loss: 0.5647\tval_acc: 0.8095\n",
      "Epoch 864:\ttrain_loss: 0.2299\ttrain_acc: 0.9333\tval_loss: 0.3933\tval_acc: 0.8571\n",
      "Epoch 865:\ttrain_loss: 0.2703\ttrain_acc: 0.9333\tval_loss: 0.3395\tval_acc: 0.8889\n",
      "Epoch 866:\ttrain_loss: 0.2592\ttrain_acc: 0.9333\tval_loss: 0.3401\tval_acc: 0.8889\n",
      "Epoch 867:\ttrain_loss: 0.2557\ttrain_acc: 0.9333\tval_loss: 0.3554\tval_acc: 0.8730\n",
      "Epoch 868:\ttrain_loss: 0.1970\ttrain_acc: 0.9667\tval_loss: 0.4860\tval_acc: 0.8254\n",
      "Epoch 869:\ttrain_loss: 0.1879\ttrain_acc: 0.9667\tval_loss: 0.5107\tval_acc: 0.8095\n",
      "Epoch 870:\ttrain_loss: 0.1869\ttrain_acc: 0.9667\tval_loss: 0.4749\tval_acc: 0.8254\n",
      "Epoch 871:\ttrain_loss: 0.2405\ttrain_acc: 0.9333\tval_loss: 0.4244\tval_acc: 0.8571\n",
      "Epoch 872:\ttrain_loss: 0.2172\ttrain_acc: 0.9667\tval_loss: 0.4893\tval_acc: 0.8254\n",
      "Epoch 873:\ttrain_loss: 0.1848\ttrain_acc: 0.9667\tval_loss: 0.4671\tval_acc: 0.8254\n",
      "Epoch 874:\ttrain_loss: 0.1918\ttrain_acc: 0.9667\tval_loss: 0.4253\tval_acc: 0.8571\n",
      "Epoch 875:\ttrain_loss: 0.1799\ttrain_acc: 0.9667\tval_loss: 0.3988\tval_acc: 0.8730\n",
      "Epoch 876:\ttrain_loss: 0.1730\ttrain_acc: 0.9667\tval_loss: 0.4385\tval_acc: 0.8413\n",
      "Epoch 877:\ttrain_loss: 0.2462\ttrain_acc: 0.9333\tval_loss: 0.4594\tval_acc: 0.8413\n",
      "Epoch 878:\ttrain_loss: 0.1730\ttrain_acc: 0.9667\tval_loss: 0.4165\tval_acc: 0.8730\n",
      "Epoch 879:\ttrain_loss: 0.1655\ttrain_acc: 0.9667\tval_loss: 0.4281\tval_acc: 0.8571\n",
      "Epoch 880:\ttrain_loss: 0.1499\ttrain_acc: 0.9667\tval_loss: 0.3964\tval_acc: 0.8730\n",
      "Epoch 881:\ttrain_loss: 0.1500\ttrain_acc: 0.9667\tval_loss: 0.5241\tval_acc: 0.8095\n",
      "Epoch 882:\ttrain_loss: 0.2169\ttrain_acc: 0.9333\tval_loss: 0.7035\tval_acc: 0.7619\n",
      "Epoch 883:\ttrain_loss: 0.2312\ttrain_acc: 0.9667\tval_loss: 0.3387\tval_acc: 0.9048\n",
      "Epoch 884:\ttrain_loss: 0.1357\ttrain_acc: 0.9667\tval_loss: 0.3747\tval_acc: 0.8730\n",
      "Epoch 885:\ttrain_loss: 0.2056\ttrain_acc: 0.9333\tval_loss: 0.5088\tval_acc: 0.8254\n",
      "Epoch 886:\ttrain_loss: 0.1384\ttrain_acc: 0.9667\tval_loss: 0.5037\tval_acc: 0.8254\n",
      "Epoch 887:\ttrain_loss: 0.1359\ttrain_acc: 0.9667\tval_loss: 0.5469\tval_acc: 0.8254\n",
      "Epoch 888:\ttrain_loss: 0.1421\ttrain_acc: 0.9667\tval_loss: 0.4602\tval_acc: 0.8571\n",
      "Epoch 889:\ttrain_loss: 0.1302\ttrain_acc: 0.9667\tval_loss: 0.4876\tval_acc: 0.8571\n",
      "Epoch 890:\ttrain_loss: 0.1784\ttrain_acc: 0.9667\tval_loss: 0.6485\tval_acc: 0.7778\n",
      "Epoch 891:\ttrain_loss: 0.2518\ttrain_acc: 0.9000\tval_loss: 0.4953\tval_acc: 0.7619\n",
      "Epoch 892:\ttrain_loss: 0.1285\ttrain_acc: 0.9667\tval_loss: 0.4174\tval_acc: 0.8571\n",
      "Epoch 893:\ttrain_loss: 0.1090\ttrain_acc: 0.9667\tval_loss: 0.5763\tval_acc: 0.8095\n",
      "Epoch 894:\ttrain_loss: 0.1605\ttrain_acc: 0.9333\tval_loss: 0.4894\tval_acc: 0.8413\n",
      "Epoch 895:\ttrain_loss: 0.2358\ttrain_acc: 0.9333\tval_loss: 0.3806\tval_acc: 0.8730\n",
      "Epoch 896:\ttrain_loss: 0.1353\ttrain_acc: 0.9667\tval_loss: 0.4241\tval_acc: 0.8730\n",
      "Epoch 897:\ttrain_loss: 0.1026\ttrain_acc: 0.9667\tval_loss: 0.5279\tval_acc: 0.8571\n",
      "Epoch 898:\ttrain_loss: 0.1386\ttrain_acc: 0.9667\tval_loss: 0.6261\tval_acc: 0.7778\n",
      "Epoch 899:\ttrain_loss: 0.2273\ttrain_acc: 0.8667\tval_loss: 0.5257\tval_acc: 0.8254\n",
      "Epoch 900:\ttrain_loss: 0.2332\ttrain_acc: 0.9333\tval_loss: 0.4409\tval_acc: 0.8413\n",
      "Epoch 901:\ttrain_loss: 0.1077\ttrain_acc: 0.9667\tval_loss: 0.5064\tval_acc: 0.8571\n",
      "Epoch 902:\ttrain_loss: 0.1545\ttrain_acc: 0.9667\tval_loss: 0.5125\tval_acc: 0.8254\n",
      "Epoch 903:\ttrain_loss: 0.1146\ttrain_acc: 0.9667\tval_loss: 0.5357\tval_acc: 0.8413\n",
      "Epoch 904:\ttrain_loss: 0.1047\ttrain_acc: 0.9667\tval_loss: 0.3906\tval_acc: 0.8730\n",
      "Epoch 905:\ttrain_loss: 0.1126\ttrain_acc: 0.9667\tval_loss: 0.6476\tval_acc: 0.7619\n",
      "Epoch 906:\ttrain_loss: 0.5156\ttrain_acc: 0.8000\tval_loss: 0.6572\tval_acc: 0.5714\n",
      "Epoch 907:\ttrain_loss: 0.6026\ttrain_acc: 0.6000\tval_loss: 0.6354\tval_acc: 0.7460\n",
      "Epoch 908:\ttrain_loss: 0.4846\ttrain_acc: 0.8000\tval_loss: 0.5762\tval_acc: 0.7619\n",
      "Epoch 909:\ttrain_loss: 0.4761\ttrain_acc: 0.8333\tval_loss: 0.5536\tval_acc: 0.7460\n",
      "Epoch 910:\ttrain_loss: 0.4162\ttrain_acc: 0.8333\tval_loss: 0.5160\tval_acc: 0.8095\n",
      "Epoch 911:\ttrain_loss: 0.3713\ttrain_acc: 0.9000\tval_loss: 0.4411\tval_acc: 0.8254\n",
      "Epoch 912:\ttrain_loss: 0.3522\ttrain_acc: 0.9000\tval_loss: 0.4692\tval_acc: 0.8571\n",
      "Epoch 913:\ttrain_loss: 0.3150\ttrain_acc: 0.9333\tval_loss: 0.4287\tval_acc: 0.8730\n",
      "Epoch 914:\ttrain_loss: 0.2648\ttrain_acc: 0.9000\tval_loss: 0.3691\tval_acc: 0.8730\n",
      "Epoch 915:\ttrain_loss: 0.2365\ttrain_acc: 0.9667\tval_loss: 0.4123\tval_acc: 0.8730\n",
      "Epoch 916:\ttrain_loss: 0.1886\ttrain_acc: 0.9667\tval_loss: 0.5070\tval_acc: 0.7302\n",
      "Epoch 917:\ttrain_loss: 0.1640\ttrain_acc: 0.9667\tval_loss: 0.4290\tval_acc: 0.8571\n",
      "Epoch 918:\ttrain_loss: 0.1681\ttrain_acc: 0.9667\tval_loss: 0.4178\tval_acc: 0.7460\n",
      "Epoch 919:\ttrain_loss: 0.1325\ttrain_acc: 0.9667\tval_loss: 0.3998\tval_acc: 0.7460\n",
      "Epoch 920:\ttrain_loss: 0.1439\ttrain_acc: 0.9667\tval_loss: 0.4576\tval_acc: 0.7460\n",
      "Epoch 921:\ttrain_loss: 0.2249\ttrain_acc: 0.9333\tval_loss: 0.4400\tval_acc: 0.8413\n",
      "Epoch 922:\ttrain_loss: 0.1251\ttrain_acc: 0.9667\tval_loss: 0.4176\tval_acc: 0.7937\n",
      "Epoch 923:\ttrain_loss: 0.1121\ttrain_acc: 0.9667\tval_loss: 0.3882\tval_acc: 0.7619\n",
      "Epoch 924:\ttrain_loss: 0.1080\ttrain_acc: 1.0000\tval_loss: 0.6308\tval_acc: 0.6349\n",
      "Epoch 925:\ttrain_loss: 0.2256\ttrain_acc: 0.9333\tval_loss: 0.4986\tval_acc: 0.8413\n",
      "Epoch 926:\ttrain_loss: 0.1049\ttrain_acc: 0.9667\tval_loss: 0.5154\tval_acc: 0.7460\n",
      "Epoch 927:\ttrain_loss: 0.1033\ttrain_acc: 0.9667\tval_loss: 0.4655\tval_acc: 0.8095\n",
      "Epoch 928:\ttrain_loss: 0.0899\ttrain_acc: 0.9667\tval_loss: 0.5434\tval_acc: 0.7143\n",
      "Epoch 929:\ttrain_loss: 0.0898\ttrain_acc: 0.9667\tval_loss: 0.4820\tval_acc: 0.7460\n",
      "Epoch 930:\ttrain_loss: 0.1051\ttrain_acc: 0.9667\tval_loss: 0.5609\tval_acc: 0.8254\n",
      "Epoch 931:\ttrain_loss: 0.1019\ttrain_acc: 0.9667\tval_loss: 0.6296\tval_acc: 0.6349\n",
      "Epoch 932:\ttrain_loss: 0.1437\ttrain_acc: 0.9333\tval_loss: 0.4932\tval_acc: 0.8571\n",
      "Epoch 933:\ttrain_loss: 0.1104\ttrain_acc: 0.9667\tval_loss: 0.5333\tval_acc: 0.8254\n",
      "Epoch 934:\ttrain_loss: 0.1070\ttrain_acc: 0.9667\tval_loss: 0.5404\tval_acc: 0.8254\n",
      "Epoch 935:\ttrain_loss: 0.0886\ttrain_acc: 0.9667\tval_loss: 0.5126\tval_acc: 0.7778\n",
      "Epoch 936:\ttrain_loss: 0.1089\ttrain_acc: 0.9667\tval_loss: 0.5563\tval_acc: 0.8413\n",
      "Epoch 937:\ttrain_loss: 0.0879\ttrain_acc: 0.9667\tval_loss: 0.5606\tval_acc: 0.7619\n",
      "Epoch 938:\ttrain_loss: 0.0988\ttrain_acc: 0.9667\tval_loss: 0.4927\tval_acc: 0.7143\n",
      "Epoch 939:\ttrain_loss: 0.1191\ttrain_acc: 0.9667\tval_loss: 0.5019\tval_acc: 0.8413\n",
      "Epoch 940:\ttrain_loss: 0.1788\ttrain_acc: 0.9333\tval_loss: 0.4914\tval_acc: 0.8413\n",
      "Epoch 941:\ttrain_loss: 0.1862\ttrain_acc: 0.9333\tval_loss: 0.5605\tval_acc: 0.8254\n",
      "Epoch 942:\ttrain_loss: 0.0911\ttrain_acc: 0.9667\tval_loss: 0.5781\tval_acc: 0.8254\n",
      "Epoch 943:\ttrain_loss: 0.1144\ttrain_acc: 0.9667\tval_loss: 0.5664\tval_acc: 0.8095\n",
      "Epoch 944:\ttrain_loss: 0.0951\ttrain_acc: 0.9667\tval_loss: 0.5269\tval_acc: 0.8413\n",
      "Epoch 945:\ttrain_loss: 0.1095\ttrain_acc: 0.9667\tval_loss: 0.5624\tval_acc: 0.8254\n",
      "Epoch 946:\ttrain_loss: 0.1094\ttrain_acc: 0.9667\tval_loss: 0.5956\tval_acc: 0.7778\n",
      "Epoch 947:\ttrain_loss: 0.1238\ttrain_acc: 0.9667\tval_loss: 0.5644\tval_acc: 0.7143\n",
      "Epoch 948:\ttrain_loss: 0.1454\ttrain_acc: 0.9333\tval_loss: 0.5161\tval_acc: 0.7302\n",
      "Epoch 949:\ttrain_loss: 0.1166\ttrain_acc: 0.9333\tval_loss: 0.5418\tval_acc: 0.7143\n",
      "Epoch 950:\ttrain_loss: 0.1128\ttrain_acc: 0.9333\tval_loss: 0.5229\tval_acc: 0.7143\n",
      "Epoch 951:\ttrain_loss: 0.1280\ttrain_acc: 0.9333\tval_loss: 0.6935\tval_acc: 0.7778\n",
      "Epoch 952:\ttrain_loss: 0.1360\ttrain_acc: 0.9333\tval_loss: 0.6163\tval_acc: 0.8254\n",
      "Epoch 953:\ttrain_loss: 0.0956\ttrain_acc: 0.9667\tval_loss: 0.5254\tval_acc: 0.8095\n",
      "Epoch 954:\ttrain_loss: 0.0835\ttrain_acc: 0.9667\tval_loss: 0.5921\tval_acc: 0.7460\n",
      "Epoch 955:\ttrain_loss: 0.0995\ttrain_acc: 0.9333\tval_loss: 0.6029\tval_acc: 0.7460\n",
      "Epoch 956:\ttrain_loss: 0.0999\ttrain_acc: 0.9333\tval_loss: 0.6148\tval_acc: 0.7460\n",
      "Epoch 957:\ttrain_loss: 0.0929\ttrain_acc: 0.9667\tval_loss: 0.5466\tval_acc: 0.7460\n",
      "Epoch 958:\ttrain_loss: 0.0775\ttrain_acc: 0.9667\tval_loss: 0.5800\tval_acc: 0.7460\n",
      "Epoch 959:\ttrain_loss: 0.0783\ttrain_acc: 0.9667\tval_loss: 0.5015\tval_acc: 0.8571\n",
      "Epoch 960:\ttrain_loss: 0.1603\ttrain_acc: 0.9667\tval_loss: 0.5462\tval_acc: 0.7302\n",
      "Epoch 961:\ttrain_loss: 0.1671\ttrain_acc: 0.9667\tval_loss: 0.6913\tval_acc: 0.7460\n",
      "Epoch 962:\ttrain_loss: 0.1267\ttrain_acc: 0.9333\tval_loss: 0.6145\tval_acc: 0.7302\n",
      "Epoch 963:\ttrain_loss: 0.1103\ttrain_acc: 0.9333\tval_loss: 0.6950\tval_acc: 0.7302\n",
      "Epoch 964:\ttrain_loss: 0.0992\ttrain_acc: 0.9667\tval_loss: 0.6823\tval_acc: 0.7143\n",
      "Epoch 965:\ttrain_loss: 0.0777\ttrain_acc: 0.9667\tval_loss: 0.6553\tval_acc: 0.7143\n",
      "Epoch 966:\ttrain_loss: 0.0783\ttrain_acc: 0.9667\tval_loss: 0.6763\tval_acc: 0.7460\n",
      "Epoch 967:\ttrain_loss: 0.0931\ttrain_acc: 0.9667\tval_loss: 0.6327\tval_acc: 0.7143\n",
      "Epoch 968:\ttrain_loss: 0.0796\ttrain_acc: 0.9667\tval_loss: 0.6754\tval_acc: 0.6984\n",
      "Epoch 969:\ttrain_loss: 0.0935\ttrain_acc: 0.9667\tval_loss: 0.6764\tval_acc: 0.7302\n",
      "Epoch 970:\ttrain_loss: 0.0776\ttrain_acc: 0.9667\tval_loss: 0.5702\tval_acc: 0.7302\n",
      "Epoch 971:\ttrain_loss: 0.1080\ttrain_acc: 1.0000\tval_loss: 0.5642\tval_acc: 0.8095\n",
      "Epoch 972:\ttrain_loss: 0.1184\ttrain_acc: 0.9667\tval_loss: 0.5744\tval_acc: 0.7778\n",
      "Epoch 973:\ttrain_loss: 0.1064\ttrain_acc: 0.9667\tval_loss: 0.5541\tval_acc: 0.7302\n",
      "Epoch 974:\ttrain_loss: 0.1010\ttrain_acc: 0.9667\tval_loss: 0.4808\tval_acc: 0.8095\n",
      "Epoch 975:\ttrain_loss: 0.0841\ttrain_acc: 1.0000\tval_loss: 0.5173\tval_acc: 0.7937\n",
      "Epoch 976:\ttrain_loss: 0.1037\ttrain_acc: 0.9667\tval_loss: 0.5757\tval_acc: 0.8095\n",
      "Epoch 977:\ttrain_loss: 0.0935\ttrain_acc: 1.0000\tval_loss: 0.5315\tval_acc: 0.7778\n",
      "Epoch 978:\ttrain_loss: 0.1180\ttrain_acc: 0.9667\tval_loss: 0.5884\tval_acc: 0.7302\n",
      "Epoch 979:\ttrain_loss: 0.1528\ttrain_acc: 0.9667\tval_loss: 0.6065\tval_acc: 0.8095\n",
      "Epoch 980:\ttrain_loss: 0.0887\ttrain_acc: 1.0000\tval_loss: 0.5912\tval_acc: 0.7778\n",
      "Epoch 981:\ttrain_loss: 0.0768\ttrain_acc: 1.0000\tval_loss: 0.5931\tval_acc: 0.7778\n",
      "Epoch 982:\ttrain_loss: 0.0780\ttrain_acc: 0.9667\tval_loss: 0.6050\tval_acc: 0.7619\n",
      "Epoch 983:\ttrain_loss: 0.1839\ttrain_acc: 0.9333\tval_loss: 0.5373\tval_acc: 0.7937\n",
      "Epoch 984:\ttrain_loss: 0.0907\ttrain_acc: 0.9667\tval_loss: 0.5985\tval_acc: 0.7778\n",
      "Epoch 985:\ttrain_loss: 0.0833\ttrain_acc: 1.0000\tval_loss: 0.5447\tval_acc: 0.7778\n",
      "Epoch 986:\ttrain_loss: 0.0816\ttrain_acc: 1.0000\tval_loss: 0.5440\tval_acc: 0.7778\n",
      "Epoch 987:\ttrain_loss: 0.0805\ttrain_acc: 1.0000\tval_loss: 0.5419\tval_acc: 0.7778\n",
      "Epoch 988:\ttrain_loss: 0.0791\ttrain_acc: 1.0000\tval_loss: 0.5391\tval_acc: 0.7778\n",
      "Epoch 989:\ttrain_loss: 0.0774\ttrain_acc: 1.0000\tval_loss: 0.5437\tval_acc: 0.7778\n",
      "Epoch 990:\ttrain_loss: 0.0757\ttrain_acc: 1.0000\tval_loss: 0.5493\tval_acc: 0.7937\n",
      "Epoch 991:\ttrain_loss: 0.0739\ttrain_acc: 1.0000\tval_loss: 0.5572\tval_acc: 0.8254\n",
      "Epoch 992:\ttrain_loss: 0.0718\ttrain_acc: 1.0000\tval_loss: 0.5761\tval_acc: 0.8254\n",
      "Epoch 993:\ttrain_loss: 0.0694\ttrain_acc: 1.0000\tval_loss: 0.5945\tval_acc: 0.8254\n",
      "Epoch 994:\ttrain_loss: 0.0678\ttrain_acc: 1.0000\tval_loss: 0.6295\tval_acc: 0.8095\n",
      "Epoch 995:\ttrain_loss: 0.0664\ttrain_acc: 1.0000\tval_loss: 0.7361\tval_acc: 0.7937\n",
      "Epoch 996:\ttrain_loss: 0.0753\ttrain_acc: 0.9667\tval_loss: 0.7688\tval_acc: 0.7937\n",
      "Epoch 997:\ttrain_loss: 0.0670\ttrain_acc: 1.0000\tval_loss: 0.7738\tval_acc: 0.7937\n",
      "Epoch 998:\ttrain_loss: 0.0658\ttrain_acc: 1.0000\tval_loss: 0.7791\tval_acc: 0.7937\n",
      "Epoch 999:\ttrain_loss: 0.0647\ttrain_acc: 1.0000\tval_loss: 0.7870\tval_acc: 0.7937\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Network(input_size=x_train.shape[1], output_size=1).to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.RMSprop(model.network.parameters(), lr=0.0025, alpha=0.8)\n",
    "model.train()\n",
    "wandb.watch(model)\n",
    "model.fit(X=x_train, y=y_train, X_val=x_val, y_val=y_val, n_epochs=1000, loss_fn=loss_fn, optimizer=optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
