{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import wandb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:boo046oy) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▅▆██▅█▆▅███▅▆▅███▆▆██▅▆█▅█████████▆█▆▅█</td></tr><tr><td>loss</td><td>▆▅▆▃▄▆▃▃▄▁▃▂▅▅█▂▂▃▃▃▂▃▄▅▂▅▂▁▁▁▁▂▂▂▁▃▁▃▅▂</td></tr><tr><td>val_acc</td><td>▁▄▅▆▄▄▇▇▇▇▇██▇███▆██▆▆▇▇▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.6</td></tr><tr><td>loss</td><td>0.92933</td></tr><tr><td>val_acc</td><td>0.7619</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jumping-plasma-1</strong> at: <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-acc-batch/runs/boo046oy' target=\"_blank\">https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-acc-batch/runs/boo046oy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230330_165523-boo046oy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:boo046oy). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Leonard\\Desktop\\2.semester\\NN\\NN_assignment_1\\wandb\\run-20230330_165550-pejrscuv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-acc-batch/runs/pejrscuv' target=\"_blank\">breezy-field-2</a></strong> to <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-acc-batch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-acc-batch' target=\"_blank\">https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-acc-batch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-acc-batch/runs/pejrscuv' target=\"_blank\">https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-acc-batch/runs/pejrscuv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-acc-batch/runs/pejrscuv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1c53af08400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"nn-assignment-1-pytorch\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/sonar.all-data\") as all_data_file:\n",
    "    lines = all_data_file.readlines()\n",
    "    all_data = []\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        line = line.strip().split(',')\n",
    "        label = line.pop()\n",
    "        #line = np.asarray(line, dtype=float)\n",
    "        if label == \"R\":\n",
    "            labels.append(0)\n",
    "            all_data.append(line)\n",
    "        elif label == \"M\":\n",
    "            labels.append(1)\n",
    "            all_data.append(line)\n",
    "        else:\n",
    "            pass\n",
    "    all_data = np.asarray(all_data, dtype=float)\n",
    "    labels = np.asarray(labels, dtype=float)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data normalization, dropping columns with correlation lower than 0.1 with the resulting class, and spliting into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_2darray(d2array):\n",
    "    output_array = []\n",
    "    for array in d2array:\n",
    "        x = (array - np.mean(array)) / np.std(array)\n",
    "        #x[x<0] *= -1\n",
    "        #x = (x-np.min(x))/(np.max(x) - np.min(x))\n",
    "        output_array.append(x)\n",
    "    return np.asarray(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_2(input_data, input_labels):\n",
    "    indices = np.random.permutation(input_data.shape[0])\n",
    "    split_idx = math.floor(input_data.shape[0] * 0.7)\n",
    "    train_idx, test_idx = indices[:split_idx], indices[split_idx:]\n",
    "    train_data, test_data = input_data[train_idx,:], input_data[test_idx,:]\n",
    "    train_labels, test_labels = input_labels[train_idx], input_labels[test_idx]\n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 37)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm = normalise_2darray(all_data)\n",
    "\n",
    "corr_arr = []\n",
    "for idx, row in enumerate(x_norm):\n",
    "    arr = np.asarray(list(row) + [labels[idx]])\n",
    "    corr_arr.append(arr)\n",
    "corr_arr = np.asarray(corr_arr)\n",
    "corr_map = np.corrcoef(corr_arr, rowvar=False).round(2)\n",
    "corr_map = corr_map[:, 60]  # keep only final column of the heatmap | correlation to target class\n",
    "corr_map = corr_map.reshape((61, 1))\n",
    "\n",
    "to_drop = []\n",
    "for idx, value in enumerate(corr_map):\n",
    "    if value > -0.1 and value < 0.1:\n",
    "        to_drop.append(idx)\n",
    "\n",
    "x_norm = np.delete(x_norm, to_drop, axis=1)\n",
    "x_norm.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 37) (63, 37) (145,) (63,)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#x_train, x_val = train_test_split(x_norm, test_size=0.3)\n",
    "#y_train, y_val = train_test_split(labels, test_size=0.3)\n",
    "x_train, x_val, y_train, y_val = train_test_split_2(x_norm, labels)\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up \"device\", converting the numpy arrays into torch tensors and passing them to device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([145, 37]) torch.Size([63, 37]) torch.Size([145, 1]) torch.Size([63, 1])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "x_val = torch.tensor(x_val, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device).reshape(-1,1).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).to(device).reshape(-1,1).to(device)\n",
    "\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size) -> None:\n",
    "        super(Network, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.network = self.__setup_network()\n",
    "\n",
    "    def __setup_network_old(self):\n",
    "        net = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        return net\n",
    "    def __setup_network(self):\n",
    "        net = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        return net\n",
    "    def forward(self, input):\n",
    "        return self.network(input)\n",
    "    \n",
    "    def fit(self, X, y, X_val, y_val, n_epochs, loss_fn, optimizer, batch_size=30):\n",
    "        batches = torch.arange(0, len(X), batch_size)\n",
    "        for epoch in range(n_epochs):\n",
    "            best_loss = 20000\n",
    "            best_acc = 0\n",
    "            self.train()\n",
    "            for batch_start in batches:\n",
    "                X_batch = X[batch_start:(batch_start+batch_size)]\n",
    "                y_batch = y[batch_start:(batch_start+batch_size)]\n",
    "\n",
    "                prediction = self.forward(X_batch)\n",
    "                loss = loss_fn(prediction, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                acc = (prediction.round() == y_batch).float().mean()\n",
    "                #wandb.log({\"loss\": loss})\n",
    "                #wandb.log({\"acc\": acc})\n",
    "                best_acc = acc if acc > best_acc else best_acc\n",
    "                best_loss = loss if loss < best_loss else best_loss\n",
    "            wandb.log({\"loss\": best_loss})\n",
    "            wandb.log({\"acc\": best_acc})\n",
    "            \n",
    "            self.eval()\n",
    "            y_pred = self.network(X_val)\n",
    "            val_acc = (y_pred.round() == y_val).float().mean()\n",
    "            val_loss = loss_fn(y_pred, y_val)\n",
    "            wandb.log({\"val_acc\": val_acc})\n",
    "            print(f\"Epoch {epoch}:\\ttrain_loss: {best_loss:.4f}\\ttrain_acc: {best_acc:.4f}\\tval_loss: {val_loss:.4f}\\tval_acc: {val_acc:.4f}\")\n",
    "                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\ttrain_loss: 0.6286\ttrain_acc: 1.0000\tval_loss: 0.6808\tval_acc: 0.5238\n",
      "Epoch 1:\ttrain_loss: 0.2592\ttrain_acc: 1.0000\tval_loss: 0.6418\tval_acc: 0.6190\n",
      "Epoch 2:\ttrain_loss: 0.2698\ttrain_acc: 1.0000\tval_loss: 0.4677\tval_acc: 0.7937\n",
      "Epoch 3:\ttrain_loss: 0.0969\ttrain_acc: 1.0000\tval_loss: 0.4945\tval_acc: 0.7619\n",
      "Epoch 4:\ttrain_loss: 0.0895\ttrain_acc: 1.0000\tval_loss: 0.4632\tval_acc: 0.8095\n",
      "Epoch 5:\ttrain_loss: 0.0462\ttrain_acc: 1.0000\tval_loss: 0.4689\tval_acc: 0.8254\n",
      "Epoch 6:\ttrain_loss: 0.0278\ttrain_acc: 1.0000\tval_loss: 0.4912\tval_acc: 0.8254\n",
      "Epoch 7:\ttrain_loss: 0.0334\ttrain_acc: 1.0000\tval_loss: 0.4872\tval_acc: 0.8095\n",
      "Epoch 8:\ttrain_loss: 0.0260\ttrain_acc: 1.0000\tval_loss: 0.5687\tval_acc: 0.8095\n",
      "Epoch 9:\ttrain_loss: 0.0086\ttrain_acc: 1.0000\tval_loss: 0.5105\tval_acc: 0.7778\n",
      "Epoch 10:\ttrain_loss: 0.0046\ttrain_acc: 1.0000\tval_loss: 0.5831\tval_acc: 0.8095\n",
      "Epoch 11:\ttrain_loss: 0.0067\ttrain_acc: 1.0000\tval_loss: 0.6920\tval_acc: 0.8095\n",
      "Epoch 12:\ttrain_loss: 0.0039\ttrain_acc: 1.0000\tval_loss: 0.7716\tval_acc: 0.7778\n",
      "Epoch 13:\ttrain_loss: 0.0008\ttrain_acc: 1.0000\tval_loss: 0.8421\tval_acc: 0.7937\n",
      "Epoch 14:\ttrain_loss: 0.0042\ttrain_acc: 1.0000\tval_loss: 0.7075\tval_acc: 0.8413\n",
      "Epoch 15:\ttrain_loss: 0.0007\ttrain_acc: 1.0000\tval_loss: 0.7391\tval_acc: 0.7143\n",
      "Epoch 16:\ttrain_loss: 0.0005\ttrain_acc: 1.0000\tval_loss: 0.9886\tval_acc: 0.8095\n",
      "Epoch 17:\ttrain_loss: 0.0000\ttrain_acc: 1.0000\tval_loss: 1.4249\tval_acc: 0.7937\n",
      "Epoch 18:\ttrain_loss: 0.0002\ttrain_acc: 1.0000\tval_loss: 1.1803\tval_acc: 0.7460\n",
      "Epoch 19:\ttrain_loss: 0.0000\ttrain_acc: 1.0000\tval_loss: 1.2812\tval_acc: 0.7302\n",
      "Epoch 20:\ttrain_loss: 0.0000\ttrain_acc: 1.0000\tval_loss: 3.4744\tval_acc: 0.7143\n",
      "Epoch 21:\ttrain_loss: 0.0000\ttrain_acc: 1.0000\tval_loss: 7.7816\tval_acc: 0.7937\n",
      "Epoch 22:\ttrain_loss: 0.0000\ttrain_acc: 1.0000\tval_loss: 6.7763\tval_acc: 0.7460\n",
      "Epoch 23:\ttrain_loss: 0.0000\ttrain_acc: 1.0000\tval_loss: 5.0673\tval_acc: 0.7937\n",
      "Epoch 24:\ttrain_loss: 0.0000\ttrain_acc: 1.0000\tval_loss: 1.0642\tval_acc: 0.7460\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Network(input_size=x_train.shape[1], output_size=1).to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.network.parameters(), lr=0.001, betas=(0.9, 0.99))\n",
    "model.train()\n",
    "wandb.watch(model)\n",
    "model.fit(X=x_train, y=y_train, X_val=x_val, y_val=y_val, n_epochs=25, loss_fn=loss_fn, optimizer=optimizer, batch_size=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
