{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonard\\anaconda3\\envs\\pytorch_nn_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import wandb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleonard-puskac\u001b[0m (\u001b[33mfiit-nn-2023-lp-vs\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Leonard\\Desktop\\2.semester\\NN\\NN_assignment_1\\wandb\\run-20230330_172447-9rmyzt3s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-50-epochs/runs/9rmyzt3s' target=\"_blank\">rare-moon-2</a></strong> to <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-50-epochs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-50-epochs' target=\"_blank\">https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-50-epochs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-50-epochs/runs/9rmyzt3s' target=\"_blank\">https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-50-epochs/runs/9rmyzt3s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignment-1-pytorch-50-epochs/runs/9rmyzt3s?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2b7908a6940>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"nn-assignment-1-pytorch-50-epochs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/sonar.all-data\") as all_data_file:\n",
    "    lines = all_data_file.readlines()\n",
    "    all_data = []\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        line = line.strip().split(',')\n",
    "        label = line.pop()\n",
    "        #line = np.asarray(line, dtype=float)\n",
    "        if label == \"R\":\n",
    "            labels.append(0)\n",
    "            all_data.append(line)\n",
    "        elif label == \"M\":\n",
    "            labels.append(1)\n",
    "            all_data.append(line)\n",
    "        else:\n",
    "            pass\n",
    "    all_data = np.asarray(all_data, dtype=float)\n",
    "    labels = np.asarray(labels, dtype=float)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data normalization, dropping columns with correlation lower than 0.1 with the resulting class, and spliting into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_2darray(d2array):\n",
    "    output_array = []\n",
    "    for array in d2array:\n",
    "        x = (array - np.mean(array)) / np.std(array)\n",
    "        #x[x<0] *= -1\n",
    "        #x = (x-np.min(x))/(np.max(x) - np.min(x))\n",
    "        output_array.append(x)\n",
    "    return np.asarray(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_2(input_data, input_labels):\n",
    "    indices = np.random.permutation(input_data.shape[0])\n",
    "    split_idx = math.floor(input_data.shape[0] * 0.7)\n",
    "    train_idx, test_idx = indices[:split_idx], indices[split_idx:]\n",
    "    train_data, test_data = input_data[train_idx,:], input_data[test_idx,:]\n",
    "    train_labels, test_labels = input_labels[train_idx], input_labels[test_idx]\n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 37)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm = normalise_2darray(all_data)\n",
    "\n",
    "corr_arr = []\n",
    "for idx, row in enumerate(x_norm):\n",
    "    arr = np.asarray(list(row) + [labels[idx]])\n",
    "    corr_arr.append(arr)\n",
    "corr_arr = np.asarray(corr_arr)\n",
    "corr_map = np.corrcoef(corr_arr, rowvar=False).round(2)\n",
    "corr_map = corr_map[:, 60]  # keep only final column of the heatmap | correlation to target class\n",
    "corr_map = corr_map.reshape((61, 1))\n",
    "\n",
    "to_drop = []\n",
    "for idx, value in enumerate(corr_map):\n",
    "    if value > -0.1 and value < 0.1:\n",
    "        to_drop.append(idx)\n",
    "\n",
    "x_norm = np.delete(x_norm, to_drop, axis=1)\n",
    "x_norm.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 37) (63, 37) (145,) (63,)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#x_train, x_val = train_test_split(x_norm, test_size=0.3)\n",
    "#y_train, y_val = train_test_split(labels, test_size=0.3)\n",
    "x_train, x_val, y_train, y_val = train_test_split_2(x_norm, labels)\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up \"device\", converting the numpy arrays into torch tensors and passing them to device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([145, 37]) torch.Size([63, 37]) torch.Size([145, 1]) torch.Size([63, 1])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "x_val = torch.tensor(x_val, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device).reshape(-1,1).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).to(device).reshape(-1,1).to(device)\n",
    "\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size) -> None:\n",
    "        super(Network, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.network = self.__setup_network()\n",
    "\n",
    "    def __setup_network_old(self):\n",
    "        net = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        return net\n",
    "    def __setup_network(self):\n",
    "        net = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        return net\n",
    "    def forward(self, input):\n",
    "        return self.network(input)\n",
    "    \n",
    "    def fit(self, X, y, X_val, y_val, n_epochs, loss_fn, optimizer, batch_size=30):\n",
    "        batches = torch.arange(0, len(X), batch_size)\n",
    "        for epoch in range(n_epochs):\n",
    "            best_loss = 20000\n",
    "            best_acc = 0\n",
    "            self.train()\n",
    "            for batch_start in batches:\n",
    "                X_batch = X[batch_start:(batch_start+batch_size)]\n",
    "                y_batch = y[batch_start:(batch_start+batch_size)]\n",
    "\n",
    "                prediction = self.forward(X_batch)\n",
    "                loss = loss_fn(prediction, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                acc = (prediction.round() == y_batch).float().mean()\n",
    "                #wandb.log({\"loss\": loss})\n",
    "                #wandb.log({\"acc\": acc})\n",
    "                best_acc = acc if acc > best_acc else best_acc\n",
    "                best_loss = loss if loss < best_loss else best_loss\n",
    "            wandb.log({\"loss\": best_loss})\n",
    "            wandb.log({\"acc\": best_acc})\n",
    "            \n",
    "            self.eval()\n",
    "            y_pred = self.network(X_val)\n",
    "            val_acc = (y_pred.round() == y_val).float().mean()\n",
    "            val_loss = loss_fn(y_pred, y_val)\n",
    "            wandb.log({\"val_acc\": val_acc})\n",
    "            print(f\"Epoch {epoch}:\\ttrain_loss: {best_loss:.4f}\\ttrain_acc: {best_acc:.4f}\\tval_loss: {val_loss:.4f}\\tval_acc: {val_acc:.4f}\")\n",
    "                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\ttrain_loss: 0.6797\ttrain_acc: 0.6800\tval_loss: 0.6945\tval_acc: 0.4921\n",
      "Epoch 1:\ttrain_loss: 0.6686\ttrain_acc: 0.6800\tval_loss: 0.6874\tval_acc: 0.4921\n",
      "Epoch 2:\ttrain_loss: 0.6336\ttrain_acc: 0.7500\tval_loss: 0.6565\tval_acc: 0.6349\n",
      "Epoch 3:\ttrain_loss: 0.5371\ttrain_acc: 0.8000\tval_loss: 0.6036\tval_acc: 0.6984\n",
      "Epoch 4:\ttrain_loss: 0.3688\ttrain_acc: 0.8400\tval_loss: 0.5829\tval_acc: 0.7302\n",
      "Epoch 5:\ttrain_loss: 0.3075\ttrain_acc: 0.9000\tval_loss: 0.6099\tval_acc: 0.7619\n",
      "Epoch 6:\ttrain_loss: 0.3224\ttrain_acc: 0.8400\tval_loss: 0.5951\tval_acc: 0.7302\n",
      "Epoch 7:\ttrain_loss: 0.2967\ttrain_acc: 0.9200\tval_loss: 0.5755\tval_acc: 0.7143\n",
      "Epoch 8:\ttrain_loss: 0.2499\ttrain_acc: 0.9000\tval_loss: 0.5508\tval_acc: 0.7778\n",
      "Epoch 9:\ttrain_loss: 0.2514\ttrain_acc: 0.9500\tval_loss: 0.5527\tval_acc: 0.6984\n",
      "Epoch 10:\ttrain_loss: 0.2357\ttrain_acc: 0.9500\tval_loss: 0.5508\tval_acc: 0.7937\n",
      "Epoch 11:\ttrain_loss: 0.2489\ttrain_acc: 0.9500\tval_loss: 0.5558\tval_acc: 0.6984\n",
      "Epoch 12:\ttrain_loss: 0.2258\ttrain_acc: 0.9500\tval_loss: 0.5563\tval_acc: 0.7937\n",
      "Epoch 13:\ttrain_loss: 0.2330\ttrain_acc: 0.9500\tval_loss: 0.5605\tval_acc: 0.7619\n",
      "Epoch 14:\ttrain_loss: 0.2091\ttrain_acc: 0.9600\tval_loss: 0.5732\tval_acc: 0.7460\n",
      "Epoch 15:\ttrain_loss: 0.2065\ttrain_acc: 0.9500\tval_loss: 0.5833\tval_acc: 0.7778\n",
      "Epoch 16:\ttrain_loss: 0.1824\ttrain_acc: 0.9600\tval_loss: 0.6182\tval_acc: 0.7460\n",
      "Epoch 17:\ttrain_loss: 0.1779\ttrain_acc: 0.9600\tval_loss: 0.6422\tval_acc: 0.7302\n",
      "Epoch 18:\ttrain_loss: 0.1615\ttrain_acc: 0.9600\tval_loss: 0.6469\tval_acc: 0.7302\n",
      "Epoch 19:\ttrain_loss: 0.1442\ttrain_acc: 0.9600\tval_loss: 0.6738\tval_acc: 0.7302\n",
      "Epoch 20:\ttrain_loss: 0.1223\ttrain_acc: 0.9600\tval_loss: 0.6718\tval_acc: 0.7778\n",
      "Epoch 21:\ttrain_loss: 0.0875\ttrain_acc: 1.0000\tval_loss: 0.7029\tval_acc: 0.7778\n",
      "Epoch 22:\ttrain_loss: 0.0762\ttrain_acc: 1.0000\tval_loss: 0.7636\tval_acc: 0.7460\n",
      "Epoch 23:\ttrain_loss: 0.0708\ttrain_acc: 1.0000\tval_loss: 0.8191\tval_acc: 0.7460\n",
      "Epoch 24:\ttrain_loss: 0.0581\ttrain_acc: 1.0000\tval_loss: 0.8287\tval_acc: 0.7460\n",
      "Epoch 25:\ttrain_loss: 0.0596\ttrain_acc: 1.0000\tval_loss: 0.8147\tval_acc: 0.7460\n",
      "Epoch 26:\ttrain_loss: 0.0654\ttrain_acc: 1.0000\tval_loss: 0.8157\tval_acc: 0.7619\n",
      "Epoch 27:\ttrain_loss: 0.0431\ttrain_acc: 1.0000\tval_loss: 0.8566\tval_acc: 0.7778\n",
      "Epoch 28:\ttrain_loss: 0.0571\ttrain_acc: 0.9600\tval_loss: 1.0019\tval_acc: 0.6984\n",
      "Epoch 29:\ttrain_loss: 0.0493\ttrain_acc: 1.0000\tval_loss: 0.8493\tval_acc: 0.7460\n",
      "Epoch 30:\ttrain_loss: 0.1060\ttrain_acc: 0.9600\tval_loss: 0.7738\tval_acc: 0.7302\n",
      "Epoch 31:\ttrain_loss: 0.0805\ttrain_acc: 1.0000\tval_loss: 0.9038\tval_acc: 0.7143\n",
      "Epoch 32:\ttrain_loss: 0.0542\ttrain_acc: 1.0000\tval_loss: 0.7467\tval_acc: 0.7619\n",
      "Epoch 33:\ttrain_loss: 0.0562\ttrain_acc: 1.0000\tval_loss: 0.8444\tval_acc: 0.7937\n",
      "Epoch 34:\ttrain_loss: 0.0350\ttrain_acc: 1.0000\tval_loss: 0.8989\tval_acc: 0.7619\n",
      "Epoch 35:\ttrain_loss: 0.0378\ttrain_acc: 1.0000\tval_loss: 1.2183\tval_acc: 0.6984\n",
      "Epoch 36:\ttrain_loss: 0.0564\ttrain_acc: 1.0000\tval_loss: 0.8912\tval_acc: 0.7619\n",
      "Epoch 37:\ttrain_loss: 0.0318\ttrain_acc: 1.0000\tval_loss: 0.9866\tval_acc: 0.7619\n",
      "Epoch 38:\ttrain_loss: 0.0186\ttrain_acc: 1.0000\tval_loss: 1.0226\tval_acc: 0.7778\n",
      "Epoch 39:\ttrain_loss: 0.0132\ttrain_acc: 1.0000\tval_loss: 1.3202\tval_acc: 0.7302\n",
      "Epoch 40:\ttrain_loss: 0.0250\ttrain_acc: 1.0000\tval_loss: 1.1258\tval_acc: 0.7778\n",
      "Epoch 41:\ttrain_loss: 0.0251\ttrain_acc: 1.0000\tval_loss: 1.2822\tval_acc: 0.7143\n",
      "Epoch 42:\ttrain_loss: 0.0268\ttrain_acc: 1.0000\tval_loss: 1.0457\tval_acc: 0.7619\n",
      "Epoch 43:\ttrain_loss: 0.0405\ttrain_acc: 1.0000\tval_loss: 1.1522\tval_acc: 0.7460\n",
      "Epoch 44:\ttrain_loss: 0.0594\ttrain_acc: 1.0000\tval_loss: 0.8438\tval_acc: 0.7778\n",
      "Epoch 45:\ttrain_loss: 0.0708\ttrain_acc: 0.9600\tval_loss: 0.7377\tval_acc: 0.7937\n",
      "Epoch 46:\ttrain_loss: 0.0518\ttrain_acc: 1.0000\tval_loss: 0.8434\tval_acc: 0.7302\n",
      "Epoch 47:\ttrain_loss: 0.0534\ttrain_acc: 1.0000\tval_loss: 0.8240\tval_acc: 0.7619\n",
      "Epoch 48:\ttrain_loss: 0.0582\ttrain_acc: 1.0000\tval_loss: 0.9607\tval_acc: 0.7619\n",
      "Epoch 49:\ttrain_loss: 0.0203\ttrain_acc: 1.0000\tval_loss: 1.0710\tval_acc: 0.7937\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Network(input_size=x_train.shape[1], output_size=1).to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.network.parameters(), lr=0.001, betas=(0.9, 0.99))\n",
    "model.train()\n",
    "wandb.watch(model)\n",
    "model.fit(X=x_train, y=y_train, X_val=x_val, y_val=y_val, n_epochs=50, loss_fn=loss_fn, optimizer=optimizer, batch_size=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
