{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/sonar.all-data\") as all_data_file:\n",
    "    lines = all_data_file.readlines()\n",
    "    all_data = []\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        line = line.strip().split(',')\n",
    "        label = line.pop()\n",
    "        #line = np.asarray(line, dtype=float)\n",
    "        if label == \"R\":\n",
    "            labels.append(0)\n",
    "            all_data.append(line)\n",
    "        elif label == \"M\":\n",
    "            labels.append(1)\n",
    "            all_data.append(line)\n",
    "        else:\n",
    "            pass\n",
    "    all_data = np.asarray(all_data, dtype=float)\n",
    "    labels = np.asarray(labels, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_2darray(d2array):\n",
    "    output_array = []\n",
    "    for array in d2array:\n",
    "        x = (array - np.mean(array)) / np.std(array)\n",
    "        x[x<0] *= -1\n",
    "        x = (x-np.min(x))/(np.max(x) - np.min(x))\n",
    "        output_array.append(x)\n",
    "    return np.asarray(output_array)\n",
    "x_norm = normalise_2darray(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(input_data, input_labels):\n",
    "    indices = np.random.permutation(input_data.shape[0])\n",
    "    split_idx = math.floor(input_data.shape[0] * 0.7)\n",
    "    train_idx, test_idx = indices[:split_idx], indices[split_idx:]\n",
    "    train_data, test_data = input_data[train_idx,:], input_data[test_idx,:]\n",
    "    train_labels, test_labels = input_labels[train_idx], input_labels[test_idx]\n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_arr = []\n",
    "for idx, row in enumerate(x_norm):\n",
    "    arr = np.asarray(list(row) + [labels[idx]])\n",
    "    corr_arr.append(arr)\n",
    "corr_arr = np.asarray(corr_arr)\n",
    "corr_map = np.corrcoef(corr_arr, rowvar=False).round(2)\n",
    "corr_map = corr_map[:, 60]  # keep only final column of the heatmap | correlation to target class\n",
    "corr_map = corr_map.reshape((61, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 4,\n",
       " 7,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 31,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 48]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = []\n",
    "for idx, value in enumerate(corr_map):\n",
    "    if value > -0.1 and value < 0.1:\n",
    "        to_drop.append(idx)\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 35)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm = np.delete(x_norm, to_drop, axis=1)\n",
    "x_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 35) (63, 35) (145,) (63, 35)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(x_norm, labels)\n",
    "print(train_data.shape, test_data.shape, train_labels.shape, test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([145, 35]) torch.Size([63, 35]) torch.Size([145, 1]) torch.Size([63, 1])\n"
     ]
    }
   ],
   "source": [
    "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.float32).reshape(-1,1)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.float32).reshape(-1,1)\n",
    "print(train_data.shape, test_data.shape, train_labels.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size) -> None:\n",
    "        super(Network, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.network = self.__setup_network()\n",
    "\n",
    "    def __setup_network(self):\n",
    "        net = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        return net\n",
    "    def forward(self, input):\n",
    "        return self.network(input)\n",
    "    \n",
    "    def fit(self, input, labels, n_epochs, loss_fn, optimizer, batch_size=10):\n",
    "        for epoch in range(n_epochs):\n",
    "            start = 0\n",
    "            #for i in range(math.floor(input.shape[0]/batch_size)):\n",
    "            #    X_batch = input[start:(start+batch_size)]\n",
    "            #    Ybatch = labels[start:(start+batch_size)]\n",
    "            #    start += batch_size\n",
    "            #    pass\n",
    "            prediction = self.forward(input)\n",
    "            loss = loss_fn(prediction, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"Epoch {epoch}:\\tloss:{loss}\")\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\tloss:0.7048636674880981\n",
      "Epoch 1:\tloss:0.7330915331840515\n",
      "Epoch 2:\tloss:0.6931250691413879\n",
      "Epoch 3:\tloss:0.6885966062545776\n",
      "Epoch 4:\tloss:0.6879522204399109\n",
      "Epoch 5:\tloss:0.6878359317779541\n",
      "Epoch 6:\tloss:0.6877980828285217\n",
      "Epoch 7:\tloss:0.6877853870391846\n",
      "Epoch 8:\tloss:0.6877989172935486\n",
      "Epoch 9:\tloss:0.6879156231880188\n",
      "Epoch 10:\tloss:0.68852299451828\n",
      "Epoch 11:\tloss:0.6916123628616333\n",
      "Epoch 12:\tloss:0.7001680135726929\n",
      "Epoch 13:\tloss:0.7000827193260193\n",
      "Epoch 14:\tloss:0.6922555565834045\n",
      "Epoch 15:\tloss:0.6886746883392334\n",
      "Epoch 16:\tloss:0.6869450211524963\n",
      "Epoch 17:\tloss:0.6852424144744873\n",
      "Epoch 18:\tloss:0.6835047006607056\n",
      "Epoch 19:\tloss:0.6855544447898865\n",
      "Epoch 20:\tloss:0.69038987159729\n",
      "Epoch 21:\tloss:0.6874575018882751\n",
      "Epoch 22:\tloss:0.6728107333183289\n",
      "Epoch 23:\tloss:0.6651995182037354\n",
      "Epoch 24:\tloss:0.6607453227043152\n",
      "Epoch 25:\tloss:0.669995903968811\n",
      "Epoch 26:\tloss:0.6651620864868164\n",
      "Epoch 27:\tloss:0.6630240678787231\n",
      "Epoch 28:\tloss:0.6473339200019836\n",
      "Epoch 29:\tloss:0.6401661038398743\n",
      "Epoch 30:\tloss:0.6346213221549988\n",
      "Epoch 31:\tloss:0.6408358216285706\n",
      "Epoch 32:\tloss:0.6761332750320435\n",
      "Epoch 33:\tloss:0.6600891947746277\n",
      "Epoch 34:\tloss:0.6271111369132996\n",
      "Epoch 35:\tloss:0.6135361194610596\n",
      "Epoch 36:\tloss:0.605744481086731\n",
      "Epoch 37:\tloss:0.6202922463417053\n",
      "Epoch 38:\tloss:0.6588003039360046\n",
      "Epoch 39:\tloss:0.6462351679801941\n",
      "Epoch 40:\tloss:0.5996150374412537\n",
      "Epoch 41:\tloss:0.5945267081260681\n",
      "Epoch 42:\tloss:0.6077571511268616\n",
      "Epoch 43:\tloss:0.6339311003684998\n",
      "Epoch 44:\tloss:0.5903123021125793\n",
      "Epoch 45:\tloss:0.6038230061531067\n",
      "Epoch 46:\tloss:0.5904196500778198\n",
      "Epoch 47:\tloss:0.6221617460250854\n",
      "Epoch 48:\tloss:0.5692098736763\n",
      "Epoch 49:\tloss:0.5862249732017517\n",
      "Epoch 50:\tloss:0.5859847664833069\n",
      "Epoch 51:\tloss:0.6309767365455627\n",
      "Epoch 52:\tloss:0.5485961437225342\n",
      "Epoch 53:\tloss:0.5450857281684875\n",
      "Epoch 54:\tloss:0.569427490234375\n",
      "Epoch 55:\tloss:0.6429683566093445\n",
      "Epoch 56:\tloss:0.5394290089607239\n",
      "Epoch 57:\tloss:0.541474461555481\n",
      "Epoch 58:\tloss:0.5531716346740723\n",
      "Epoch 59:\tloss:0.6243078112602234\n",
      "Epoch 60:\tloss:0.53950434923172\n",
      "Epoch 61:\tloss:0.5479941368103027\n",
      "Epoch 62:\tloss:0.5405076742172241\n",
      "Epoch 63:\tloss:0.5997124314308167\n",
      "Epoch 64:\tloss:0.5425765514373779\n",
      "Epoch 65:\tloss:0.5690714716911316\n",
      "Epoch 66:\tloss:0.5262562036514282\n",
      "Epoch 67:\tloss:0.5325933694839478\n",
      "Epoch 68:\tloss:0.5138623714447021\n",
      "Epoch 69:\tloss:0.5354483723640442\n",
      "Epoch 70:\tloss:0.5407924652099609\n",
      "Epoch 71:\tloss:0.6965558528900146\n",
      "Epoch 72:\tloss:0.5197412371635437\n",
      "Epoch 73:\tloss:0.5118575692176819\n",
      "Epoch 74:\tloss:0.5051363706588745\n",
      "Epoch 75:\tloss:0.4978085160255432\n",
      "Epoch 76:\tloss:0.4907241761684418\n",
      "Epoch 77:\tloss:0.5021159052848816\n",
      "Epoch 78:\tloss:0.7257593870162964\n",
      "Epoch 79:\tloss:0.5020242929458618\n",
      "Epoch 80:\tloss:0.4957096576690674\n",
      "Epoch 81:\tloss:0.5445750951766968\n",
      "Epoch 82:\tloss:0.7119454145431519\n",
      "Epoch 83:\tloss:0.5344259142875671\n",
      "Epoch 84:\tloss:0.5056455731391907\n",
      "Epoch 85:\tloss:0.49604329466819763\n",
      "Epoch 86:\tloss:0.4883374869823456\n",
      "Epoch 87:\tloss:0.5167344808578491\n",
      "Epoch 88:\tloss:0.6919367909431458\n",
      "Epoch 89:\tloss:0.5107142925262451\n",
      "Epoch 90:\tloss:0.4974546730518341\n",
      "Epoch 91:\tloss:0.5134032368659973\n",
      "Epoch 92:\tloss:0.5517377853393555\n",
      "Epoch 93:\tloss:0.6769987344741821\n",
      "Epoch 94:\tloss:0.5336853265762329\n",
      "Epoch 95:\tloss:0.5039426684379578\n",
      "Epoch 96:\tloss:0.49235883355140686\n",
      "Epoch 97:\tloss:0.48362815380096436\n",
      "Epoch 98:\tloss:0.5064451098442078\n",
      "Epoch 99:\tloss:0.6651793718338013\n"
     ]
    }
   ],
   "source": [
    "model = Network(input_size=35, output_size=1)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.RMSprop(model.network.parameters(), lr=0.0025, alpha=0.8)\n",
    "model.train()\n",
    "model.fit(input=train_data, labels=train_labels, n_epochs=1000, loss_fn=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7088],\n",
      "        [0.0435],\n",
      "        [0.0397],\n",
      "        [0.7088],\n",
      "        [0.7087],\n",
      "        [0.0652],\n",
      "        [0.0393],\n",
      "        [0.7085],\n",
      "        [0.7087],\n",
      "        [0.7085],\n",
      "        [0.7085],\n",
      "        [0.7056],\n",
      "        [0.7018],\n",
      "        [0.7068],\n",
      "        [0.7086],\n",
      "        [0.7084],\n",
      "        [0.7083],\n",
      "        [0.7088],\n",
      "        [0.6996],\n",
      "        [0.7088],\n",
      "        [0.7089],\n",
      "        [0.7086],\n",
      "        [0.0418],\n",
      "        [0.7086],\n",
      "        [0.7012],\n",
      "        [0.7089],\n",
      "        [0.7074],\n",
      "        [0.7088],\n",
      "        [0.7038],\n",
      "        [0.7072],\n",
      "        [0.0455],\n",
      "        [0.6789],\n",
      "        [0.7073],\n",
      "        [0.0512],\n",
      "        [0.6948],\n",
      "        [0.7086],\n",
      "        [0.7088],\n",
      "        [0.7089],\n",
      "        [0.7079],\n",
      "        [0.7089],\n",
      "        [0.2311],\n",
      "        [0.7076],\n",
      "        [0.4286],\n",
      "        [0.0797],\n",
      "        [0.7088],\n",
      "        [0.7084],\n",
      "        [0.0433],\n",
      "        [0.7084],\n",
      "        [0.0476],\n",
      "        [0.7057],\n",
      "        [0.6983],\n",
      "        [0.4122],\n",
      "        [0.7075],\n",
      "        [0.5942],\n",
      "        [0.7037],\n",
      "        [0.7083],\n",
      "        [0.6811],\n",
      "        [0.0431],\n",
      "        [0.7085],\n",
      "        [0.0397],\n",
      "        [0.7071],\n",
      "        [0.7064],\n",
      "        [0.7087]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(model.forward(test_data))\n",
    "print(test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
