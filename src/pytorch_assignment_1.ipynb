{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/datasets/sonar.all-data\") as all_data_file:\n",
    "    lines = all_data_file.readlines()\n",
    "    all_data = []\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        line = line.strip().split(',')\n",
    "        label = line.pop()\n",
    "        #line = np.asarray(line, dtype=float)\n",
    "        if label == \"R\":\n",
    "            labels.append(0)\n",
    "            all_data.append(line)\n",
    "        elif label == \"M\":\n",
    "            labels.append(1)\n",
    "            all_data.append(line)\n",
    "        else:\n",
    "            pass\n",
    "    all_data = np.asarray(all_data, dtype=float)\n",
    "    labels = np.asarray(labels, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_2darray(d2array):\n",
    "    output_array = []\n",
    "    for array in d2array:\n",
    "        x = (array - np.mean(array)) / np.std(array)\n",
    "        x[x<0] *= -1\n",
    "        x = (x-np.min(x))/(np.max(x) - np.min(x))\n",
    "        output_array.append(x)\n",
    "    return np.asarray(output_array)\n",
    "x_norm = normalise_2darray(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(input_data, input_labels):\n",
    "    indices = np.random.permutation(input_data.shape[0])\n",
    "    split_idx = math.floor(input_data.shape[0] * 0.9)\n",
    "    train_idx, test_idx = indices[:split_idx], indices[split_idx:]\n",
    "    train_data, test_data = torch.from_numpy(input_data[train_idx,:]).type(torch.FloatTensor), torch.from_numpy(input_data[test_idx,:]).type(torch.FloatTensor)\n",
    "    train_labels, test_labels = torch.from_numpy(input_labels[train_idx]).type(torch.FloatTensor), torch.from_numpy(input_labels[test_idx]).type(torch.FloatTensor)\n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(x_norm, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02   0.0371 0.0428 ... 0.0084 0.009  0.0032]\n",
      " [0.0453 0.0523 0.0843 ... 0.0049 0.0052 0.0044]\n",
      " [0.0262 0.0582 0.1099 ... 0.0164 0.0095 0.0078]\n",
      " ...\n",
      " [0.0522 0.0437 0.018  ... 0.0138 0.0077 0.0031]\n",
      " [0.0303 0.0353 0.049  ... 0.0079 0.0036 0.0048]\n",
      " [0.026  0.0363 0.0136 ... 0.0036 0.0061 0.0115]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(all_data)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size) -> None:\n",
    "        super(Network, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.network = self.__setup_network()\n",
    "\n",
    "    def __setup_network(self):\n",
    "        net = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, self.output_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        return net\n",
    "    def forward(self, input):\n",
    "        return self.network(input)\n",
    "    \n",
    "    def fit(self, input, labels, n_epochs, loss_fn, optimizer, batch_size=10):\n",
    "        for epoch in range(n_epochs):\n",
    "            start = 0\n",
    "            #for i in range(math.floor(input.shape[0]/batch_size)):\n",
    "            #    X_batch = input[start:(start+batch_size)]\n",
    "            #    Ybatch = labels[start:(start+batch_size)]\n",
    "            #    start += batch_size\n",
    "            #    pass\n",
    "            prediction = self.forward(input)\n",
    "            loss = loss_fn(prediction, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            print(f\"Epoch {epoch}:\\tloss:{loss}\")\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\tloss:0.6645808219909668\n",
      "Epoch 1:\tloss:0.6336681246757507\n",
      "Epoch 2:\tloss:0.604480504989624\n",
      "Epoch 3:\tloss:0.5780047178268433\n",
      "Epoch 4:\tloss:0.5535826086997986\n",
      "Epoch 5:\tloss:0.5440340638160706\n",
      "Epoch 6:\tloss:0.5436834692955017\n",
      "Epoch 7:\tloss:0.5439351797103882\n",
      "Epoch 8:\tloss:0.5444506406784058\n",
      "Epoch 9:\tloss:0.5450596213340759\n",
      "Epoch 10:\tloss:0.5476834774017334\n",
      "Epoch 11:\tloss:0.5481240749359131\n",
      "Epoch 12:\tloss:0.5454043745994568\n",
      "Epoch 13:\tloss:0.5453516840934753\n",
      "Epoch 14:\tloss:0.5454282760620117\n",
      "Epoch 15:\tloss:0.5466386079788208\n",
      "Epoch 16:\tloss:0.5453544855117798\n",
      "Epoch 17:\tloss:0.5452448129653931\n",
      "Epoch 18:\tloss:0.5451863408088684\n",
      "Epoch 19:\tloss:0.5451464653015137\n",
      "Epoch 20:\tloss:0.5451071262359619\n",
      "Epoch 21:\tloss:0.5450624227523804\n",
      "Epoch 22:\tloss:0.545005738735199\n",
      "Epoch 23:\tloss:0.54493248462677\n",
      "Epoch 24:\tloss:0.5448429584503174\n",
      "Epoch 25:\tloss:0.5447370409965515\n",
      "Epoch 26:\tloss:0.544613242149353\n",
      "Epoch 27:\tloss:0.5444712042808533\n",
      "Epoch 28:\tloss:0.5443148016929626\n",
      "Epoch 29:\tloss:0.5441464781761169\n",
      "Epoch 30:\tloss:0.5439680814743042\n",
      "Epoch 31:\tloss:0.5437813997268677\n",
      "Epoch 32:\tloss:0.5435901880264282\n",
      "Epoch 33:\tloss:0.54339599609375\n",
      "Epoch 34:\tloss:0.5432014465332031\n",
      "Epoch 35:\tloss:0.5430058836936951\n",
      "Epoch 36:\tloss:0.5428115725517273\n",
      "Epoch 37:\tloss:0.5426192283630371\n",
      "Epoch 38:\tloss:0.542428195476532\n",
      "Epoch 39:\tloss:0.5422385334968567\n",
      "Epoch 40:\tloss:0.5420500636100769\n",
      "Epoch 41:\tloss:0.5418628454208374\n",
      "Epoch 42:\tloss:0.5416767597198486\n",
      "Epoch 43:\tloss:0.5414919853210449\n",
      "Epoch 44:\tloss:0.5413084626197815\n",
      "Epoch 45:\tloss:0.5411261916160583\n",
      "Epoch 46:\tloss:0.5409455299377441\n",
      "Epoch 47:\tloss:0.5407658219337463\n",
      "Epoch 48:\tloss:0.5405877232551575\n",
      "Epoch 49:\tloss:0.540411114692688\n",
      "Epoch 50:\tloss:0.5402364134788513\n",
      "Epoch 51:\tloss:0.5400637984275818\n",
      "Epoch 52:\tloss:0.539893388748169\n",
      "Epoch 53:\tloss:0.5397252440452576\n",
      "Epoch 54:\tloss:0.5395597219467163\n",
      "Epoch 55:\tloss:0.5393968224525452\n",
      "Epoch 56:\tloss:0.539236843585968\n",
      "Epoch 57:\tloss:0.5390798449516296\n",
      "Epoch 58:\tloss:0.5389260053634644\n",
      "Epoch 59:\tloss:0.5387755632400513\n",
      "Epoch 60:\tloss:0.5386287569999695\n",
      "Epoch 61:\tloss:0.5384854078292847\n",
      "Epoch 62:\tloss:0.538345992565155\n",
      "Epoch 63:\tloss:0.5382105112075806\n",
      "Epoch 64:\tloss:0.5380792021751404\n",
      "Epoch 65:\tloss:0.5379520654678345\n",
      "Epoch 66:\tloss:0.5378293395042419\n",
      "Epoch 67:\tloss:0.5377110242843628\n",
      "Epoch 68:\tloss:0.5375973582267761\n",
      "Epoch 69:\tloss:0.5374882221221924\n",
      "Epoch 70:\tloss:0.5373839139938354\n",
      "Epoch 71:\tloss:0.5372843742370605\n",
      "Epoch 72:\tloss:0.5371896624565125\n",
      "Epoch 73:\tloss:0.5370998382568359\n",
      "Epoch 74:\tloss:0.537014901638031\n",
      "Epoch 75:\tloss:0.5369349718093872\n",
      "Epoch 76:\tloss:0.5368598699569702\n",
      "Epoch 77:\tloss:0.53678959608078\n",
      "Epoch 78:\tloss:0.5367241501808167\n",
      "Epoch 79:\tloss:0.5366634726524353\n",
      "Epoch 80:\tloss:0.536607563495636\n",
      "Epoch 81:\tloss:0.5365561246871948\n",
      "Epoch 82:\tloss:0.5365092158317566\n",
      "Epoch 83:\tloss:0.536466658115387\n",
      "Epoch 84:\tloss:0.5364282727241516\n",
      "Epoch 85:\tloss:0.5363940000534058\n",
      "Epoch 86:\tloss:0.5363635420799255\n",
      "Epoch 87:\tloss:0.5363368988037109\n",
      "Epoch 88:\tloss:0.5363136529922485\n",
      "Epoch 89:\tloss:0.5362938642501831\n",
      "Epoch 90:\tloss:0.5362770557403564\n",
      "Epoch 91:\tloss:0.5362631678581238\n",
      "Epoch 92:\tloss:0.536251962184906\n",
      "Epoch 93:\tloss:0.5362431406974792\n",
      "Epoch 94:\tloss:0.5362366437911987\n",
      "Epoch 95:\tloss:0.5362321138381958\n",
      "Epoch 96:\tloss:0.5362293124198914\n",
      "Epoch 97:\tloss:0.5362280607223511\n",
      "Epoch 98:\tloss:0.5362280607223511\n",
      "Epoch 99:\tloss:0.5362293124198914\n"
     ]
    }
   ],
   "source": [
    "model = Network(input_size=60, output_size=1)\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.9, betas=(0.8, 0.95))\n",
    "model.train()\n",
    "model.fit(input=train_data, labels=train_labels, n_epochs=100, loss_fn=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015],\n",
       "        [0.1015]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.forward(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
