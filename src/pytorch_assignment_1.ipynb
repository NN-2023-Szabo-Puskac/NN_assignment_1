{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/datasets/sonar.all-data\") as all_data_file:\n",
    "    lines = all_data_file.readlines()\n",
    "    all_data = []\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        line = line.strip().split(',')\n",
    "        label = line.pop()\n",
    "        #line = np.asarray(line, dtype=float)\n",
    "        if label == \"R\":\n",
    "            labels.append(0)\n",
    "            all_data.append(line)\n",
    "        elif label == \"M\":\n",
    "            labels.append(1)\n",
    "            all_data.append(line)\n",
    "        else:\n",
    "            pass\n",
    "    all_data = np.asarray(all_data, dtype=float)\n",
    "    labels = np.asarray(labels, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(all_data.shape[0])\n",
    "split_idx = math.floor(all_data.shape[0] * 0.9)\n",
    "train_idx, test_idx = indices[:split_idx], indices[split_idx:]\n",
    "train_data, test_data = torch.from_numpy(all_data[train_idx,:]).type(torch.FloatTensor), torch.from_numpy(all_data[test_idx,:]).type(torch.FloatTensor)\n",
    "train_labels, test_labels = torch.from_numpy(labels[train_idx]).type(torch.FloatTensor), torch.from_numpy(labels[test_idx]).type(torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02   0.0371 0.0428 ... 0.0084 0.009  0.0032]\n",
      " [0.0453 0.0523 0.0843 ... 0.0049 0.0052 0.0044]\n",
      " [0.0262 0.0582 0.1099 ... 0.0164 0.0095 0.0078]\n",
      " ...\n",
      " [0.0522 0.0437 0.018  ... 0.0138 0.0077 0.0031]\n",
      " [0.0303 0.0353 0.049  ... 0.0079 0.0036 0.0048]\n",
      " [0.026  0.0363 0.0136 ... 0.0036 0.0061 0.0115]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(all_data)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size) -> None:\n",
    "        super(Network, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.network = self.__setup_network()\n",
    "\n",
    "    def __setup_network(self):\n",
    "        net = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, self.output_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        return net\n",
    "    def forward(self, input):\n",
    "        return self.network(input)\n",
    "    \n",
    "    def fit(self, input, labels, n_epochs, loss_fn, optimizer, batch_size=10):\n",
    "        for epoch in range(n_epochs):\n",
    "            start = 0\n",
    "            #for i in range(math.floor(input.shape[0]/batch_size)):\n",
    "            #    X_batch = input[start:(start+batch_size)]\n",
    "            #    Ybatch = labels[start:(start+batch_size)]\n",
    "            #    start += batch_size\n",
    "            #    pass\n",
    "            prediction = self.forward(input)\n",
    "            loss = loss_fn(prediction, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            print(f\"Epoch {epoch}:\\tloss:{loss}\")\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\tloss:0.49889901280403137\n",
      "Epoch 1:\tloss:0.498904287815094\n",
      "Epoch 2:\tloss:0.49899664521217346\n",
      "Epoch 3:\tloss:0.4991132318973541\n",
      "Epoch 4:\tloss:0.4992375075817108\n",
      "Epoch 5:\tloss:0.4993674159049988\n",
      "Epoch 6:\tloss:0.4994971454143524\n",
      "Epoch 7:\tloss:0.49961763620376587\n",
      "Epoch 8:\tloss:0.49971503019332886\n",
      "Epoch 9:\tloss:0.49977847933769226\n",
      "Epoch 10:\tloss:0.49980172514915466\n",
      "Epoch 11:\tloss:0.4997945725917816\n",
      "Epoch 12:\tloss:0.49976563453674316\n",
      "Epoch 13:\tloss:0.4997183382511139\n",
      "Epoch 14:\tloss:0.49966076016426086\n",
      "Epoch 15:\tloss:0.499599426984787\n",
      "Epoch 16:\tloss:0.49954211711883545\n",
      "Epoch 17:\tloss:0.4994968771934509\n",
      "Epoch 18:\tloss:0.49946531653404236\n",
      "Epoch 19:\tloss:0.4994491636753082\n",
      "Epoch 20:\tloss:0.4994497299194336\n",
      "Epoch 21:\tloss:0.49946314096450806\n",
      "Epoch 22:\tloss:0.4994858205318451\n",
      "Epoch 23:\tloss:0.49951350688934326\n",
      "Epoch 24:\tloss:0.49954187870025635\n",
      "Epoch 25:\tloss:0.4995667040348053\n",
      "Epoch 26:\tloss:0.4995846748352051\n",
      "Epoch 27:\tloss:0.49959462881088257\n",
      "Epoch 28:\tloss:0.49959567189216614\n",
      "Epoch 29:\tloss:0.49958914518356323\n",
      "Epoch 30:\tloss:0.4995770752429962\n",
      "Epoch 31:\tloss:0.4995625615119934\n",
      "Epoch 32:\tloss:0.4995485544204712\n",
      "Epoch 33:\tloss:0.4995375871658325\n",
      "Epoch 34:\tloss:0.49953144788742065\n",
      "Epoch 35:\tloss:0.4995307922363281\n",
      "Epoch 36:\tloss:0.4995349049568176\n",
      "Epoch 37:\tloss:0.49954232573509216\n",
      "Epoch 38:\tloss:0.49955087900161743\n",
      "Epoch 39:\tloss:0.4995584189891815\n",
      "Epoch 40:\tloss:0.49956345558166504\n",
      "Epoch 41:\tloss:0.4995650053024292\n",
      "Epoch 42:\tloss:0.4995633363723755\n",
      "Epoch 43:\tloss:0.4995592534542084\n",
      "Epoch 44:\tloss:0.499554306268692\n",
      "Epoch 45:\tloss:0.499549925327301\n",
      "Epoch 46:\tloss:0.49954721331596375\n",
      "Epoch 47:\tloss:0.4995467960834503\n",
      "Epoch 48:\tloss:0.4995482563972473\n",
      "Epoch 49:\tloss:0.49955111742019653\n",
      "Epoch 50:\tloss:0.4995540678501129\n",
      "Epoch 51:\tloss:0.499556303024292\n",
      "Epoch 52:\tloss:0.4995570182800293\n",
      "Epoch 53:\tloss:0.499556303024292\n",
      "Epoch 54:\tloss:0.49955469369888306\n",
      "Epoch 55:\tloss:0.49955272674560547\n",
      "Epoch 56:\tloss:0.499551385641098\n",
      "Epoch 57:\tloss:0.4995509386062622\n",
      "Epoch 58:\tloss:0.4995515048503876\n",
      "Epoch 59:\tloss:0.4995526671409607\n",
      "Epoch 60:\tloss:0.4995538592338562\n",
      "Epoch 61:\tloss:0.4995545744895935\n",
      "Epoch 62:\tloss:0.4995546340942383\n",
      "Epoch 63:\tloss:0.49955394864082336\n",
      "Epoch 64:\tloss:0.4995531141757965\n",
      "Epoch 65:\tloss:0.49955251812934875\n",
      "Epoch 66:\tloss:0.4995523989200592\n",
      "Epoch 67:\tloss:0.4995526671409607\n",
      "Epoch 68:\tloss:0.4995531737804413\n",
      "Epoch 69:\tloss:0.49955374002456665\n",
      "Epoch 70:\tloss:0.4995538592338562\n",
      "Epoch 71:\tloss:0.4995536208152771\n",
      "Epoch 72:\tloss:0.4995531737804413\n",
      "Epoch 73:\tloss:0.49955296516418457\n",
      "Epoch 74:\tloss:0.4995529055595398\n",
      "Epoch 75:\tloss:0.49955305457115173\n",
      "Epoch 76:\tloss:0.4995533525943756\n",
      "Epoch 77:\tloss:0.49955350160598755\n",
      "Epoch 78:\tloss:0.49955350160598755\n",
      "Epoch 79:\tloss:0.49955329298973083\n",
      "Epoch 80:\tloss:0.4995531141757965\n",
      "Epoch 81:\tloss:0.49955305457115173\n",
      "Epoch 82:\tloss:0.4995531737804413\n",
      "Epoch 83:\tloss:0.4995533525943756\n",
      "Epoch 84:\tloss:0.4995534121990204\n",
      "Epoch 85:\tloss:0.4995533525943756\n",
      "Epoch 86:\tloss:0.4995531737804413\n",
      "Epoch 87:\tloss:0.4995531141757965\n",
      "Epoch 88:\tloss:0.4995531737804413\n",
      "Epoch 89:\tloss:0.49955323338508606\n",
      "Epoch 90:\tloss:0.4995533525943756\n",
      "Epoch 91:\tloss:0.49955329298973083\n",
      "Epoch 92:\tloss:0.4995531737804413\n",
      "Epoch 93:\tloss:0.4995531737804413\n",
      "Epoch 94:\tloss:0.4995531737804413\n",
      "Epoch 95:\tloss:0.49955323338508606\n",
      "Epoch 96:\tloss:0.49955329298973083\n",
      "Epoch 97:\tloss:0.49955323338508606\n",
      "Epoch 98:\tloss:0.4995531737804413\n",
      "Epoch 99:\tloss:0.4995531737804413\n"
     ]
    }
   ],
   "source": [
    "model = Network(input_size=60, output_size=1)\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.9, betas=(0.8, 0.95))\n",
    "model.train()\n",
    "model.fit(input=train_data, labels=train_labels, n_epochs=100, loss_fn=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056],\n",
       "        [0.5056]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.forward(test_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
