{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading input into numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cell(cell: str):\n",
    "    if cell == \"R\\n\" or \"M\\n\":\n",
    "        return cell.strip(\"\\n\")\n",
    "    return float(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/sonar.all-data\"\n",
    "f = open(file)\n",
    "M = []\n",
    "for line in f:\n",
    "    M.append([clean_cell(x) for x in line.split(',')])\n",
    "M = np.array([np.array(i) for i in M])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting matrix into features and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = M[:, :60].astype(float)\n",
    "y = M[:, 60]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalising features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_2darray(d2array):\n",
    "    output_array = []\n",
    "    for array in d2array:\n",
    "        output_array.append((array - np.mean(array)) / np.std(array))\n",
    "    return np.asarray(output_array)\n",
    "\n",
    "x_norm = normalise_2darray(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding classes and displaying counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  97],\n",
       "       [  1, 111]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_classes(target):\n",
    "    encoded_target = []\n",
    "    encoding_dict = {'R': 0, 'M': 1}\n",
    "    \n",
    "    for x in target:\n",
    "        encoded_target.append(encoding_dict.get(x))\n",
    "            \n",
    "    return np.asarray(encoded_target), encoding_dict\n",
    "\n",
    "y_enc, encoding = encode_classes(y)\n",
    "np.array(np.unique(y_enc, return_counts=True)).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing features with low impact on target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 37)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_arr = []\n",
    "for idx, row in enumerate(x_norm):\n",
    "    arr = np.asarray(list(row) + [y_enc[idx]])\n",
    "    corr_arr.append(arr)\n",
    "corr_arr = np.asarray(corr_arr)\n",
    "corr_map = np.corrcoef(corr_arr, rowvar=False).round(2)\n",
    "corr_map = corr_map[:, 60]  # keep only final column of the heatmap | correlation to target class\n",
    "corr_map = corr_map.reshape((61, 1))\n",
    "\n",
    "to_drop = []\n",
    "for idx, value in enumerate(corr_map):\n",
    "    if value > -0.1 and value < 0.1:\n",
    "        to_drop.append(idx)\n",
    "to_drop\n",
    "\n",
    "x_norm = np.delete(x_norm, to_drop, axis=1)\n",
    "x_norm.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into train, val and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test  = train_test_split(x_norm, y_enc, test_size=0.1)\n",
    "x_train, x_val, y_train, y_val =  train_test_split(x_train, y_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 37) (57, 37) (21, 37)\n",
      "(130,) (57,) (21,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_val.shape, x_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 64],\n",
       "       [ 1, 66]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.unique(y_train, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 22],\n",
       "       [ 1, 35]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.unique(y_val, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 11],\n",
       "       [ 1, 10]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.unique(y_test, return_counts=True)).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model in Keras (tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\nsiete_test\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (None)/charset_normalizer (3.0.1) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.activations import sigmoid, relu, hard_sigmoid, tanh, softmax\n",
    "\n",
    "input = Input(shape=(x_norm.shape[1], ), name=\"input\")\n",
    "dense1 = Dense(128, activation=lambda x: relu(x, alpha=0.3))(input,)\n",
    "dense2 = Dense(128, activation=lambda x: relu(x, alpha=0.3))(dense1)\n",
    "dense3 = Dense(128, activation=lambda x: relu(x, alpha=0.3))(dense2)\n",
    "dense4 = Dense(64, activation=lambda x: relu(x, alpha=0.3))(dense3)\n",
    "dense5 = Dense(64, activation=lambda x: relu(x, alpha=0.3))(dense4)\n",
    "dense6 = Dense(64, activation=lambda x: relu(x, alpha=0.3))(dense5)\n",
    "dense_out = Dense(1, activation=sigmoid, name=\"dense_out\")(dense6)\n",
    "model = Model(input, dense_out, name='test_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network consists of dense layers using a leaky relu activation function. The alpha is set to 0.3 because it is the default value for the LeakyReLu Keras layer and also more or less consistent with solution and literature I found online. I am using leaky relu instead of standard relu to avoid dead gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.metrics import BinaryAccuracy, AUC\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.99)\n",
    "model.compile(loss=BinaryCrossentropy(from_logits=False), optimizer=optimizer, metrics=[BinaryAccuracy(), AUC()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the Adam optimizer with default arguments. The model is evaluated using the BinaryAccuracy and AUC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "26/26 [==============================] - 1s 9ms/step - loss: 0.6510 - binary_accuracy: 0.6000 - auc: 0.6847 - val_loss: 0.7322 - val_binary_accuracy: 0.4386 - val_auc: 0.7435\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6305 - binary_accuracy: 0.6615 - auc: 0.7041 - val_loss: 0.6644 - val_binary_accuracy: 0.5614 - val_auc: 0.7409\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4479 - binary_accuracy: 0.7615 - auc: 0.8767 - val_loss: 0.5532 - val_binary_accuracy: 0.7193 - val_auc: 0.7974\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3936 - binary_accuracy: 0.8308 - auc: 0.9029 - val_loss: 0.5348 - val_binary_accuracy: 0.7193 - val_auc: 0.7987\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3604 - binary_accuracy: 0.8692 - auc: 0.9182 - val_loss: 0.6704 - val_binary_accuracy: 0.5965 - val_auc: 0.8377\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3512 - binary_accuracy: 0.8615 - auc: 0.9202 - val_loss: 0.7190 - val_binary_accuracy: 0.6140 - val_auc: 0.7935\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3666 - binary_accuracy: 0.8538 - auc: 0.9194 - val_loss: 0.5362 - val_binary_accuracy: 0.6667 - val_auc: 0.8123\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3081 - binary_accuracy: 0.8538 - auc: 0.9408 - val_loss: 0.5116 - val_binary_accuracy: 0.6667 - val_auc: 0.8260\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3151 - binary_accuracy: 0.8846 - auc: 0.9432 - val_loss: 0.6167 - val_binary_accuracy: 0.7018 - val_auc: 0.7838\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2476 - binary_accuracy: 0.8923 - auc: 0.9640 - val_loss: 0.7435 - val_binary_accuracy: 0.6842 - val_auc: 0.7948\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2147 - binary_accuracy: 0.9154 - auc: 0.9749 - val_loss: 0.6113 - val_binary_accuracy: 0.7719 - val_auc: 0.8091\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1977 - binary_accuracy: 0.9000 - auc: 0.9788 - val_loss: 0.7345 - val_binary_accuracy: 0.6667 - val_auc: 0.8474\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1665 - binary_accuracy: 0.9462 - auc: 0.9817 - val_loss: 0.7326 - val_binary_accuracy: 0.7193 - val_auc: 0.7565\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2318 - binary_accuracy: 0.9000 - auc: 0.9701 - val_loss: 0.6775 - val_binary_accuracy: 0.7193 - val_auc: 0.8630\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1771 - binary_accuracy: 0.9154 - auc: 0.9807 - val_loss: 0.9443 - val_binary_accuracy: 0.6316 - val_auc: 0.7422\n",
      "Epoch 16/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1578 - binary_accuracy: 0.9385 - auc: 0.9847 - val_loss: 1.2611 - val_binary_accuracy: 0.5789 - val_auc: 0.7240\n",
      "Epoch 17/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2271 - binary_accuracy: 0.9077 - auc: 0.9724 - val_loss: 1.4886 - val_binary_accuracy: 0.5965 - val_auc: 0.6922\n",
      "Epoch 18/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2446 - binary_accuracy: 0.8769 - auc: 0.9622 - val_loss: 0.5927 - val_binary_accuracy: 0.7193 - val_auc: 0.8409\n",
      "Epoch 19/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1475 - binary_accuracy: 0.9231 - auc: 0.9879 - val_loss: 0.8844 - val_binary_accuracy: 0.6842 - val_auc: 0.8247\n",
      "Epoch 20/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1120 - binary_accuracy: 0.9538 - auc: 0.9931 - val_loss: 1.2743 - val_binary_accuracy: 0.6140 - val_auc: 0.8091\n",
      "Epoch 21/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0652 - binary_accuracy: 0.9923 - auc: 0.9988 - val_loss: 1.1460 - val_binary_accuracy: 0.6316 - val_auc: 0.8000\n",
      "Epoch 22/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0349 - binary_accuracy: 0.9923 - auc: 0.9998 - val_loss: 1.0679 - val_binary_accuracy: 0.7368 - val_auc: 0.8065\n",
      "Epoch 23/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1232 - binary_accuracy: 0.9538 - auc: 0.9922 - val_loss: 0.6399 - val_binary_accuracy: 0.8070 - val_auc: 0.8766\n",
      "Epoch 24/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1134 - binary_accuracy: 0.9462 - auc: 0.9927 - val_loss: 1.0105 - val_binary_accuracy: 0.7895 - val_auc: 0.8039\n",
      "Epoch 25/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0631 - binary_accuracy: 0.9692 - auc: 0.9989 - val_loss: 0.9766 - val_binary_accuracy: 0.7018 - val_auc: 0.8214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28819c35ca0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = (x_val, y_val)\n",
    "model.fit(x=x_train, y=y_train, validation_data=val_data, batch_size=5, epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5543 - binary_accuracy: 0.8095 - auc: 0.9545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5542677640914917, 0.8095238208770752, 0.9545454382896423]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 37)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4864      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_out (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,529\n",
      "Trainable params: 54,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsiete_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
