{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading input into numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cell(cell: str):\n",
    "    if cell == \"R\\n\" or \"M\\n\":\n",
    "        return cell.strip(\"\\n\")\n",
    "    return float(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/sonar.all-data\"\n",
    "f = open(file)\n",
    "M = []\n",
    "for line in f:\n",
    "    M.append([clean_cell(x) for x in line.split(',')])\n",
    "M = np.array([np.array(i) for i in M])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting matrix into features and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = M[:, :60].astype(float)\n",
    "y = M[:, 60]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalising features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_2darray(d2array):\n",
    "    output_array = []\n",
    "    for array in d2array:\n",
    "        output_array.append((array - np.mean(array)) / np.std(array))\n",
    "    return np.asarray(output_array)\n",
    "\n",
    "x_norm = normalise_2darray(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding classes and displaying counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  97],\n",
       "       [  1, 111]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_classes(target):\n",
    "    encoded_target = []\n",
    "    encoding_dict = {'R': 0, 'M': 1}\n",
    "    \n",
    "    for x in target:\n",
    "        encoded_target.append(encoding_dict.get(x))\n",
    "            \n",
    "    return np.asarray(encoded_target), encoding_dict\n",
    "\n",
    "y_enc, encoding = encode_classes(y)\n",
    "np.array(np.unique(y_enc, return_counts=True)).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing features with low impact on target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 37)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORR_TRESHOLD = 0.1\n",
    "\n",
    "corr_arr = []\n",
    "for idx, row in enumerate(x_norm):\n",
    "    arr = np.asarray(list(row) + [y_enc[idx]])\n",
    "    corr_arr.append(arr)\n",
    "corr_arr = np.asarray(corr_arr)\n",
    "corr_map = np.corrcoef(corr_arr, rowvar=False).round(2)\n",
    "corr_map = corr_map[:, 60]  # keep only final column of the heatmap | correlation to target class\n",
    "corr_map = corr_map.reshape((61, 1))\n",
    "\n",
    "to_drop = []\n",
    "for idx, value in enumerate(corr_map):\n",
    "    if value > -CORR_TRESHOLD and value < CORR_TRESHOLD:\n",
    "        to_drop.append(idx)\n",
    "to_drop\n",
    "\n",
    "x_norm = np.delete(x_norm, to_drop, axis=1)\n",
    "x_norm.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into train, val and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test  = train_test_split(x_norm, y_enc, test_size=0.1)\n",
    "x_train, x_val, y_train, y_val =  train_test_split(x_train, y_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 37) (57, 37) (21, 37)\n",
      "(130,) (57,) (21,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_val.shape, x_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 54],\n",
       "       [ 1, 76]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.unique(y_train, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 28],\n",
       "       [ 1, 29]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.unique(y_val, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 15],\n",
       "       [ 1,  6]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.unique(y_test, return_counts=True)).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model in Keras (tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\nsiete_test\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (None)/charset_normalizer (3.0.1) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.activations import sigmoid, relu, hard_sigmoid, tanh, softmax\n",
    "\n",
    "input = Input(shape=(x_norm.shape[1], ), name=\"input\")\n",
    "dense1 = Dense(128, activation=lambda x: relu(x, alpha=0.3))(input,)\n",
    "dense2 = Dense(128, activation=lambda x: relu(x, alpha=0.3))(dense1)\n",
    "dense3 = Dense(128, activation=lambda x: relu(x, alpha=0.3))(dense2)\n",
    "dense4 = Dense(64, activation=lambda x: relu(x, alpha=0.3))(dense3)\n",
    "dense5 = Dense(64, activation=lambda x: relu(x, alpha=0.3))(dense4)\n",
    "dense6 = Dense(64, activation=lambda x: relu(x, alpha=0.3))(dense5)\n",
    "dense_out = Dense(1, activation=sigmoid, name=\"dense_out\")(dense6)\n",
    "model = Model(input, dense_out, name='test_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network consists of dense layers using a leaky relu activation function. The alpha is set to 0.3 because it is the default value for the LeakyReLu Keras layer and also more or less consistent with solution and literature I found online. I am using leaky relu instead of standard relu to avoid dead gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.metrics import BinaryAccuracy, AUC\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.99)\n",
    "model.compile(loss=BinaryCrossentropy(from_logits=False), optimizer=optimizer, metrics=[BinaryAccuracy(), AUC()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the Adam optimizer with default Keras arguments. The model is evaluated using the BinaryAccuracy and AUC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleonard-puskac\u001b[0m (\u001b[33mfiit-nn-2023-lp-vs\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\VScode Projects\\FIIT_MASTERS\\NSIETE\\nsiete_projects\\NN_assignment_1\\wandb\\run-20230330_164746-2nk1w0lg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras/runs/2nk1w0lg' target=\"_blank\">eager-universe-11</a></strong> to <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras' target=\"_blank\">https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras/runs/2nk1w0lg' target=\"_blank\">https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras/runs/2nk1w0lg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 1/26 [>.............................] - ETA: 9s - loss: 0.6995 - binary_accuracy: 0.4000 - auc: 0.3333WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.\n",
      "26/26 [==============================] - 1s 9ms/step - loss: 0.6331 - binary_accuracy: 0.6769 - auc: 0.6886 - val_loss: 0.5820 - val_binary_accuracy: 0.7018 - val_auc: 0.8183\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5443 - binary_accuracy: 0.7462 - auc: 0.7814 - val_loss: 0.4511 - val_binary_accuracy: 0.7895 - val_auc: 0.8818\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4998 - binary_accuracy: 0.7769 - auc: 0.8375 - val_loss: 0.4501 - val_binary_accuracy: 0.7544 - val_auc: 0.9033\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4362 - binary_accuracy: 0.7846 - auc: 0.8724 - val_loss: 0.5287 - val_binary_accuracy: 0.7368 - val_auc: 0.8799\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4191 - binary_accuracy: 0.8000 - auc: 0.8757 - val_loss: 0.4036 - val_binary_accuracy: 0.7895 - val_auc: 0.8984\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3726 - binary_accuracy: 0.8308 - auc: 0.9069 - val_loss: 0.3910 - val_binary_accuracy: 0.8421 - val_auc: 0.8990\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3338 - binary_accuracy: 0.8538 - auc: 0.9232 - val_loss: 0.3689 - val_binary_accuracy: 0.8421 - val_auc: 0.9138\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2782 - binary_accuracy: 0.8769 - auc: 0.9488 - val_loss: 0.4715 - val_binary_accuracy: 0.7895 - val_auc: 0.8947\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2620 - binary_accuracy: 0.8923 - auc: 0.9533 - val_loss: 0.4046 - val_binary_accuracy: 0.8421 - val_auc: 0.9021\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2299 - binary_accuracy: 0.9077 - auc: 0.9645 - val_loss: 0.4986 - val_binary_accuracy: 0.7544 - val_auc: 0.9058\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2513 - binary_accuracy: 0.8692 - auc: 0.9544 - val_loss: 0.4498 - val_binary_accuracy: 0.8596 - val_auc: 0.8984\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1813 - binary_accuracy: 0.9231 - auc: 0.9789 - val_loss: 0.5333 - val_binary_accuracy: 0.8070 - val_auc: 0.8947\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1431 - binary_accuracy: 0.9231 - auc: 0.9895 - val_loss: 0.6304 - val_binary_accuracy: 0.7544 - val_auc: 0.8978\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1467 - binary_accuracy: 0.9385 - auc: 0.9915 - val_loss: 0.6658 - val_binary_accuracy: 0.8246 - val_auc: 0.8805\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2233 - binary_accuracy: 0.9231 - auc: 0.9716 - val_loss: 0.9311 - val_binary_accuracy: 0.7719 - val_auc: 0.8454\n",
      "Epoch 16/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2459 - binary_accuracy: 0.8846 - auc: 0.9569 - val_loss: 0.5367 - val_binary_accuracy: 0.8421 - val_auc: 0.8812\n",
      "Epoch 17/25\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0963 - binary_accuracy: 0.9692 - auc: 0.9974 - val_loss: 0.7394 - val_binary_accuracy: 0.7895 - val_auc: 0.8830\n",
      "Epoch 18/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0789 - binary_accuracy: 0.9615 - auc: 0.9973 - val_loss: 0.7744 - val_binary_accuracy: 0.8421 - val_auc: 0.8658\n",
      "Epoch 19/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0276 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.8784 - val_binary_accuracy: 0.8596 - val_auc: 0.8713\n",
      "Epoch 20/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0198 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.1543 - val_binary_accuracy: 0.8246 - val_auc: 0.8812\n",
      "Epoch 21/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0096 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.1837 - val_binary_accuracy: 0.8246 - val_auc: 0.8885\n",
      "Epoch 22/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0411 - binary_accuracy: 0.9923 - auc: 0.9993 - val_loss: 1.5992 - val_binary_accuracy: 0.7719 - val_auc: 0.8436\n",
      "Epoch 23/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1573 - binary_accuracy: 0.9462 - auc: 0.9767 - val_loss: 1.2895 - val_binary_accuracy: 0.8070 - val_auc: 0.8331\n",
      "Epoch 24/25\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4879 - binary_accuracy: 0.8615 - auc: 0.9310 - val_loss: 0.5824 - val_binary_accuracy: 0.8070 - val_auc: 0.8633\n",
      "Epoch 25/25\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1385 - binary_accuracy: 0.9538 - auc: 0.9973 - val_loss: 0.5848 - val_binary_accuracy: 0.8246 - val_auc: 0.8805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12399d98670>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "\n",
    "wandb.init(project=\"nn-assignemt-1-tf-keras\")\n",
    "\n",
    "val_data = (x_val, y_val)\n",
    "model.fit(x=x_train, y=y_train, validation_data=val_data, batch_size=5, epochs=25, verbose=1, callbacks=[WandbMetricsLogger()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7164 - binary_accuracy: 0.8095 - auc: 0.8611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7164464592933655, 0.8095238208770752, 0.8611111044883728]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 37)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4864      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_out (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,529\n",
      "Trainable params: 54,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsiete_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
