{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading input into numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cell(cell: str):\n",
    "    if cell == \"R\\n\" or \"M\\n\":\n",
    "        return cell.strip(\"\\n\")\n",
    "    return float(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/sonar.all-data\"\n",
    "f = open(file)\n",
    "M = []\n",
    "for line in f:\n",
    "    M.append([clean_cell(x) for x in line.split(',')])\n",
    "M = np.array([np.array(i) for i in M])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting matrix into features and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = M[:, :60].astype(float)\n",
    "y = M[:, 60]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalising features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_2darray(d2array):\n",
    "    output_array = []\n",
    "    for array in d2array:\n",
    "        output_array.append((array - np.mean(array)) / np.std(array))\n",
    "    return np.asarray(output_array)\n",
    "\n",
    "x_norm = normalise_2darray(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding classes and displaying counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  97],\n",
       "       [  1, 111]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_classes(target):\n",
    "    encoded_target = []\n",
    "    encoding_dict = {'R': 0, 'M': 1}\n",
    "    \n",
    "    for x in target:\n",
    "        encoded_target.append(encoding_dict.get(x))\n",
    "            \n",
    "    return np.asarray(encoded_target), encoding_dict\n",
    "\n",
    "y_enc, encoding = encode_classes(y)\n",
    "np.array(np.unique(y_enc, return_counts=True)).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing features with low impact on target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 37)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORR_TRESHOLD = 0.1\n",
    "\n",
    "corr_arr = []\n",
    "for idx, row in enumerate(x_norm):\n",
    "    arr = np.asarray(list(row) + [y_enc[idx]])\n",
    "    corr_arr.append(arr)\n",
    "corr_arr = np.asarray(corr_arr)\n",
    "corr_map = np.corrcoef(corr_arr, rowvar=False).round(2)\n",
    "corr_map = corr_map[:, 60]  # keep only final column of the heatmap | correlation to target class\n",
    "corr_map = corr_map.reshape((61, 1))\n",
    "\n",
    "to_drop = []\n",
    "for idx, value in enumerate(corr_map):\n",
    "    if value > -CORR_TRESHOLD and value < CORR_TRESHOLD:\n",
    "        to_drop.append(idx)\n",
    "to_drop\n",
    "\n",
    "x_norm = np.delete(x_norm, to_drop, axis=1)\n",
    "x_norm.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into train, val and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test  = train_test_split(x_norm, y_enc, test_size=0.1)\n",
    "x_train, x_val, y_train, y_val =  train_test_split(x_train, y_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 37) (57, 37) (21, 37)\n",
      "(130,) (57,) (21,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_val.shape, x_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 65],\n",
       "       [ 1, 65]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.unique(y_train, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 23],\n",
       "       [ 1, 34]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.unique(y_val, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  9],\n",
       "       [ 1, 12]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.unique(y_test, return_counts=True)).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model in Keras (tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.activations import sigmoid, relu, hard_sigmoid, tanh, softmax\n",
    "\n",
    "input = Input(shape=(x_norm.shape[1], ), name=\"input\")\n",
    "dense1 = Dense(128, activation=lambda x: relu(x, alpha=0.3))(input,)\n",
    "dense2 = Dense(128, activation=lambda x: relu(x, alpha=0.3))(dense1)\n",
    "dense3 = Dense(128, activation=lambda x: relu(x, alpha=0.3))(dense2)\n",
    "dense4 = Dense(64, activation=lambda x: relu(x, alpha=0.3))(dense3)\n",
    "dense5 = Dense(64, activation=lambda x: relu(x, alpha=0.3))(dense4)\n",
    "dense6 = Dense(64, activation=lambda x: relu(x, alpha=0.3))(dense5)\n",
    "dense_out = Dense(1, activation=sigmoid, name=\"dense_out\")(dense6)\n",
    "model = Model(input, dense_out, name='test_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network consists of dense layers using a leaky relu activation function. The alpha is set to 0.3 because it is the default value for the LeakyReLu Keras layer and also more or less consistent with solution and literature I found online. I am using leaky relu instead of standard relu to avoid dead gradients."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also tried using alternating tanh and sigmoid functions, as well as standard relu, but the results were significantly worse -> 0.4 - 0.6 accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.metrics import BinaryAccuracy, AUC\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.99)\n",
    "model.compile(loss=BinaryCrossentropy(from_logits=False), optimizer=optimizer, metrics=[BinaryAccuracy(), AUC()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the Adam optimizer with default Keras arguments. The model is evaluated using the BinaryAccuracy and AUC metrics\n",
    "\n",
    "Other optimizers, such as RMSProp, didn't make much difference, just different behaviour with regards to required batch sizes and epochs\n",
    "\n",
    "With regards to Adam parameters, they caused some difference in the results with the batch size and epoch settings we used the most frequently, and also occasional wild jumps in val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:93gyejk1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/auc</td><td>▁▅▅▆▇▇▇▇▇▇████▇███████████████▇█████████</td></tr><tr><td>epoch/binary_accuracy</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████▇▇▇▇████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▆▆▅▄▅▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▃▃▅▃▂▂▂▁▁▁▁▁</td></tr><tr><td>epoch/val_auc</td><td>▁▂▂▃▆▇▅▆▆▆▆▇▇▇█▇▇▇▇▇▇▇▇▆▆▇▇▇▇▅█▇████████</td></tr><tr><td>epoch/val_binary_accuracy</td><td>▁▃▃▄▅▆▅▅▆▅▆▆▇▆▇▅▇█▆▇▆▇▇▆▇██▇▆▆▆▇▆▇▇▇▇▇▇▇</td></tr><tr><td>epoch/val_loss</td><td>▂▂▂▂▁▁▂▁▁▂▂▂▂▂▁▂▂▂▂▂▄▃▄▃▅▄▃▃▄█▂▂▂▁▂▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/auc</td><td>1.0</td></tr><tr><td>epoch/binary_accuracy</td><td>0.99231</td></tr><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.02392</td></tr><tr><td>epoch/val_auc</td><td>0.85546</td></tr><tr><td>epoch/val_binary_accuracy</td><td>0.78947</td></tr><tr><td>epoch/val_loss</td><td>0.92729</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-field-29</strong> at: <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras/runs/93gyejk1' target=\"_blank\">https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras/runs/93gyejk1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230330_173901-93gyejk1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:93gyejk1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\VScode Projects\\FIIT_MASTERS\\NSIETE\\nsiete_projects\\NN_assignment_1\\wandb\\run-20230330_174017-wfg5x58p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras/runs/wfg5x58p' target=\"_blank\">deep-grass-30</a></strong> to <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras' target=\"_blank\">https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras/runs/wfg5x58p' target=\"_blank\">https://wandb.ai/fiit-nn-2023-lp-vs/nn-assignemt-1-tf-keras/runs/wfg5x58p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 32ms/step - loss: 0.7009 - binary_accuracy: 0.4923 - auc_1: 0.5187 - val_loss: 0.6660 - val_binary_accuracy: 0.6491 - val_auc_1: 0.7442\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6341 - binary_accuracy: 0.7154 - auc_1: 0.8141 - val_loss: 0.6160 - val_binary_accuracy: 0.6491 - val_auc_1: 0.7673\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5548 - binary_accuracy: 0.7462 - auc_1: 0.8347 - val_loss: 0.6052 - val_binary_accuracy: 0.6667 - val_auc_1: 0.7801\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4791 - binary_accuracy: 0.7769 - auc_1: 0.8718 - val_loss: 0.4884 - val_binary_accuracy: 0.7719 - val_auc_1: 0.8350\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4353 - binary_accuracy: 0.7846 - auc_1: 0.9045 - val_loss: 0.5186 - val_binary_accuracy: 0.7018 - val_auc_1: 0.8402\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4012 - binary_accuracy: 0.8077 - auc_1: 0.9096 - val_loss: 0.5217 - val_binary_accuracy: 0.7719 - val_auc_1: 0.8325\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3785 - binary_accuracy: 0.7923 - auc_1: 0.9288 - val_loss: 0.4732 - val_binary_accuracy: 0.7719 - val_auc_1: 0.8216\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3584 - binary_accuracy: 0.8385 - auc_1: 0.9310 - val_loss: 0.4697 - val_binary_accuracy: 0.7193 - val_auc_1: 0.8178\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3553 - binary_accuracy: 0.8538 - auc_1: 0.9266 - val_loss: 0.4670 - val_binary_accuracy: 0.7544 - val_auc_1: 0.8331\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2947 - binary_accuracy: 0.8923 - auc_1: 0.9538 - val_loss: 0.5147 - val_binary_accuracy: 0.7193 - val_auc_1: 0.8191\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2983 - binary_accuracy: 0.8769 - auc_1: 0.9478 - val_loss: 0.5354 - val_binary_accuracy: 0.7368 - val_auc_1: 0.8133\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2710 - binary_accuracy: 0.8692 - auc_1: 0.9576 - val_loss: 0.5760 - val_binary_accuracy: 0.7368 - val_auc_1: 0.8095\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2508 - binary_accuracy: 0.9231 - auc_1: 0.9606 - val_loss: 0.5616 - val_binary_accuracy: 0.7193 - val_auc_1: 0.8050\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2293 - binary_accuracy: 0.9077 - auc_1: 0.9676 - val_loss: 0.5699 - val_binary_accuracy: 0.8070 - val_auc_1: 0.8037\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2131 - binary_accuracy: 0.9154 - auc_1: 0.9723 - val_loss: 0.6138 - val_binary_accuracy: 0.7368 - val_auc_1: 0.8146\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2706 - binary_accuracy: 0.8846 - auc_1: 0.9699 - val_loss: 0.7150 - val_binary_accuracy: 0.7719 - val_auc_1: 0.7852\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3564 - binary_accuracy: 0.8385 - auc_1: 0.9537 - val_loss: 0.7015 - val_binary_accuracy: 0.6842 - val_auc_1: 0.7877\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3020 - binary_accuracy: 0.8462 - auc_1: 0.9720 - val_loss: 0.5645 - val_binary_accuracy: 0.7895 - val_auc_1: 0.8012\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2734 - binary_accuracy: 0.8615 - auc_1: 0.9709 - val_loss: 0.5903 - val_binary_accuracy: 0.8070 - val_auc_1: 0.8069\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2278 - binary_accuracy: 0.9000 - auc_1: 0.9693 - val_loss: 0.5689 - val_binary_accuracy: 0.7193 - val_auc_1: 0.8178\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2122 - binary_accuracy: 0.9154 - auc_1: 0.9774 - val_loss: 0.6914 - val_binary_accuracy: 0.7544 - val_auc_1: 0.7871\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1792 - binary_accuracy: 0.9154 - auc_1: 0.9845 - val_loss: 0.7004 - val_binary_accuracy: 0.6667 - val_auc_1: 0.7839\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1804 - binary_accuracy: 0.9308 - auc_1: 0.9862 - val_loss: 0.6869 - val_binary_accuracy: 0.7193 - val_auc_1: 0.7871\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1396 - binary_accuracy: 0.9538 - auc_1: 0.9938 - val_loss: 0.7092 - val_binary_accuracy: 0.7368 - val_auc_1: 0.7896\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1183 - binary_accuracy: 0.9538 - auc_1: 0.9953 - val_loss: 0.8386 - val_binary_accuracy: 0.7193 - val_auc_1: 0.7781\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1045 - binary_accuracy: 0.9615 - auc_1: 0.9961 - val_loss: 0.8951 - val_binary_accuracy: 0.6842 - val_auc_1: 0.7762\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1003 - binary_accuracy: 0.9538 - auc_1: 0.9953 - val_loss: 0.9959 - val_binary_accuracy: 0.7368 - val_auc_1: 0.7705\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0902 - binary_accuracy: 0.9692 - auc_1: 0.9964 - val_loss: 1.0192 - val_binary_accuracy: 0.6842 - val_auc_1: 0.7775\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0740 - binary_accuracy: 0.9692 - auc_1: 0.9980 - val_loss: 1.1832 - val_binary_accuracy: 0.6667 - val_auc_1: 0.7634\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0646 - binary_accuracy: 0.9692 - auc_1: 0.9988 - val_loss: 1.2215 - val_binary_accuracy: 0.7018 - val_auc_1: 0.7762\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0562 - binary_accuracy: 0.9692 - auc_1: 0.9988 - val_loss: 1.2934 - val_binary_accuracy: 0.6842 - val_auc_1: 0.7769\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0503 - binary_accuracy: 0.9692 - auc_1: 0.9983 - val_loss: 1.3841 - val_binary_accuracy: 0.6842 - val_auc_1: 0.7666\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0614 - binary_accuracy: 0.9692 - auc_1: 0.9988 - val_loss: 1.3473 - val_binary_accuracy: 0.7018 - val_auc_1: 0.7845\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0497 - binary_accuracy: 0.9769 - auc_1: 0.9983 - val_loss: 1.4345 - val_binary_accuracy: 0.7018 - val_auc_1: 0.7590\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0481 - binary_accuracy: 0.9923 - auc_1: 0.9988 - val_loss: 1.4278 - val_binary_accuracy: 0.7018 - val_auc_1: 0.7660\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0345 - binary_accuracy: 0.9923 - auc_1: 0.9991 - val_loss: 1.5129 - val_binary_accuracy: 0.6667 - val_auc_1: 0.7826\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0317 - binary_accuracy: 0.9846 - auc_1: 0.9993 - val_loss: 1.7601 - val_binary_accuracy: 0.7018 - val_auc_1: 0.7749\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0279 - binary_accuracy: 0.9923 - auc_1: 0.9995 - val_loss: 1.8923 - val_binary_accuracy: 0.6842 - val_auc_1: 0.7526\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0317 - binary_accuracy: 0.9846 - auc_1: 1.0000 - val_loss: 1.8903 - val_binary_accuracy: 0.7018 - val_auc_1: 0.7506\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0190 - binary_accuracy: 0.9923 - auc_1: 1.0000 - val_loss: 1.8712 - val_binary_accuracy: 0.6667 - val_auc_1: 0.7519\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0125 - binary_accuracy: 0.9923 - auc_1: 1.0000 - val_loss: 2.0031 - val_binary_accuracy: 0.6842 - val_auc_1: 0.7660\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0120 - binary_accuracy: 0.9923 - auc_1: 1.0000 - val_loss: 2.1943 - val_binary_accuracy: 0.7018 - val_auc_1: 0.7430\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0099 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 2.1818 - val_binary_accuracy: 0.7018 - val_auc_1: 0.7391\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0060 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 2.0939 - val_binary_accuracy: 0.6842 - val_auc_1: 0.7564\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0037 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 2.2180 - val_binary_accuracy: 0.6667 - val_auc_1: 0.7410\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0028 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 2.3892 - val_binary_accuracy: 0.6667 - val_auc_1: 0.7474\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0020 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 2.5009 - val_binary_accuracy: 0.6667 - val_auc_1: 0.7564\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0014 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 2.5446 - val_binary_accuracy: 0.6667 - val_auc_1: 0.7302\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0012 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 2.5845 - val_binary_accuracy: 0.6667 - val_auc_1: 0.7295\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.8526e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 2.6063 - val_binary_accuracy: 0.6842 - val_auc_1: 0.7379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ca72d85e0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "\n",
    "wandb.init(project=\"nn-assignemt-1-tf-keras\", group=\"batch_25_epoch_50\")\n",
    "\n",
    "val_data = (x_val, y_val)\n",
    "model.fit(x=x_train, y=y_train, validation_data=val_data, batch_size=25, epochs=50, verbose=1, callbacks=[WandbMetricsLogger()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step - loss: 2.6009 - binary_accuracy: 0.6667 - auc_1: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6008682250976562, 0.6666666865348816, 0.75]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 37)]              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               4864      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_out (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,529\n",
      "Trainable params: 54,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsiete_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
